:raw-latex:`\pagebreak`


----------------------
Sim-Diasca Cheat Sheet
----------------------

.. warning:: This section would deserve some update.


Note: unless specified otherwise, mentioned tests are to be found in the ``sim-diasca/src/core/src/scheduling/tests`` directory.




Which Sim-Diasca Version Should Be Used?
========================================

Previously there were two versions, one local, one distributed. Now that they have been merged into a single base, one should simply pick the latest stable version. That's it!

To check which version you are using, simply run from the root directory:

.. code:: bash

 $ make info-version
 This is Sim-Diasca version x.y.z.


Alternatively, look at the ``SIM_DIASCA_VERSION`` variable in ``sim-diasca/GNUmakevars.inc``.


As upgrading the Sim-Diasca version is fairly straightforward, we recommend to stick to the latest stable one, which simplifies considerably any support.

Finally, the lower layers (namely Erlang itself, ``Myriad``, ``WOOPER`` and ``Traces``) have of course their own version as well, and the same holds for the upper layers, i.e. the actual simulations making use of Sim-Diasca (from the toy examples in ``mock-simulators`` to any user-provided one).

Anyway, as a given version of Sim-Diasca is delivered with all its strictly mandatory prerequisites except Erlang, no particular checking of their version is necessary, as they collectively form a consistent bundle.



How Can We Run a Simulation?
============================

A simulation can be run either from a *test* file, whose name is suffixed with ``_test.erl`` (ex: stored in a ``my_foobar_test.erl``) or from a *case* file, whose name is suffixed with ``_case.erl`` (ex: stored in a ``my_baz_case.erl``).

No runtime difference is made between these two (they are technically exactly handled the same), the purpose of this distinction being solely to help the user separating the more punctual testing from full-blown simulation cases.

So, with both tests and cases:

- the corresponding simulation shall be run by executing a make target bearing the same name, suffixed by ``_run``; respectively as ``make my_foobar_run`` and ``make my_baz_run`` for the two examples above
- all files and directories generated by the simulation (notably traces and results) will be created in the current directory; typically the user changes to the directory where the corresponding test or case file is stored, and run it from there
- by default, simulations will be run in interactively, i.e. with graphical windows popping up (ex: to browse traces, results, etc.); to prevent that and remain in a purely textual, command-line, batch execution, one can add the ``CMD_LINE_OPT="--batch"`` option to the make command; as it involves some typing, it may be convenient to define a shorthand for that, typically by putting in ones's ``~/.bashrc`` a line like: ``export BATCH='CMD_LINE_OPT="--batch"'``


As a full, concrete example of running a *test* simulation interactively:

.. code:: bash

 $ cd mock-simulators/soda-test/src
 $ ls soda_stochastic_integration_test.erl
 soda_stochastic_integration_test.erl
 $ make soda_stochastic_integration_run
 Running unitary test soda_stochastic_integration_run (third form) from soda_stochastic_integration_test
 [...]
 End of test soda_stochastic_integration_test
 (test finished, interpreter halted)


To run a simulation *case*, here in batch mode:

.. code:: bash

 $ cd mock-simulators/soda-test/src
 $ ls soda_platform_integration_case.erl
 soda_platform_integration_case.erl
 $ make soda_platform_integration_run CMD_LINE_OPT="--batch"
 Running simulation case soda_platform_integration_case
 [...]
 End of case soda_platform_integration_case
 (case finished, interpreter halted)


Of course, with the aforementioned shell shorthand, the last case could also be run as:

.. code:: bash

 $ make soda_platform_integration_run $BATCH



How Can I Select Whether A Simulation Run Shall be Purely Local, or Distributed?
================================================================================

Each simulation case is able to define how it is to be deployed or executed, simply by setting accordingly the ``computing_hosts`` field in its ``deployment_settings`` record (whose full definition and associated comments can be found in ``class_DeploymentManager.hrl``).

Most test cases rely on default settings, which operate this way:

1. if a host file - named by default ``sim-diasca-host-candidates.txt`` - is found in the current directory (the one from which a test case ``X`` is run, thanks to a ``make X_run`` for example), then the engine will read it and try to use the hosts listed there; the (ETF) syntax is simple and described in the ``sim-diasca-host-candidates-sample.txt`` example file, to be found in the ``sim-diasca/conf`` directory (it is also described `here <http://myriad.esperide.org/#etf>`_)

2. if this host file is not found, the simulation will run only locally


The ``computing_hosts`` field can also directly list the hosts involved, but we do not recommend doing so, as in general a simulation case should not be specific to any deployment context (hence our defaults).

The ``deployment_settings`` record allows to specify more advanced options (ex: whether the simulation should stop on error if at least one of the listed hosts could not be used, up to which duration a deployment may last, whether the user host shall be used for computations, etc.), see its definition mentioned above for further information.



How Many Erlang Nodes Are Involved in a Simulation?
===================================================

By default (unless specified otherwise, see above), only the local host is involved, yet there are two VMs running then: the one of the user node, and the one of a (local) computing node.

In the general case, distributed simulations running on ``N`` hosts will involve by default ``N+1`` nodes: one user node (on the user host) and ``N`` computing nodes (including one on the user host).

See the ``computing_hosts`` field in the ``deployment_settings`` record (defined in ``class_DeploymentManager.hrl``) for further options.


.. _`distributed cheat sheet`:


What Constraints shall be Observed in order to run in a Distributed Manner (ex: on a cluster)?
==============================================================================================

Let's suppose that you benefit from a set of hosts, either ad hoc or allocated on a cluster by a job manager such as `Slurm <https://en.wikipedia.org/wiki/Slurm_Workload_Manager>`_.

These hosts are expected to run GNU/Linux, to be rather homogeneous in terms of processing power and configuration, and to be interlinked thanks to a suitable IPv4 [#]_ communication network providing at least DNS services, and possibly ping (ICMP) ones [#]_.

.. [#] If the network is by default using IPv6, generally a setting allows to present it to applications as an IPv4 network.

.. [#] If no ping service is available, then, in the ``deployment_settings`` record of your simulation case, set ``ping_available=false``, and the simulation will try directly to SSH-connect to hosts (possibly inducing longer timeouts).

When specifying these hosts (ex: in a host file of the ``computing_hosts`` field of the deployment record, or directly in the simulation case), their DNS name (more precisely, their FQDN [#]_) shall be retained (not, for example, their IP address).

.. [#] *Fully-Qualified Domain Name*, e.g. ``hurricane.foobar.org`` rather than just ``hurricane``, knowing that from a FQDN a (domain-less) hostname can be derived, whereas this cannot be done the other way round. Sim-Diasca will start first with no distribution, then will attempt first to make use, in Erlang node parlance, of *short* names before, depending on the local DNS configuration, attempting to switch to *long* names instead.


Moreover, for the simulation user, a SSH password-less authentication must be possible at least from the user host to each of the computing hosts, so that the former can spawn an Erlang VM on the latter.

Indeed, all hosts, be them the user one or a computing one, must be able to run their own Erlang virtual machine; as a result the Erlang environment must have been installed, typically thanks to our ``myriad/conf/install-erlang.sh`` script.

Quite often HPC clusters implement a distributed filesystem (ex: mounted in ``/scratch``, thanks to NFS, Lustre or any similar solution), in which case a single Erlang installation can be done once for all, each computing node creating its own VM from it.

If no such distributed filesystem exists, the Erlang environment must be deployed/installed on each computing host, by any relevant means.

These target Erlang installations must be readily available from the default ``PATH`` that is obtained from a SSH connection to a computing host: from the user host, ``ssh A_COMPUTING_NODE erl`` should successfully run an Erlang VM [#]_.

.. [#] If in this case a custom, locally-installed Erlang version (ex: located in ``~/Software/Erlang/Erlang-current-install``) is not found whereas it was added in the ``PATH`` of the user's ``~/.bashrc``, consider that many default batch configurations ignore this file for non-login shells ("*If not running interactively, don't do anything*"); a workaround is to update one's ``PATH`` at the beginning of one's ``~/.bashrc`` rather than at its end, before it bails out with a ``return``.


As for Sim-Diasca, its own Ceylan prerequisites (namely `Myriad <http://myriad.esperide.org/>`_, `WOOPER <http://wooper.esperide.org/>`_ and `Traces <http://traces.esperide.org/>`_), the engine itself and the user-defined simulation elements (simulation case, models, data, etc.), the whole will be automatically deployed from the user host to the computing ones, according to the specified simulation settings.

One should thus ensure that these settings are complete, and that any third-party software used (ex: in models, in probes, etc.; including any language binding) is available on all computing hosts.

Finally, we advise having a look to the help scripts defined in ``sim-diasca/conf/clusters``, which are meant to ease the management of Sim-Diasca jobs run on Slurm-based HPC clusters.


.. _`distributed gotchas`:

What are the Most Common Gotchas encountered with Distributed Simulations?
==========================================================================

As soon as an application is distributed, a rather wide range of additional problems may appear.

Here are a list of checks that might be of help:

- is this simulation (possibly set to a lesser scale) running well on a single host?
- has the full simulation been recompiled from scratch with success, using a recent version of Erlang?
- is this version of Erlang uniform across all hosts involved in the simulation? (it is usually not strictly necessary, but is convenient to rule out some possible incompatibilities)
- are ping (ICMP) messages supported by the hosts and network at hand? If no, set the ``ping_available`` field of the ``deployment_settings`` record to ``false``
- does spawning a Erlang VM on a computing host non-interactively through SSH from the user host succeed? Ex: from the user host, ``ssh A_COMPUTING_HOST erl``
- does it spawn a VM with the same, expected Erlang version? (ex: ``Eshell V10.2``)
- can this VM be run with long names, and does it report the expected FQDN in its prompt? Ex: ``ssh COMPUTING_HOST_FQDN erl -name foo`` reporting ``(foo@COMPUTING_HOST_FQDN)1>``
- are all hosts specified indeed by their FQDN? (rather than by a riskier mere hostname or, worse, by their IP address - which is not permitted)
- on any host or network device, have fancier firewall rules been defined? (ex: ``iptables -L`` might give clues)
- on a cluster, have the right hosts been allocated by the job manager, and is the user host one of them? (rather than for example being a front-end host, which surely should not be attempted)

Should the problem remain, one may log interactively and perform operations manually to check whether the engine has a chance of succeeding when doing the same.


What is the First Tick Offset of a Simulation?
==============================================

Tick offset #0.


What is the First Diasca of a given Tick T?
===========================================

Diasca #0! Hence the corresponding simulation timestamp is ``{T,0}``.



How a Simulation Starts?
========================

The root time manager is to be requested to start from the simulation case being run, typically by executing its ``start/{1,2,3}`` or ``startFor/{2,3}`` oneways.

For that, the PID of the deployment manager shall be obtained first, thanks a call to one of the ``sim_diasca/{1,2,3}`` functions; for example:

.. code:: erlang

 DeploymentManagerPid = sim_diasca:init(SimulationSettings, DeploymentSettings)


Then the PID of the root time manager can be requested from it:

.. code:: erlang

 DeploymentManagerPid ! {getRootTimeManager, [], self()},
 RootTimeManagerPid = test_receive()


The actual start can be then triggered thanks to:

.. code:: erlang

 RootTimeManagerPid ! {start, [self()]}



This will evaluate the simulation from its first timestamp, ``{0,0}``:

- the ``simulationStarted/3`` request of all time managers will be triggered by the root one, resulting in the request being triggered (by transparent chunks) in turn to all initial actors so that they can be synchronised (i.e. so that they are notified of various information, mostly time-related); at this point they are still passive, have no agenda declared and are not fully initialized (their own initialization logic is to be triggered only when entering for good the simulation, at their fist diasca)
- then the root time manager auto-triggers its ``beginTimeManagerTick/2`` oneway
- then ``{0,0}`` is scheduled, and the load balancer (created, like the time managers, by the deployment manager) is triggered (by design no other actor can possibly in that case), for its first and only spontaneous scheduling, during which it will trigger in turn, over the first diascas (to avoid a potentially too large initial spike), the ``onFirstDiasca/2`` actor oneway of all initial actors (that it had spawned)

As actors can schedule themselves only once fully ready (thus from their ``onFirstDiasca/2`` actor oneway onward), by design the load balancer is the sole actor to be scheduled at ``{0,0}`` (thus spontaneously), leading all other actors to be triggered for their first diasca only at ``{0,1}``, and possible next diascas, should initial actors be numerous.

From that point they can start sending (and thus receiving) actor messages (while still at tick offset #0), or they can request a spontaneous activation at the next tick (hence at ``{1,0}``), see ``class_Actor:scheduleNextSpontaneousTick/1`` for that.


In summary, from an actor's viewpoint, in all cases:

- it is constructed first (no inter-actor message of any kind to be sent from there)
- (it is synchronised to the simulation with its time manager - this step is fully transparent to the model developer)
- its ``onFirstDiasca/2`` actor oneway is triggered once entering the simulation; it is up to this oneway to send actor messages and/or declare at least one spontaneous tick (otherwise this actor will remain purely passive)


For more information about simulation cases, one may look at a complete example thereof, such as ``soda_deterministic_integration_test.erl``, located in ``mock-simulators/soda-test/test``.



How Actors Are To Be Created?
=============================

Actors are to be created either before the simulation starts (they are then called *initial actors*) or in the course of the simulation (they are then *simulation-time actors*, or *runtime* actors).

In all cases, their creation must be managed through the simulation engine, not directly by the user (for example, making a direct use of ``erlang:spawn*`` or any WOOPER ``new`` variation is *not* allowed), as otherwise even essential simulation properties could not be preserved.

**Initial** actors are to be created:

- either *programmatically*, directly from the simulation case, or from any code running (synchronously, to avoid a potential race condition) prior to the starting the simulation (ex: in the constructor of a scenario which would be created from the simulation case); see the ``class_Actor:create_initial_actor/{2,3}`` and ``class_Actor:create_initial_placed_actor/{3,4}`` static methods for individual creations (in the latter case with a placement hint), and the static methods ``class_Actor:create_initial_actors/{1,2}`` for the creation of a set of actors
- or *from data*, i.e. from a stream of construction parameters; these information are typically read from an initialization file, see the ``initialisation_files`` field of the ``simulation_settings`` record

In both cases, an initial actor is able to create directly from its constructor any number of other (initial) actors.


**Simulation-time** actors are solely to be created directly from other actors that are already running - not from their constructors [#]_; hence simulation-time actors shall be created no sooner than in the ``onFirstDiasca/2`` oneway of the creating actor; creation tags may be specified in order to help the creating actor between simultaneous creations; please refer to the ``class_Actor:create_actor/{3,4}`` and ``class_Actor:create_placed_actor/{4,5}`` helper functions for that

.. [#] As a just-created *and* creating actor is not yet synchronized to the simulation, hence unable to interact with the load balancer through actor messages for that.


In all cases, an actor can be either automatically created by the engine on a computing node chosen according to its *default heuristic* (agnostic placement), or the target node can be selected according to a *placement hint*, specified at the actor creation.

In the latter case, the engine will then do its best to place all actors being created with the same placement hint on the same computing node, to further optimise the evaluation of tightly coupled actors.



Initial Actors
--------------

Initial actors are to be created directly from the simulation case, and their creation must be synchronous, otherwise there could be a race condition between the moment they are all up and ready and the moment at which the simulation starts.

There must be at least one initial actor, as otherwise the simulation will stop as soon as started, since it will detect that no event at all can possibly happen anymore.


With Agnostic Actor Placement
.............................


The actual creation is in this case done thanks to the ``class_Actor:create_initial_actor/2`` static method, whose API is identical in the centralised and distributed branches.

For example, if wanting to create an initial soda vending machine (``class_SodaVendingMachine``), whose constructor takes two parameters (its name and its initial stock of cans), then one has simply to use, before the simulation is started:

.. code-block:: erlang

 ...
 VendingMachinePid = class_Actor:create_initial_actor(
   class_SodaVendingMachine, [ _Name="My machine", _CanCount=15 ] ),
 ...
 % Now simulation can be started.


An additional static method, ``class_Actor:create_initial_actor/3``, is available, the third parameter being the PID of an already-retrieved load balancer. This allows, when creating a large number of initial actors, to retrieve the load balancer once for all, instead of looking it up again and again, at each ``class_Actor:create_initial_actor/2`` call.


For example:

.. code-block:: erlang

 ...
 LoadBalancerPid = class_LoadBalancer:get_balancer(),
 ...

 FirstVendingMachinePid = class_Actor:create_initial_actor(
	   class_SodaVendingMachine, [ _Name="My first machine",
		  _FirstCanCount=15 ],
	   LoadBalancerPid ),
 ...
 SecondVendingMachinePid = class_Actor:create_initial_actor(
	   class_SodaVendingMachine, [ "My second machine",
		  _SecondCanCount=8 ],
	   LoadBalancerPid ),
 ...
 % Now simulation can be started.



Full examples can be found in:

- ``scheduling_one_initial_terminating_actor_test.erl``
- ``scheduling_one_initial_non_terminating_actor_test.erl``



Based On A Placement Hint
.........................

The same kind of calls as previously can be used, with an additional parameter, which is the placement hint, which can be any Erlang term chosen by the developer.

In the following example, first and second vending machines should be placed on the same computing node (having the same hint), whereas the third vending machine may be placed on any node:

.. code-block:: erlang

 ...
 FirstVendingMachinePid = class_Actor:create_initial_placed_actor(
	class_SodaVendingMachine, [ "My first machine", _CanCount=15 ]
	my_placement_hint_a ),
 ...
 % Using now the variation with an explicit load balancer:
 % (only available in the distributed case)
 LoadBalancerPid = class_LoadBalancer:get_balancer(),
 ...

 SecondVendingMachinePid = class_Actor:create_initial_placed_actor(
	   class_SodaVendingMachine, [ "My second machine",
		 _SecondCanCount=0 ],
	   LoadBalancerPid, my_placement_hint_a ),
 ...
 ThirdVendingMachinePid = class_Actor:create_initial_actor(
	   class_SodaVendingMachine, [ "My third machine",
		 _ThirdCanCount=8 ],
	   LoadBalancerPid, my_placement_hint_b ),
 ...
 % Now simulation can be started.


In a centralised version, placement hints are simply ignored.

Full examples can be found in ``scheduling_initial_placement_hint_test.erl``.



Simulation-Time Actors
----------------------

These actors are created in the course of the simulation.

Such actors can *only* be created by other (pre-existing) actors, otherwise the uncoupling of real time and simulated times would be jeopardised. Thus once the simulation is started it is the only way of introducing new actors.

As before, actors can be created with or without placement hints.


With Agnostic Actor Placement
.............................

An actor A needing to create another one (B) should use the ``class_Actor:create_actor/3`` helper function.

For example:

.. code-block:: erlang

 ...
 CreatedState = class_Actor:create_actor(
		_CreatedClassname=class_PinkFlamingo,
		[_Name="Ringo",_Age=34], CurrentState ),
 ...


If actor A calls this function at a simulation timestamp {T,D}, then B will be created at the next diasca (hence at {T,D+1}) and A will be notified of it at {T,D+2}.

Indeed the load balancer will process the underlying actor creation message (which is an actor oneway) at {T,D+1} and will create immediately actor B, whose PID will be notified to A thanks to another actor oneway, ``onActorCreated/5``, sent on the same diasca. This message will then be processed by A at {T,D+2}, for example:

.. code-block:: erlang

 onActorCreated( State, CreatedActorPid,
				ActorClassName=class_PinkFlamingo,
				ActorConstructionParameters=[ "Ringo", 34 ],
				LoadBalancerPid ) ->
 % Of course this oneway is usually overridden, at least
 % to record the PID of the created actor and/or to start
 % interacting with it.



Based On A Placement Hint
.........................

An actor A needing to create another one (B) while specifying a placement hint should simply use the ``class_Actor:create_placed_actor/4`` helper function for that.

Then the creation will transparently be done according to the placement hint, and the ``onActorCreated/5`` actor oneway will be triggered back on the side of the actor which requested this creation, exactly as in the case with no placement hint.



How Constructors of Actors Are To Be Defined?
=============================================

Actor classes are to be defined like any WOOPER classes (of course they have to inherit, directly or not, from ``class_Actor``), except that their first construction parameter must be their actor settings.

These settings (which include the actor's AAI, for *Abstract Actor Identifier*) will be specified automatically by the engine, and should be seen as opaque information just to be transmitted to the parent constructor(s).

All other parameters (if any) are call *actual parameters*.

For example, a ``Foo`` class may define a constructor as:

.. code:: erlang

 -spec construct(wooper:state(),actor_settings(),T1(), T2()) ->
		  wooper:state().
 construct(State,ActorSettings,FirstParameter,SecondParameter) ->
	[...]


Or course, should this class take no specific actual construction parameter, we would have had:

.. code:: erlang

 -spec construct(wooper:state(),actor_settings()) -> wooper:state().
 construct(State,ActorSettings) ->
	[...]


The creation of an instance will require all actual parameters to be specified by the caller (since the actor settings will be determined and assigned by the simulation engine itself).

For example:

.. code-block:: erlang

 ...
 MyFooPid = class_Actor:create_initial_actor( class_Foo,
	[ MyFirstParameter, MySecondParameter] ),
 % Actor settings will be automatically added at creation-time
 % by the engine.

For a complete example, see ``class_TestActor.erl``.


.. Note:: No message of any sort shall be sent by an actor to another one from its constructoir; see `Common Pitfalls`_ for more information.




How Actors Can Define Their Spontaneous Behaviour?
==================================================

They just have to override the default implementation of the ``class_Actor:actSpontaneous/1`` oneway.

The simplest of all spontaneous behaviour is to do nothing at all:

.. code:: erlang

 actSpontaneous(State) ->
	State.

For a complete example, see ``class_TestActor.erl``.



How Actors Are To Interact?
===========================

Actors must *only* interact based on ``actor messages`` (ex: using directly Erlang messages or WOOPER ones is *not* allowed), as otherwise even essential simulation properties could not be preserved.

Thus the ``class_Actor:send_actor_message/3`` helper function should be used for each and every inter-actor communication (see the function header for a detailed usage information).

As a consequence, only actor oneways are to be used, and if an actor A sends an actor message to an actor B at simulation timestamp ``{T,D}``, then B will process it at tick ``{T,D+1}``, i.e. at the next diasca (that will be automatically scheduled).

Requests, i.e. a message sent from an actor A to an actor B (the question), to be followed by a message being sent back from B to A (the answer), must be implemented based on a round-trip exchange of two actor oneways, one in each direction.

For example, if actor A wants to know the color of actor B, then:

- first at tick T, diasca D, actor A sends an actor message to B, ex: ``SentState = class_Actor:send_actor_message( PidOfB, getColor, CurrentState ), ...`` (probably from its ``actSpontaneous/1`` oneway)

- then, at diasca D+1, the ``getColor(State,SenderPid)`` oneway of actor B is triggered, in the body of which B should send, as an answer, a second actor message, back to A: ``AnswerState = class_Actor:send_actor_message(SenderPid, {beNotifiedOfColor,red}, CurrentState)``; here ``SenderPid`` corresponds to the PID of A and we suppose that the specification requires the answer to be sent immediately by B (as opposed to a deferred answer that would have to be sent after a duration corresponding to some number of ticks)

- then at diasca D+2 actor A processes this answer: its ``beNotifiedOfColor( State, Color, SenderPid )`` oneway is called, and it can react appropriately; here ``Color`` could be ``red``, and ``SenderPid`` corresponds to the PID of B


Finally, the only licit case involving the direct use of a WOOPER request (instead of an exchange of actor messages) in Sim-Diasca occurs before the simulation is started.

This is useful typically whenever the simulation case needs to interact with some initial actors [#]_ or when two initial actors have to communicate, in both cases *before* the simulation is started.

.. [#] For example requests can be used to set up the connectivity between initial actors, i.e. to specify which actor shall be aware of which, i.e. shall know its PID.



How Actor Oneways Shall be Defined?
===================================

An actor oneway being a special case of a WOOPER oneway, it behaves mostly the same (ex: it is to return a state, and no result shall be expected from it) but, for clarity, it is to rely on its own type specifications and method terminators.

In terms of *type specification*, an actor oneway shall use:

- either, if being a const actor oneway: ``actor_oneway_return/0``
- otherwise (non-const actor oneway): ``const_actor_oneway_return/0``


In terms of *implementation*, similarly, each of its clauses, shall use:

- either, if being a const clause: ``actor:const_return/0``
- otherwise (non-const clause): ``actor:return_state/1``


As an example:

.. code:: erlang

 % This actor oneway is not const, as not all its clauses are const:
 -spec notifySomeEvent(wooper:state(),a_type(),other_type(),
					   sending_actor_pid()) -> actor_oneway_return().
 % A non-const clause to handle fire-related events:
 notifySomeEvent(State,_FirstValue=fire_event,SecondValue,_SendingActorPid) ->
	 [...]
	 actor:return_state(SomeFireState);

 % A const clause to handle other events (through side-effects only):
 notifySomeEvent(State,_FirstValue,_SecondValue,_SendingActorPid) ->
	 [...]
	 actor:const_return_state().


Note that we also recommend to follow the conventions used above regarding the typing of the last parameter (``sending_actor_pid()``) and the name of its (often muted) associated value (``SendingActorPid``).



How to Handle Actors Needing to Exchange a Larger Volume of Data?
=================================================================

First of all, such Erlang terms shall be made as compact as possible: data duplication shall be avoided, identifiers (such as atoms or integers) shall be used to designate elements rather than copying them, plain strings shall be replaced with binary ones, more compact compounding types (e.g. tuples instead of maps) shall be preferred, etc.

Is the data static and can be defined either at build-time or at runtime, when starting the simulator? Then Myriad's "const" facilities (e.g. ``const_table``, ``const_bijective_table``, ``const_bijective_topics``) may be of help; also, static or infrequently-changing data may be handled thanks to the Erlang ``persistent_term`` module.

If the data is dynamic, yet is identical for many actors, ``class_DataExchanger`` may then be of help.

Finally, having larger, dynamic, specific (per-actor) data to be exchanged is not necessarily a problem in a distributed context: they should just be co-allocated (that is: instantiated on the same Erlang node, and thus host) by specifying the same placement hint when creating them.

See also the next section for more specific communication solutions.



How to Handle Less Classical Communication Schemes?
===================================================

While oneway messages constitute a universal paradigm in order to communicate inside the simulation (hence between actors), in a case where one-to-many communication is to occur, relying on a standard actor or even a set thereof (ex: as a pool to even the load, or as for example a 3D environment split into a binary space partitioning scheme, with one actor per cell) may be suboptimal.

Should the same message have to be sent from one actor to many, one may have a look to ``class_BroadcastingActor``, a specialised actor designed for that use case.

Also, using the data-exchanger service (see ``class_DataExchanger``) may be of help, keeping in mind that this is a data-management service (not a specific kind of actor) that is updated between diascas.

As for communication that is “pure result” (produced by an actor, but not read by any of them), data may be sent immediately out of the simulation, either directly (as fire and forget), or with some flow control (should there be a risk that the simulation overwhelms the targeted data sink).



How Actors Are To Be Deleted?
=============================

Actors are to be deleted either in the course of the simulation or after the simulation is over.

In all cases their deletion must be managed through the simulation engine, not directly by the user (ex: sending  WOOPER ``delete`` messages is *not* allowed), as otherwise even essential simulation properties could not be preserved.

The recommended way of deleting an actor is to have it trigger its own deletion process. Indeed this requires at least that actor to notify all other actors that may interact with it that this should not happen anymore.

Once they are notified, this actor (possibly on the same tick at which it sent these notifications) should execute its ``declareTermination/{1,2}`` oneway (or the ``class_Actor:declare_termination/{1,2}`` helper function), for example from  ``actSpontaneous/1``:

.. code:: erlang

 ...
 TerminatingState = executeOneway( CurrentState,  declareTermination),
 ...


See ``class_TestActor.erl`` for an example of complex yet proper coordinated termination, when a terminating actor knows other actors and is known by other actors.

See also the ``Sim-Diasca Developer Guide``.



How Requests Should Be Managed From A Simulation Case?
======================================================

As already explained, direct WOOPER calls should not be used to modify the state of the simulation once it has been started, as we have to let the simulation layer have full control over the exchanges, notably so that they can be reordered.

However requests can be used *before* the simulation is started.

For example we may want to know, from the simulation case, what the initial time will be, like in:

.. code-block:: erlang

 TimeManagerPid ! {getTextualTimings,[],self()},
 receive

	{wooper_result,TimingString} when is_list(TimingString) ->
		?test_info_fmt("Initial time is ~s.",[TimingString])

 end,
 ...


The ``is_list/1`` guard would be mandatory here, as other messages may spontaneously be sent to the simulation case [#]_.


.. [#] Typically the trace supervisor will send ``{wooper_result,monitor_ok}`` messages to the simulation case whenever the user closes the window of the trace supervision tool, which can happen at any time: without the guard, we could then have  ``TimingString`` be unfortunately bound to ``monitor_ok``, instead of the expected timing string returned by the ``getTextualTimings`` request.


However, specifying, at each request call issued from the simulation case, a proper guard is tedious and error-prone, so a dedicated, safe function is provided for that by the engine, ``test_receive/0``; thus the previous example should be written that way instead:

.. code-block:: erlang

	TimeManagerPid ! {getTextualTimings,[],self()},
	TimingString = test_receive(),
	?test_info_fmt("Received time: ~s.",[TimingString]),
	...


This ``test_receive/0`` function performs a (blocking) selective receive, retrieving any WOOPER result which is *not* emanating directly from the operation of the engine itself. That way, developers of simulation cases can reliably retrieve the values returned by the requests they send, with no fear of interference.



How Should I run larger simulations?
====================================


Larger simulations are more difficult to run, notably because they are generally distributed and because they tend to exhaust various resources.


Testing in a Simple Case
------------------------

A good first step is to ensure that, in the target hardware and software setting, the intended simulation is already able to run in a small scale from begin to end, first on a single host then, if targeted, on an increasing number of hosts (see the `distributed gotchas`_ for that).

Ensure that only the safest choices are made (e.g. have a properly-configured DNS, fix permissions, rely on a normal user - not root, etc.). Investigate any network-related issue with `such checkings <https://olivier-boudeville.github.io/Ceylan-Myriad/#testing-troubleshooting>`_.



Enabling the ``production`` Execution Target
--------------------------------------------

If, for a given simulation, more than a few nodes are needed, then various preventive measures shall be taken in order to be ready to go to further scales (typically disabling most `simulation traces`_, extending key time-outs, etc.).

For that the ``EXECUTION_TARGET`` compile-time overall flag has been defined. Its default value is ``development`` (simulations will not be really scalable, but a good troubleshooting support will be provided), but if you set it to ``production``, then all settings for larger simulations will be applied.

It is a compile-time option, hence it must be applied when building Sim-Diasca and the layers above; thus one may run, from the root:

.. code:: bash

 $ make clean all EXECUTION_TARGET=production

to prepare for any demanding run.

One may instead set ``EXECUTION_TARGET=production`` once for all, typically in ``myriad/GNUmakevars.inc``, however most users prefer to go back and forth between the execution target settings (as traces, shorter time-outs etc. are very useful for developing and troubleshooting), using the command-line to switch.

It is even possible to compile everything in production mode, touch the source files that one wants to be still talkative (``touch some_module.erl``) and run just ``make all`` for the root: all touched module (and only them) will be then recompiled with the default execution target, by default the ``development`` one.


Circumventing any System Limit
------------------------------

Many GNU/Linux operating systems enforce various limits onto the resources that one application may use (RAM, file descriptors, cores, etc.).

Notably, UNIX processes that are considered using "too much" RAM might be killed by the operating system far before exhausting this memory.

The ``ulimit`` command and the configuration of the Linux kernel capabilities may be of interest then.

Containerization / OS-level virtualization (e.g. Docker, Singularity) may also have an impact.



Increasing the Maximum Number of Erlang Processes
-------------------------------------------------

The Erlang default limit is only 32768 processes, but Sim-Diasca relies on the ``myriad/src/scripts/launch-erl.sh`` script to launch its user VM, and this script enforces a larger limit (of a few thousands; refer to its ``max_process_count`` variable).

One may set the ``MAX_PROCESS_COUNT`` make variable (defined in ``myriad/GNUmakevars.inc``) to set that process limit to any value of interest.



Monitoring Resources
--------------------

Any tool to track resource usage (at least CPU, RAM, swap) on the target host(s), at the level of the operating system will certainly be of use.

Regarding Erlang itself (notably its VM), the ``observer`` application provides also invaluable runtime information.



Monitoring Traces and Logs
--------------------------

The Sim-Diasca traces are an invaluable means of tracking the course of a given simulation; error-like severities will always be enabled (even in production mode).

In case of a runtime problem, one should investigate also the main log files of the operating system (typically thanks to ``journalctl``), as many events can happen (OOM - *Out of Memory*, the Sim-Diasca main process being killed process due to some limit being reached, a container enforcing some constraint, etc.).
