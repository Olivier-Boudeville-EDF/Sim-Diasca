<?xml version="1.0" encoding="utf-8" ?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="Docutils 0.13.1: http://docutils.sourceforge.net/" />
<title>Technical Manual of the Sim-Diasca Simulation Engine</title>
<meta content="Sim-Diasca, massive, simulation, multi-agent, development" name="keywords" />
<link rel="stylesheet" href="pygments-default.css" type="text/css" />
<link rel="stylesheet" href="sim-diasca.css" type="text/css" />
<link href="sim-diasca-icon.png" rel="icon">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
</head>
<body>
<div class="document" id="technical-manual-of-the-sim-diasca-simulation-engine">
<h1 class="title">Technical Manual of the <strong>Sim-Diasca</strong> Simulation Engine</h1>

<p><span class="raw-html"><a name="sim_diasca_top"></a></span></p>
<p><span class="raw-html"><center><table><tr colspan="2"><center><img src="sim-diasca.png" style="width:500px"></tr><tr><td><center><img src="logo-EDF-english.png" style="width:150px"></td><td><center><img src="lgpl-v3-logo-bordered.png" style="width:140px"></td></tr></table></span></p>
<p></p>
<p><span class="raw-html"><div class="banner"><p><em>Sim-Diasca Technical Manual</em> <a href="https://olivier-boudeville-edf.github.io/Sim-Diasca/">browse latest</a> <a href="Sim-Diasca-technical-manual-english.pdf">get PDF</a> <a href="#sim_diasca_top">go to top</a> <a href="#sim_diasca_toc">go to toc</a> <a href="#sim_diasca_bottom">go to bottom</a> <a href="api-doc/index.html">browse API</a> <a href="https://github.com/Olivier-Boudeville-EDF/Sim-Diasca/">go to project</a> <a href="mailto:olivier(dot)boudeville(at)edf(dot)fr?subject=[Sim-Diasca]%20Remark">email us</a></p></div></span></p>
<table class="docutils field-list" frame="void" rules="none">
<col class="field-name" />
<col class="field-body" />
<tbody valign="top">
<tr class="field"><th class="field-name">Organisation:</th><td class="field-body">Copyright (C) 2008-2023 EDF R&amp;D</td>
</tr>
<tr class="field"><th class="field-name">Author:</th><td class="field-body">Olivier Boudeville</td>
</tr>
<tr class="field"><th class="field-name">Contact:</th><td class="field-body">olivier (dot) boudeville (at) edf (dot) fr</td>
</tr>
<tr class="field"><th class="field-name">Creation date:</th><td class="field-body">Monday, February 8, 2010</td>
</tr>
<tr class="field"><th class="field-name">Lastly updated:</th><td class="field-body">Thursday, January 5, 2023</td>
</tr>
<tr class="field"><th class="field-name">Version:</th><td class="field-body">2.4.5</td>
</tr>
<tr class="field"><th class="field-name">Status:</th><td class="field-body">Stable</td>
</tr>
<tr class="field"><th class="field-name">Website:</th><td class="field-body"><a class="reference external" href="http://sim-diasca.com">http://sim-diasca.com</a></td>
</tr>
<tr class="field"><th class="field-name">Dedication:</th><td class="field-body">For people interested in the inner workings of the <cite>Sim-Diasca</cite> simulation engine.</td>
</tr>
<tr class="field"><th class="field-name">Abstract:</th><td class="field-body">The main design choices of the simulation engine are discussed here, from the requirements to the implementation, including the software architecture and the algorithmic approach. Its recommended use is also described.</td>
</tr>
</tbody>
</table>
<p><span class="raw-html"></center></span></p>
<p></p>
<p><span class="raw-html"><a name="sim_diasca_toc"></a></span></p>
<div class="contents topic" id="table-of-contents">
<p class="topic-title first"><strong>Table of Contents</strong></p>
<ul class="simple">
<li><a class="reference internal" href="#overview-context" id="id153">Overview &amp; Context</a><ul>
<li><a class="reference internal" href="#sim-diasca" id="id154">Sim-Diasca</a></li>
<li><a class="reference internal" href="#current-status" id="id155">Current Status</a></li>
<li><a class="reference internal" href="#minimal-quick-start-for-early-technical-testing" id="id156">Minimal Quick-Start For Early Technical Testing</a></li>
</ul>
</li>
<li><a class="reference internal" href="#how-to-read-this-manual" id="id157">How to Read This Manual</a></li>
<li><a class="reference internal" href="#let-s-start-with-a-short-ontology" id="id158">Let's Start With A Short Ontology</a><ul>
<li><a class="reference internal" href="#what-is-an-ontology" id="id159">What is an Ontology?</a></li>
<li><a class="reference internal" href="#simulation-concepts-in-relation" id="id160">Simulation Concepts in Relation</a></li>
<li><a class="reference internal" href="#simulation-terms-defined" id="id161">Simulation Terms Defined</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-specifications" id="id162">Sim-Diasca Specifications</a><ul>
<li><a class="reference internal" href="#simulator-potential-role" id="id163">Simulator Potential Role</a></li>
<li><a class="reference internal" href="#simulator-potential-context-of-use" id="id164">Simulator Potential Context of Use</a></li>
<li><a class="reference internal" href="#functional-technical-requirements" id="id165">Functional &amp; Technical Requirements</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-functional-coverage" id="id166">Sim-Diasca Functional Coverage</a></li>
<li><a class="reference internal" href="#modelling-approach" id="id167">Modelling Approach</a><ul>
<li><a class="reference internal" href="#questions-metrics-models" id="id168">Questions, Metrics &amp; Models</a></li>
<li><a class="reference internal" href="#implementation-of-models" id="id169">Implementation Of Models</a></li>
</ul>
</li>
<li><a class="reference internal" href="#a-short-overview-of-simulation-services" id="id170">A Short Overview of Simulation Services</a></li>
<li><a class="reference internal" href="#sim-diasca-time-management-explained" id="id171">Sim-Diasca Time Management Explained</a><ul>
<li><a class="reference internal" href="#some-general-technical-considerations-first" id="id172">Some General Technical Considerations First</a></li>
<li><a class="reference internal" href="#preservation-of-properties" id="id173">Preservation of Properties</a></li>
<li><a class="reference internal" href="#approaches-to-time-management" id="id174">Approaches to Time Management</a></li>
<li><a class="reference internal" href="#sim-diasca-time-management-algorithm" id="id175">Sim-Diasca Time Management Algorithm</a></li>
<li><a class="reference internal" href="#how-virtual-time-is-managed" id="id176">How Virtual Time is Managed</a></li>
<li><a class="reference internal" href="#in-depth-scheduling-implementation" id="id177">In-Depth: Scheduling Implementation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-management-of-probabilistic-laws" id="id178">Sim-Diasca Management of Probabilistic Laws</a><ul>
<li><a class="reference internal" href="#principles" id="id179">Principles</a></li>
<li><a class="reference internal" href="#built-in-random-distributions" id="id180">Built-in Random Distributions</a></li>
<li><a class="reference internal" href="#user-specified-random-distributions" id="id181">User-Specified Random Distributions</a></li>
<li><a class="reference internal" href="#actual-management-of-randomness" id="id182">Actual Management of Randomness</a></li>
<li><a class="reference internal" href="#randomness-pitfalls" id="id183">Randomness Pitfalls</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-management-of-simulation-inputs" id="id184">Sim-Diasca Management of Simulation Inputs</a><ul>
<li><a class="reference internal" href="#id32" id="id185">Principles</a></li>
<li><a class="reference internal" href="#requirements" id="id186">Requirements</a></li>
<li><a class="reference internal" href="#creation-of-the-initial-state-of-the-simulation" id="id187">Creation of the Initial State of the Simulation</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-management-of-simulation-outputs" id="id188">Sim-Diasca Management of Simulation Outputs</a><ul>
<li><a class="reference internal" href="#id41" id="id189">Principles</a></li>
<li><a class="reference internal" href="#managing-the-outputs" id="id190">Managing The Outputs</a></li>
<li><a class="reference internal" href="#result-generation" id="id191">Result Generation</a></li>
<li><a class="reference internal" href="#post-processing-the-results" id="id192">Post-Processing the Results</a></li>
<li><a class="reference internal" href="#interpreting-the-outcome" id="id193">Interpreting the Outcome</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-reliability" id="id194">Sim-Diasca Reliability</a><ul>
<li><a class="reference internal" href="#context" id="id195">Context</a></li>
<li><a class="reference internal" href="#a-tunable-resilience-service" id="id196">A Tunable Resilience Service</a></li>
<li><a class="reference internal" href="#id54" id="id197">Mode of Operation</a></li>
<li><a class="reference internal" href="#testing" id="id198">Testing</a></li>
<li><a class="reference internal" href="#future-improvements" id="id199">Future Improvements</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-technical-architecture" id="id200">Sim-Diasca Technical Architecture</a><ul>
<li><a class="reference internal" href="#general-view" id="id201">General View</a></li>
<li><a class="reference internal" href="#supported-platforms" id="id202">Supported Platforms</a></li>
<li><a class="reference internal" href="#tools-for-the-sim-diasca-simulation-engine-itself" id="id203">Tools For the Sim-Diasca Simulation Engine Itself</a></li>
<li><a class="reference internal" href="#complementary-tools" id="id204">Complementary Tools</a></li>
<li><a class="reference internal" href="#other-tools" id="id205">Other Tools</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-building-blocks" id="id206">Sim-Diasca Building Blocks</a><ul>
<li><a class="reference internal" href="#id72" id="id207">Simulation Traces</a></li>
<li><a class="reference internal" href="#id78" id="id208">Probes</a></li>
<li><a class="reference internal" href="#id82" id="id209">Data-Logger</a></li>
<li><a class="reference internal" href="#id85" id="id210">Console Tracker</a></li>
<li><a class="reference internal" href="#id88" id="id211">Data Exchanger</a></li>
<li><a class="reference internal" href="#spatialised-support" id="id212">Spatialised Support</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-helper-tools" id="id213">Sim-Diasca Helper Tools</a><ul>
<li><a class="reference internal" href="#performance-tracker" id="id214">Performance Tracker</a></li>
<li><a class="reference internal" href="#post-processing-services" id="id215">Post-Processing Services</a></li>
<li><a class="reference internal" href="#plugin-infrastructure" id="id216">Plugin Infrastructure</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-modelling-guide" id="id217">Sim-Diasca Modelling Guide</a><ul>
<li><a class="reference internal" href="#objective-context" id="id218">Objective &amp; Context</a></li>
<li><a class="reference internal" href="#basics-of-simulation-operation-mode" id="id219">Basics Of Simulation Operation Mode</a></li>
<li><a class="reference internal" href="#main-choices-in-terms-of-actor-modelling" id="id220">Main Choices In Terms Of Actor Modelling</a></li>
<li><a class="reference internal" href="#modelling-process" id="id221">Modelling Process</a></li>
</ul>
</li>
<li><a class="reference internal" href="#validating-the-resulting-simulators" id="id222">Validating The Resulting Simulators</a></li>
<li><a class="reference internal" href="#sim-diasca-cheat-sheet" id="id223">Sim-Diasca Cheat Sheet</a><ul>
<li><a class="reference internal" href="#which-sim-diasca-version-should-be-used" id="id224">Which Sim-Diasca Version Should Be Used?</a></li>
<li><a class="reference internal" href="#how-can-we-run-a-simulation" id="id225">How Can We Run a Simulation?</a></li>
<li><a class="reference internal" href="#how-can-i-select-whether-a-simulation-run-shall-be-purely-local-or-distributed" id="id226">How Can I Select Whether A Simulation Run Shall be Purely Local, or Distributed?</a></li>
<li><a class="reference internal" href="#how-many-erlang-nodes-are-involved-in-a-simulation" id="id227">How Many Erlang Nodes Are Involved in a Simulation?</a></li>
<li><a class="reference internal" href="#what-constraints-shall-be-observed-in-order-to-run-in-a-distributed-manner-ex-on-a-cluster" id="id228">What Constraints shall be Observed in order to run in a Distributed Manner (ex: on a cluster)?</a></li>
<li><a class="reference internal" href="#what-are-the-most-common-gotchas-encountered-with-distributed-simulations" id="id229">What are the Most Common Gotchas encountered with Distributed Simulations?</a></li>
<li><a class="reference internal" href="#what-is-the-first-tick-offset-of-a-simulation" id="id230">What is the First Tick Offset of a Simulation?</a></li>
<li><a class="reference internal" href="#what-is-the-first-diasca-of-a-given-tick-t" id="id231">What is the First Diasca of a given Tick T?</a></li>
<li><a class="reference internal" href="#how-a-simulation-starts" id="id232">How a Simulation Starts?</a></li>
<li><a class="reference internal" href="#how-actors-are-to-be-created" id="id233">How Actors Are To Be Created?</a></li>
<li><a class="reference internal" href="#how-constructors-of-actors-are-to-be-defined" id="id234">How Constructors of Actors Are To Be Defined?</a></li>
<li><a class="reference internal" href="#how-actors-can-define-their-spontaneous-behaviour" id="id235">How Actors Can Define Their Spontaneous Behaviour?</a></li>
<li><a class="reference internal" href="#how-actors-are-to-interact" id="id236">How Actors Are To Interact?</a></li>
<li><a class="reference internal" href="#how-actor-oneways-shall-be-defined" id="id237">How Actor Oneways Shall be Defined?</a></li>
<li><a class="reference internal" href="#how-to-handle-actors-needing-to-exchange-a-larger-volume-of-data" id="id238">How to Handle Actors Needing to Exchange a Larger Volume of Data?</a></li>
<li><a class="reference internal" href="#how-to-handle-less-classical-communication-schemes" id="id239">How to Handle Less Classical Communication Schemes?</a></li>
<li><a class="reference internal" href="#how-actors-are-to-be-deleted" id="id240">How Actors Are To Be Deleted?</a></li>
<li><a class="reference internal" href="#how-requests-should-be-managed-from-a-simulation-case" id="id241">How Requests Should Be Managed From A Simulation Case?</a></li>
<li><a class="reference internal" href="#how-should-i-run-larger-simulations" id="id242">How Should I run larger simulations?</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-troubleshooting" id="id243">Sim-Diasca Troubleshooting</a><ul>
<li><a class="reference internal" href="#first-of-all-did-you-read-the-manuals" id="id244">First Of All: Did You Read The Manuals?</a></li>
<li><a class="reference internal" href="#troubleshooting-principles" id="id245">Troubleshooting Principles</a></li>
<li><a class="reference internal" href="#most-common-issues" id="id246">Most Common Issues</a></li>
<li><a class="reference internal" href="#common-misconceptions" id="id247">Common Misconceptions</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-support" id="id248">Sim-Diasca Support</a></li>
<li><a class="reference internal" href="#sim-diasca-changes" id="id249">Sim-Diasca Changes</a></li>
<li><a class="reference internal" href="#sim-diasca-future-enhancements" id="id250">Sim-Diasca Future Enhancements</a><ul>
<li><a class="reference internal" href="#general-requirements" id="id251">General Requirements</a></li>
<li><a class="reference internal" href="#id145" id="id252">Load Balancing</a></li>
<li><a class="reference internal" href="#reproducible-actor-identifiers" id="id253">Reproducible Actor Identifiers</a></li>
<li><a class="reference internal" href="#code-deployment" id="id254">Code Deployment</a></li>
<li><a class="reference internal" href="#performance-tuning" id="id255">Performance Tuning</a></li>
<li><a class="reference internal" href="#upstream-works" id="id256">Upstream Works</a></li>
<li><a class="reference internal" href="#miscellaneous" id="id257">Miscellaneous</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-hints" id="id258">Sim-Diasca Hints</a><ul>
<li><a class="reference internal" href="#common-pitfalls" id="id259">Common Pitfalls</a></li>
<li><a class="reference internal" href="#good-practices" id="id260">Good Practices</a></li>
<li><a class="reference internal" href="#lesser-known-features" id="id261">Lesser-Known Features</a></li>
<li><a class="reference internal" href="#other-useful-information" id="id262">Other Useful Information</a></li>
<li><a class="reference internal" href="#tips-and-tricks" id="id263">Tips And Tricks</a></li>
</ul>
</li>
<li><a class="reference internal" href="#sim-diasca-bibliography" id="id264">Sim-Diasca Bibliography</a></li>
<li><a class="reference internal" href="#sim-diasca-credits" id="id265">Sim-Diasca Credits</a></li>
<li><a class="reference internal" href="#sim-diasca-license" id="id266">Sim-Diasca License</a></li>
<li><a class="reference internal" href="#contributing-to-sim-diasca" id="id267">Contributing To Sim-Diasca</a></li>
<li><a class="reference internal" href="#what-to-do-next" id="id268">What To Do Next?</a></li>
</ul>
</div>
<p></p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Before reading this document, we strongly advise to have a look first at the slides of the general-purpose presentation of Sim-Diasca.</p>
</div>
<div class="section" id="overview-context">
<h1><a class="toc-backref" href="#id153">Overview &amp; Context</a></h1>
<div class="section" id="sim-diasca">
<h2><a class="toc-backref" href="#id154">Sim-Diasca</a></h2>
<p><strong>Sim-Diasca</strong> stands for <cite>Simulation of Discrete Systems of All Scales</cite>.</p>
<p>Sim-Diasca is a lightweight simulation platform, released by EDF R&amp;D under the GNU <a class="reference internal" href="#lgpl">LGPL</a> licence, offering a set of simulation elements, including notably a simulation engine, to be applied to the simulation of discrete event-based systems made of potentially very numerous interacting parts.</p>
<p>This class of simulation encompasses a wide range of target systems, from ecosystems to information systems, i.e. it could be used for most applications in the so-called <a class="reference external" href="http://en.wikipedia.org/wiki/Complex_systems">Complex systems</a> scientific field.</p>
<p>Before entering in the details of the present manual, we recommend the reader to go first through the <a class="reference external" href="https://raw.githubusercontent.com/wiki/Olivier-Boudeville-EDF/Sim-Diasca/documents/sim-diasca-general-purpose-english.pdf">Sim-Diasca general-purpose presentation</a> in order to benefit from a general overview.</p>
<p>As a matter of fact, a classical use case for Sim-Diasca is the simulation of industrial distributed systems federating a large number of networked devices.</p>
<p>The simulation elements provided by Sim-Diasca are mainly <em>base models</em> and <em>technical components</em>.</p>
<p><strong>Models</strong> are designed to reproduce key behavioural traits of various elements of the system, notably business-specific objects, regarding a specific concern, i.e. a matter on which the simulator must provide an answer. An instance of a model is called here an <em>actor</em>. A simulation involves actors to be driven by a specific scenario implemented thanks to a <em>simulation case</em>.</p>
<p>Sim-Diasca includes built-in base models that can be further specialized to implement the actual business objects that are to be simulated.</p>
<p><strong>Technical components</strong> allow the simulator to operate on models, so that their state and behaviour can be evaluated appropriately, in the context of the execution of an actual simulation.</p>
<p>Depending on the conventions that models and technical components respect, different properties of the simulation can be expected.</p>
<p>Thus the first question addressed in the context of Sim-Diasca has been the specification of the simulation needs that should be covered, i.e. its functional requirements.</p>
<p>Then, from these requirements, a relevant set of technical measures has been determined and then implemented.</p>
</div>
<div class="section" id="current-status">
<h2><a class="toc-backref" href="#id155">Current Status</a></h2>
<p>Sim-Diasca and the first simulators making use of it are works in progress since the beginning of 2008, and the efforts dedicated to them remained light yet steady.</p>
<p>The Sim-Diasca engine is already fully functional <a class="footnote-reference" href="#id2" id="id1">[1]</a> on GNU/Linux platforms, and provides all the needed basic underlying simulation mechanisms to model and run full simulations on various hardware solutions.</p>
<p>A set of models, specifically tied to the first two business projects making use of Sim-Diasca, have been developed successfully on top of it, and the corresponding business results were delivered appropriately to stakeholders.</p>
<table class="docutils footnote" frame="void" id="id2" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id1">[1]</a></td><td>This is also a great pun, as the simulator is implemented thanks to the <a class="reference external" href="http://www.erlang.org">Erlang</a> language which, in terms of programming paradigm, is a <em>functional</em> language.</td></tr>
</tbody>
</table>
<p>Some further enhancements to the Sim-Diasca engine are to be implemented (see <a class="reference internal" href="#sim-diasca-future-enhancements">Sim-Diasca Future Enhancements</a>).</p>
</div>
<div class="section" id="minimal-quick-start-for-early-technical-testing">
<h2><a class="toc-backref" href="#id156">Minimal Quick-Start For Early Technical Testing</a></h2>
<p>For the fearless users wanting an early glance at Sim-Diasca in action, here is the shortest path to testing, provided you already have the prerequisites (including a well-compiled, recent, Erlang interpreter on a GNU/Linux box) installed.</p>
<p>First, download the latest stable archive, for example: <tt class="docutils literal"><span class="pre">Sim-Diasca-x.y.z.tar.bz2</span></tt>.</p>
<p>Extract it: <tt class="docutils literal">tar xvjf <span class="pre">Sim-Diasca-x.y.z.tar.bz2</span></tt>.</p>
<p>Build it: <tt class="docutils literal">cd <span class="pre">Sim-Diasca-x.y.z</span> &amp;&amp; make all</tt>.</p>
<p>Select your test case: <tt class="docutils literal">cd <span class="pre">sim-diasca/src/core/src/scheduling/tests/</span></tt>, for example: <tt class="docutils literal">scheduling_multiple_coupled_erratic_actors_test.erl</tt>.</p>
<p>Optionally, if you want to run a <em>distributed</em> simulation, create in the current directory a file named <tt class="docutils literal"><span class="pre">sim-diasca-host-candidates.txt</span></tt> which lists the computing hosts you want to take part to the simulation, with one entry by line, like (do not forget the final dot on each line):</p>
<pre class="code erlang literal-block">
<span class="p">{</span><span class="n">'hurricane.foobar.org'</span><span class="p">,</span> <span class="s">&quot;Computer of John (this is free text).&quot;</span><span class="p">}.</span>
</pre>
<p>Then run the test case:</p>
<pre class="code bash literal-block">
make scheduling_multiple_coupled_erratic_actors_run <span class="nv">CMD_LINE_OPT</span><span class="o">=</span><span class="s2">&quot;--batch&quot;</span>
</pre>
<p>The <tt class="docutils literal"><span class="pre">CMD_LINE_OPT=&quot;--batch&quot;</span></tt> option was added as, for the sake of this quick-start, the trace supervisor is not expected to have already been installed.</p>
<p>For the more in-depth reference installation instructions, refer to the <tt class="docutils literal"><span class="pre">Sim-Diasca</span> Installation Guide</tt>.</p>
</div>
</div>
<div class="section" id="how-to-read-this-manual">
<h1><a class="toc-backref" href="#id157">How to Read This Manual</a></h1>
<p><span class="raw-html"><center><center><img src="xkcd-manuals.png" id="responsive-image-medium"></img></center></span>
</p>
<p></p>
</div>
<div class="section" id="let-s-start-with-a-short-ontology">
<h1><a class="toc-backref" href="#id158">Let's Start With A Short Ontology</a></h1>
<div class="section" id="what-is-an-ontology">
<h2><a class="toc-backref" href="#id159">What is an Ontology?</a></h2>
<p>As defined <a class="reference external" href="http://en.wikipedia.org/wiki/Ontology_%28information_science%29">here</a>, <em>an ontology formally represents knowledge as a set of concepts within a domain, and the relationships among those concepts. It can be used to reason about the entities within that domain and may be used to describe the domain.</em></p>
<p>We aim here to express a Sim-Diasca ontology about (discrete-time) simulations of complex systems, so that we can define relevant terms and share them once for all.</p>
</div>
<div class="section" id="simulation-concepts-in-relation">
<h2><a class="toc-backref" href="#id160">Simulation Concepts in Relation</a></h2>
<p>Many additional relations could be defined, we just concentrated on the most influencial ones. Each concept is defined in turn at the bottom of this diagram.</p>
<p></p>
</div>
<div class="section" id="simulation-terms-defined">
<h2><a class="toc-backref" href="#id161">Simulation Terms Defined</a></h2>
<p>The ontology is currently in a simpler form, the one of a glossary (terms, sorted alphabetically, and their definition).</p>
<p>The examples illustrating the definitions are taken from a hypothetical simulation case involving preys and predators (a typical use-case in this simulation domain).</p>
<dl class="docutils">
<dt>Abstraction</dt>
<dd>An <tt class="docutils literal">Abstraction</tt> is a simplification of elements of the
<tt class="docutils literal">Simulated World</tt> regarding traits of interest, i.e. how the
<tt class="docutils literal">Simulation</tt> should represent a part of the various elements to be
simulated. An <tt class="docutils literal">Abstraction</tt> is a <tt class="docutils literal">Schedulable</tt>.
Typically an <tt class="docutils literal">Abstraction</tt> is either a <tt class="docutils literal">Modlet</tt> or a
<tt class="docutils literal">Scenario</tt>.</dd>
<dt>Actor</dt>
<dd>An <tt class="docutils literal">Actor</tt> is an instance of a <tt class="docutils literal">Modlet</tt>.
For example: &quot;<em>This particular actor corresponds to this specific
prey that we wanted to introduce in previous simulations, the one
that is bound to be eaten first due to its starting location.</em>&quot;</dd>
<dt>Experiment settings</dt>
<dd>An <tt class="docutils literal">Experiment settings</tt> is a set of runtime static parameters
that applies to all instances of a given <tt class="docutils literal">Abstraction</tt> in the
context of a given experiment (i.e. <tt class="docutils literal">Simulation</tt>). Indeed, when
constructed, <tt class="docutils literal">Abstractions</tt> may accept a set of parameters that
will be common to all their instances for that simulation. It is a
way of overriding, at the level of a given simulation, the internal
constants ruling the <tt class="docutils literal">Abstraction</tt> behaviours. A key point is that
these parameters are <em>static</em>, i.e. that, on a given simulation,
they apply to all instances of a given <tt class="docutils literal">Abstraction</tt>, while
another simulation may rely on other experiment settings (the
default ones or other overriding parameters).
<tt class="docutils literal">Experiment settings</tt> are known in some simulations as
&quot;<em>strategies</em>&quot;.
For example an <tt class="docutils literal">Experiment settings</tt> may define various constants
that determine the efficiency of the technical elements making up a
kind of photovoltaic panel. All instances of the corresponding
<tt class="docutils literal">Modlet</tt> will share these <tt class="docutils literal">Experiment settings</tt>, but these
settings may differ from one simulation to another (ex: a given
technology could be made more cost-effective in another simulation
relying on a different context).</dd>
<dt>Model</dt>
<dd><tt class="docutils literal">Model</tt> designates primarily an overall system (often the
<tt class="docutils literal">Target system</tt> as a whole), like a city - even if in the
simulation there is no specific instance corresponding directly to
that name (ex: not even a <tt class="docutils literal">City</tt> <tt class="docutils literal">Modlet</tt> defined; for example a
city could be then represented in such a simulation just as a set of
building instances instead).
By extension a <tt class="docutils literal">Model</tt> may also be used as a synonym of <tt class="docutils literal">Modlet</tt>
(see next entry), an actual simplification of an element of the
<tt class="docutils literal">Target system</tt>. It is a type (like a class), from which instances
(<tt class="docutils literal">Actors</tt>) can be created; it then defines notably their state and
behaviour.
For example, &quot;<em>I am quite happy of the current predator model, it
behaves nicely compared to what experience tells us. See how its
instances are chasing these preys?</em>&quot;
As the target system, which is reproduced thanks to a collection of
modlet instances (second acception of <tt class="docutils literal">Model</tt>), can be itself seen
as a <tt class="docutils literal">Model</tt> (as defined in the first acception), the term may be
ambiguous in some contexts. In these cases, <tt class="docutils literal">Modlet</tt> should be
used only to designate the type of actors (the implemented,
disaggregated parts of this overall model), while <tt class="docutils literal">Model</tt> would be
used for more conceptual descriptions (that are not instantiated as
such).
When there is really little ambiguity, <tt class="docutils literal">Model</tt> may be used to
refer to <tt class="docutils literal">Modlet</tt>, but it is not encouraged.</dd>
<dt>Modlet</dt>
<dd>A <tt class="docutils literal">Modlet</tt> is an atomic sub-model of a simulation, i.e. a modeling
element that cannot be further simplified and corresponds directly
to a type that can be instantiated.
In following example there is no specific city instance as such:
“<em>This tiny model of San-Francisco involves only a few building
modlets, some road modlets and three bridge modlets.</em>”
A set of <tt class="docutils literal">Modlets</tt> may form a more general <tt class="docutils literal">Model</tt>, possibly the
overall one.</dd>
<dt>Probe</dt>
<dd>A <tt class="docutils literal">Probe</tt> is a producer of simulation results, based on
information made available by a set of <tt class="docutils literal">Abstractions</tt>.
For example, &quot;<em>I need to monitor how many preys are killed by
predators of this type. I will add a probe to track this
information</em>&quot;.
A probe may be fed by multiple abstractions.</dd>
<dt>Scenario</dt>
<dd>A <tt class="docutils literal">Scenario</tt> is a representation of the elements in the
<tt class="docutils literal">Simulated world</tt> that are outside of the <tt class="docutils literal">Target system</tt> but
that may influence it and/or possibly be influenced by it.
For example, &quot;<em>My monsoon scenario, once combined to your epizootic
scenario, shows unexpected results in terms of prey population.</em>&quot;
The set of all <tt class="docutils literal">Scenario</tt> instances form the <tt class="docutils literal">System context</tt>.</dd>
<dt>Scenario instance</dt>
<dd>A <tt class="docutils literal">Scenario instance</tt> is simply an instance of a <tt class="docutils literal">Scenario</tt>,
like an <tt class="docutils literal">Actor</tt> is an instance of <tt class="docutils literal">Modlet</tt>.
<tt class="docutils literal">Scenario instances</tt> and <tt class="docutils literal">Actors</tt> are technically managed the
same way; their difference lies in the viewpoint of the author of
the simulation, who can arbitarily set the limit between the system
of interest (the <tt class="docutils literal">Target system</tt>) and its surroundings
(<tt class="docutils literal">System context</tt>).</dd>
<dt>Schedulable</dt>
<dd>A <tt class="docutils literal">Schedulable</tt> designates any element that is driven, time-wise,
by a <tt class="docutils literal">Time manager</tt>, like <tt class="docutils literal">Abstractions</tt>.</dd>
<dt>Simulated world</dt>
<dd>The <tt class="docutils literal">Simulated world</tt> corresponds to the full set of
<tt class="docutils literal">Abstractions</tt> that are to be evaluated through the simulation;
the <tt class="docutils literal">Simulated world</tt> is the union of the <tt class="docutils literal">Target system</tt> and
its context (i.e. the <tt class="docutils literal">System context</tt>), i.e., respectively,
<tt class="docutils literal">Actors</tt> and <tt class="docutils literal">Scenario</tt> instances.
For example, &quot;<em>The simulated world is the whole savannah, including
fauna and flora.</em>&quot;</dd>
<dt>Simulation</dt>
<dd>A <tt class="docutils literal">Simulation</tt> corresponds to the execution of a
<tt class="docutils literal">Simulation case</tt>. It is an experiment typically done for
decision-making.</dd>
<dt>Simulation case</dt>
<dd>A <tt class="docutils literal">Simulation case</tt> is the specification of a <tt class="docutils literal">Simulation</tt>. This
encompasses:
- Technical settings, like the properties to be enforced for this
simulation (ex: reproducibility), the time-step to be used or the
list of the eligible computing hosts
- Domain-specific settings, like the description of the initial
state of the simulation or its various termination criteria
For example, &quot;<em>This predator / prey simulation case, which must run
on these following 3 computers, will rely on a 20 millisecond
timestep; it takes place in this kind of savannah and starts with 2
predators (that can mate) and 15 preys, on these specified
locations. This is the weather scenario that I want to apply. I want
the simulation to stop whenever either all animals are extinct or
the elapsed duration (in simulation time) reaches one century. In
terms of results, I want the simulation to keep track only of the
predator population and of the number of preys that are born in its
course.</em>&quot;</dd>
<dt>Simulation engine</dt>
<dd>The <tt class="docutils literal">Simulation engine</tt> is, among other roles, in charge of managing the virtual time of a simulation; by scheduling the various <tt class="docutils literal">Schedulable</tt> instances, it allows to enforce the properties expected from the simulation while making its (virtual) time progress, preferably in an efficient way. Typically a simulation engine includes a <tt class="docutils literal">Time manager</tt> service, which is a key feature thereof.</dd>
<dt>Simulation inputs</dt>
<dd>The <tt class="docutils literal">Simulation inputs</tt> correspond to the data that is needed for
the simulation to be ready to start. This encompasses notably the
description of its initial state, i.e. the data allowing defining
the state of the whole simulated world when the simulation is to
begin.</dd>
<dt>Simulation outputs</dt>
<dd>The <tt class="docutils literal">Simulation outputs</tt> regroup the simulation results and the
simulation traces (we consider here only <em>successful</em> simulations -
failed ones output errors and traces).</dd>
<dt>Simulation results</dt>
<dd>The <tt class="docutils literal">Simulation results</tt> are the main by-product of a simulation,
if not its only purpose. These are data that are computed based on
information provided by <tt class="docutils literal">Actors</tt> and <tt class="docutils literal">Scenario</tt> instances, at
various points in <tt class="docutils literal">Simulation time</tt>, and that are aggregated and
managed by <tt class="docutils literal">Probes</tt>.</dd>
<dt>Simulation time</dt>
<dd>There are at least two kinds of time that are useful in the context
of a simulation: the wall-clock (user) time (i.e. the one we,
humans, all experience) and the <tt class="docutils literal">Simulation time</tt> that is known of
the simulation, i.e. of actors and scenario instances (a.k.a. the
virtual time the <tt class="docutils literal">Simulated world</tt> is plunged into; at least a
discretised version thereof). By default there is no link between
the wall-clock time and the simulation one.</dd>
<dt>Simulation traces</dt>
<dd>The <tt class="docutils literal">Simulation traces</tt> correspond to the time-stamped (in
wall-clock or simulation time) information emitted by the actors,
scenario instances and the technical agents of the simulation,
during its course (ex: probes, service providers). These are not
simulation results, they are a technical means of following the
events that happen in the course of a simulation, for example in
order to troubleshoot the behaviour of models.</dd>
<dt>System context</dt>
<dd>The <tt class="docutils literal">System context</tt> gathers everything in the <tt class="docutils literal">Simulated world</tt>
that is not the <tt class="docutils literal">Target system</tt>. It is made of all the
<tt class="docutils literal">Scenario</tt> instances.</dd>
<dt>Target system</dt>
<dd>The <tt class="docutils literal">Target system</tt> is the system of interest, whose mode of
operation is reproduced thanks to a set of models. Generally such a
target system cannot be simulated without its context, i.e. parts of
the reality that do not belong to the target system but must be
taken into account to simulate it.
For example, &quot;<em>The target system is made of the preys and the
predators. Its context is the weather and the savannah (vegetation
and relief).</em>&quot;</dd>
</dl>
<p></p>
</div>
</div>
<div class="section" id="sim-diasca-specifications">
<h1><a class="toc-backref" href="#id162">Sim-Diasca Specifications</a></h1>
<p>Sim-Diasca has been originally designed in the context of two French and British projects aiming to perform a massive roll-out of communicating meters for millions of residential customers.</p>
<p>This became a typical example of the complex systems whose simulation could be addressed by Sim-Diasca, showing the usual process involved by a project having to focus on business simulations: as the development of models and simulation cases is long and expensive, and as switching from an engine to another in the course of a project is almost never an option, an appropriate choice in the simulation tools is crucial for the success of such a project.</p>
<p>To reduce this technical risk, a very basic, straightforward decision process is generally to be applied:</p>
<ol class="arabic simple">
<li>establish the functional requirements for the targeted simulator</li>
<li>deduce and formalise the corresponding technical requirements</li>
<li>make a review of the state of the art of this simulation field, and establish a short list of the most relevant simulation tools</li>
<li>test and rank each of them against the list of needed properties that was previously agreed from step 2 and weighted accordingly</li>
<li>elect the best candidate, possibly by benchmarking it on a representative use-case against a reference tool or the best other contenders</li>
</ol>
<div class="section" id="simulator-potential-role">
<h2><a class="toc-backref" href="#id163">Simulator Potential Role</a></h2>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">In this document, we will often rely on examples taken from the smart metering field; however one must keep in mind that Sim-Diasca is a fully generic, business-free simulation engine, which has no connection at all with metering, and which can be applied to <em>any</em> kind of discrete complex systems.</p>
</div>
<p>In our context, the goal was to be able to perform virtual experiments on a system - here, before it even exists - mainly for decision-making purposes.</p>
<p>Indeed, the main purpose for such a simulator is generally to allow for a harmless test of a system:</p>
<p><span class="raw-html"><center><img src="xkcd-los_alamos.png" id="responsive-image-intermediate"></img></center></span>
 <a class="footnote-reference" href="#id4" id="id3">[2]</a></p>
<table class="docutils footnote" frame="void" id="id4" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id3">[2]</a></td><td>For the non-native English speakers, expressions like &quot;<tt class="docutils literal">SOH CAH TOA</tt>&quot; are <a class="reference external" href="http://en.wikipedia.org/wiki/Trigonometry#Mnemonics">mnemonics</a> for basic trigonometry.</td></tr>
</tbody>
</table>
<p>(see the <a class="reference internal" href="#credits">credits</a> section about the comic strips)</p>
<p>Such a simulator could allow indeed to:</p>
<ul class="simple">
<li><strong>determine a priori</strong> some of the properties of the target system:<ul>
<li>functionally, for example: &quot;<em>How are implemented the business services, with what overall coverage and constraints on the processes?</em>&quot;</li>
<li>technically, for example: &quot;<em>What is the lowest/mean/highest possible duration for this particular request to be completed?</em>&quot; or &quot;<em>What is the minimal bandwidth to plan for this particular link?</em>&quot;</li>
</ul>
</li>
<li><strong>compare answers</strong> to a call for tenders, so that the various solution candidates can be better evaluated</li>
<li>better <strong>review delivered versions</strong> of the system and <strong>ease their technical validation</strong></li>
<li><strong>help developing and tuning</strong> the system, for example by the impact on traffic due to a change in a data format</li>
<li><strong>help validating project strategies</strong>, for example regarding the roll-out: &quot;<em>If meters are installed without any particular order, what is the ratio of meters whose proper operation could be directly validated at installation-time?</em>&quot;</li>
<li><strong>quantify the costs of the system</strong> to establish its value analysis, by evaluating the total investments costs (ex: for an installed concentrator) and operational costs (ex: for GPRS communication costs, which may be partly proportional to the actual exchanged volumes)</li>
<li>better <strong>secure the ability of the system to evolve</strong>, for example by evaluating <em>a priori</em> the impact of a change in the functional or technical perimeter: &quot;<em>Should this new service be offered, what would be its technical feasibility (ex: in terms of embedded processing or telecom link) and what would be the consequences on the overall properties and performance of the system?</em>&quot;</li>
<li><strong>ease the test</strong> of all or part of the system, for example by recreating the environment of an actual component thanks to the simulation, and by assessing the correctness of the behaviour of the component with regard to a set of test interactions, which comply or not to the specifications</li>
</ul>
<p>Of course any given simulator will rarely be requested to fulfil everything in such a wide range of expectations, but these are examples of questions that could be tackled thanks to a generic enough simulator and a set of appropriate models and metrics.</p>
</div>
<div class="section" id="simulator-potential-context-of-use">
<h2><a class="toc-backref" href="#id164">Simulator Potential Context of Use</a></h2>
<p>Beyond the operational context of the aforementioned projects, such a simulator could be applied to:</p>
<ul class="simple">
<li>R&amp;D studies of alternative architectures for a metering system, for example:<ul>
<li>offering different services</li>
<li>and/or based on other choices in terms of software architecture (ex: showing a different dispatching of the processing on the various devices)</li>
<li>and/or using different infrastructures (ex: mesh networks)</li>
</ul>
</li>
<li>other target systems, like the one developed by the EDF supplier, instead of the one developed by ERDF, the monopolistic distributor</li>
<li>the British case, as a tool to help decision-making (EDF Energy, CLEVER project)</li>
<li>more generally, all kinds of simulation of information systems</li>
<li>more generally, all kinds of simulation of complex discrete systems</li>
</ul>
</div>
<div class="section" id="functional-technical-requirements">
<h2><a class="toc-backref" href="#id165">Functional &amp; Technical Requirements</a></h2>
<p>Here the simulation objective is to be able to rely on a <strong>simplified</strong> version of the target system, i.e. a <em>model</em> of it, on which various experiments can be conducted so that the overall system can be better understood, and questions about it can be answered.</p>
<p>We will discuss here the main requirements that applied to our use-cases and thus played a main role in the design choices for Sim-Diasca.</p>
<div class="section" id="a-key-point-scalability">
<h3>A Key Point: Scalability</h3>
<div class="section" id="other-approaches-than-simulation-hardly-scale">
<h4>Other Approaches Than Simulation Hardly Scale</h4>
<p>Among the most challenging questions raised by this new system, many of them were directly related to the consequences of its significant size. And this same size prevented most of the usual evaluation approaches to be applicable. Indeed these approaches, which include:</p>
<ul class="simple">
<li>thought experiments</li>
<li>expert-based assessments</li>
<li>simple extrapolations</li>
<li>more complex spreadsheet-based computations</li>
</ul>
<p>could hardly tackle non-trivial questions since they generally fail to recreate precisely what happens in the system (notably time-wise) and what are the outcomes of these corresponding interactions: usually, only macroscopic values at equilibrium or not depending on time can be expected from these approaches.</p>
<p>Indeed some questions become increasingly difficult and crucial to tackle as the size of the target system rises: even simple individual behaviours, once interacting with a sufficient number of others, can combine themselves to form complex systems whose behaviour is surprisingly difficult to predict.</p>
<p>Solving issues affecting these systems is all the more difficult than some elements of a metering infrastructure, like the concentrators or the PLC networks, are themselves complex.</p>
<p>Despite these difficulties, such scale effects must be addressed soon, as costs induced by their late detection become quickly prohibitive.</p>
<p>Therefore the use of more demanding approaches like <em>simulation</em> is often needed, since, more often than not, a real-size target system cannot be built just for test purpose.</p>
</div>
<div class="section" id="a-simulator-may-or-may-not-scale">
<h4>A Simulator May or May Not Scale</h4>
<p>Due to the very large number of devices in most metering systems (more than 35 million meters in the French case), the simulator has itself to be able to scale up.</p>
<p>This does not necessarily imply that this tool must to be able to reach the exact full size of the target system, however it means it should be able at the very least to handle a massive numbers of interacting elements, as close as reasonably achievable to the real extent of the planned system.</p>
<p>Scalability is therefore at the heart of the properties wanted for that kind of simulators.</p>
<p>This concern severely constrained its implementation: so that it can reach performances suitable for its intended use, or just have a reasonable chance to actually deal with the problem in its required size, one had to ensure that the operation of the simulator is as <strong>concurrent</strong> as possible.</p>
</div>
<div class="section" id="concurrency-first-but-other-properties-matter-too">
<h4>Concurrency First, But Other Properties Matter Too</h4>
<p>The simulator had thus to be designed to be strongly <em>parallel</em> (on a given computation node, multiple models can be evaluated simultaneously by the available cores) and <em>distributed</em> (a simulation can take place over a set of networked computation nodes), and all this without hurting the properties deemed important but difficult to preserve in that context, such as:</p>
<ul class="simple">
<li>the correctness of the evaluation of models</li>
<li>the preservation of causality between simulation events</li>
<li>the ability to have completely reproducible simulations</li>
</ul>
<p>More precisely, in our case the objective was to rely on a framework, made of a generic simulation engine and of reusable components, that allows the development of simulations of information systems that are:</p>
<ul class="simple">
<li><strong>discrete</strong> rather than continuous, because the modeled phenomena themselves are essentially discrete, and those which were continuous could easily be quantized</li>
<li>in <strong>dynamic state</strong> rather than in steady state, since for example cascading outages or the progressive roll-out of the system are subjects of interest</li>
<li><strong>event-driven</strong>, as state changes of the modeled instances are generally punctual and can happen at any time</li>
<li><strong>causal</strong>, so that a total order on the simulation events can be recreated despite the massive concurrency</li>
<li><strong>reproducible</strong>, so that different executions of the simulation take place identically, no matter their execution context, i.e. not depending on scheduling, dispatching of processing, available resources, number and nature of computing nodes, capacity of the network, etc.</li>
<li><strong>intensely concurrent</strong>, as already mentioned, thus supporting a high degree of parallelism (taking advantage of multicores and SMP <a class="footnote-reference" href="#id7" id="id5">[3]</a>) and able to be distributed over HPC <a class="footnote-reference" href="#id8" id="id6">[4]</a> solutions like clusters or supercomputers (ex: <tt class="docutils literal">Bluegene</tt>)</li>
<li><strong>potentially of very large scale</strong>, as already mentioned, to be able to simulate systems made of many thousands, if not millions, of interacting elements</li>
</ul>
<table class="docutils footnote" frame="void" id="id7" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id5">[3]</a></td><td>SMP: <em>Symmetric multiprocessing</em>.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id8" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id6">[4]</a></td><td>HPC: <em>High Performance Computing</em>.</td></tr>
</tbody>
</table>
<p>This is the base specifications we had in mind for Sim-Diasca. However more generic and/or detailed requirements could be imagined, they are listed below.</p>
</div>
<div class="section" id="list-of-spotted-potential-properties-for-the-simulator">
<h4>List of Spotted Potential Properties For the Simulator</h4>
<p>Determining the simulation properties that are required is a critical step of a project, so that an appropriate engine can be chosen. Indeed, the requirements may include very varying features to be provided by such a simulation engine, from high-level programming of models to scalability or support for continuous components (i.e. solver embedding).</p>
<p>The devil is in the details in terms of tool selection as well. So even two discrete simulation engines that, from a remote point of view, might look rather similar, may actually be widely different beasts.</p>
<div class="section" id="related-to-simulation-correctness">
<h5>Related to Simulation Correctness</h5>
<ul class="simple">
<li><strong>P1</strong> Preservation of causality between events (see the <a class="reference internal" href="#maintaining-causality">Maintaining Causality</a> section for detailed explanations)</li>
<li><strong>P2</strong> Reproducibility of the evaluation of models (this is directly linked to the usability of the simulator: one usually needs to be able to relate changes in simulation results to changes operated on the target system or on its context)</li>
</ul>
</div>
<div class="section" id="related-to-what-can-be-simulated">
<h5>Related to What Can Be Simulated</h5>
<ul class="simple">
<li><strong>P3</strong> Models are based on discrete events, even for any continuous phenomenon</li>
<li><strong>P4</strong> Ability to simulate the system when it is in static/steady/nominal state</li>
<li><strong>P5</strong> Ability to simulate the system when it is in any dynamic/transient/abnormal state, for example when being deployed, or under unexpected circumstances (ex: cascading failures), or during migration between versions</li>
<li><strong>P6</strong> Ability to support stochastic actors, whose behaviours depend on a set of various random variables based on various probabilistic distributions (opens to Monte Carlo computations)</li>
</ul>
</div>
<div class="section" id="related-to-interaction-with-the-simulator">
<h5>Related to Interaction With the Simulator</h5>
<ul class="simple">
<li><strong>P7</strong> Ability to run in batch (i.e. non-interactive) mode</li>
<li><strong>P8</strong> Ability to run in interactive mode (for emulation and/or if human can be in the loop)</li>
<li><strong>P9</strong> Use of a standardised format for simulation traces and results (to interface to third-party tools instead of having to develop them)</li>
</ul>
</div>
<div class="section" id="related-to-the-size-of-the-system-that-can-be-simulated">
<h5>Related to the Size of the System That Can Be Simulated</h5>
<ul class="simple">
<li><strong>P11</strong> Ability to process, algorithm-wise (in terms of logic and expressiveness, not depending on the way we dispatch processing), in parallel most, if not all, models, instead of having them evaluated sequentially (ex: 5 million models running simultaneously rather than having 5 million models to walk through, one after the other)</li>
<li><strong>P12</strong> Ability to take advantage of parallel computational resources, like SMP (multi-processors) and multicores (i.e. to dispatch a simulation over a set of local processing units)</li>
<li><strong>P13</strong> Ability to take advantage of distributed computational resources (i.e. to dispatch a simulation over a set of networked computing nodes)</li>
<li><strong>P14</strong> Ability to use HPC resources (full-blown clusters, super-computers, etc.)</li>
</ul>
</div>
<div class="section" id="related-to-how-models-can-be-injected-into-the-simulation">
<h5>Related to How Models Can Be Injected Into the Simulation</h5>
<ul class="simple">
<li><strong>P15</strong> Ability to add new models easily (extensibility)</li>
<li><strong>P16</strong> Ability to define models with little effort, with a high-level modelling language (for example abstracting technical constraints, being based on an appropriate formalism, or even opening the use of advanced modelling tools, for model-checking, formal proof, etc.)</li>
<li><strong>P17</strong> Ability to integrate with real devices (i.e. having actual equipments taking parts among models into simulations)</li>
<li><strong>P18</strong> Ability to perform model composition, parameterised models, dynamic topology, multi-level evaluations, etc.</li>
</ul>
</div>
<div class="section" id="related-to-the-technical-characteristics-of-the-simulator-itself">
<h5>Related to the Technical Characteristics of the Simulator Itself</h5>
<ul class="simple">
<li><strong>P19</strong> Ability to interface easily to third-party tools (ex: to an emulation layer of a specific protocol, to post-processing tools, etc.)</li>
<li><strong>P20</strong> Use of free software tools (thus that can be modified/fixed/enhanced/shared/freely used), preferably well-known</li>
</ul>
</div>
<div class="section" id="newly-added-properties">
<h5>Newly Added Properties</h5>
<p>These properties and features were not listed in the initial requirements, but over time proved to be key points as well:</p>
<ul class="simple">
<li><strong>P21</strong> Support for a complete result management, which allows mainly the user to specify what are the results expected from the simulation (preferably producing them, and only them) and then automatically collects and retrieves them to the user node, efficiently (ex: post-processing them concurrently on the computing nodes, and sending corresponding compressed data over the network) and conveniently (ex: gathering everything in a experiment-specific directory on the user node, and allowing to browse them automatically if not in batch mode)</li>
<li><strong>P22</strong> A basic support for simulation reliability is to be provided: first of all, results will be produced if and only if the simulation not only terminates, but terminates on a success; otherwise, as soon as any of its elements fail (including model instances), the simulation should crash immediately and completely (as a whole); any abnormal slow-down should be reported, and a diagnosis system should be provided, notably to help the debugging of models (who are the lingering instances, what are they doing, who are they waiting for, etc.)</li>
</ul>
<p></p>
</div>
</div>
</div>
</div>
</div>
<div class="section" id="sim-diasca-functional-coverage">
<h1><a class="toc-backref" href="#id166">Sim-Diasca Functional Coverage</a></h1>
<p>Based on the property list discussed in <a class="reference internal" href="#list-of-spotted-potential-properties-for-the-simulator">List of Spotted Potential Properties For the Simulator</a>, we tried to evaluate what are the features currently offered by Sim-Diasca in the following table.</p>
<table border="1" class="docutils">
<colgroup>
<col width="31%" />
<col width="25%" />
<col width="44%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Property Identifier</th>
<th class="head">Estimated Quality
of Sim-Diasca
support
for that property</th>
<th class="head">Comments</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>P1: causality
preservation</td>
<td>Fully supported</td>
<td>No effect should occur before
its cause since it will be
managed at least one simulation
tick later.</td>
</tr>
<tr><td>P2: reproducibility</td>
<td>Fully supported</td>
<td>A reproducible total order on
simulation events is enforced,
(provided of course that models
respect the Sim-Diasca
conventions).</td>
</tr>
<tr><td>P3: discrete events</td>
<td>Fully supported</td>
<td>Events happen relatively to a
given simulation tick.</td>
</tr>
<tr><td>P4: steady state</td>
<td>Fully supported</td>
<td>Special case of P5.</td>
</tr>
<tr><td>P5: dynamic state</td>
<td>Fully supported</td>
<td>Models are free to develop
<em>any</em> behaviour over time.</td>
</tr>
<tr><td>P6: stochastic actors</td>
<td>Fully supported</td>
<td>There are two generic mechanisms
to support all kinds of
probability distributions. Most
basic laws (uniform, Gaussian
and exponential) are built-in.</td>
</tr>
<tr><td>P7: batch mode</td>
<td>Fully supported</td>
<td>This is the default mode of
operation.</td>
</tr>
<tr><td>P8: interactive mode</td>
<td>Fully supported</td>
<td>Easy to provide effectively with
time-stepped simulations. Of
course does not guarantee that
simulations will be fast enough
to keep up with the user time
(depends mostly on the available
computing resources).</td>
</tr>
<tr><td>P9: standardised traces</td>
<td>Fully supported</td>
<td>A fairly advanced system allows
to emit distributed traces,
aggregate them and monitor them,
but they are currently managed
for the user: they are not
especially designed for
third-party tools.</td>
</tr>
<tr><td>P10: result management</td>
<td>Supported</td>
<td>Currently most results come from
the probes and the data-logger,
both of which are built-in.</td>
</tr>
<tr><td>P11: parallel operation
(algorithmic)</td>
<td>Fully supported</td>
<td>Provided by the time-stepped
approach (all actors can run
concurrently at each time step).</td>
</tr>
<tr><td>P12: parallel operation
(technical)</td>
<td>Fully supported</td>
<td>Provided by the Erlang runtime
(one Erlang virtual machine per
processor and/or core).</td>
</tr>
<tr><td>P13: distributed</td>
<td>Fully Supported</td>
<td>The engine can run on any set of
networked (UNIX-based) computing
nodes, including High Performance
Computing clusters (full suite of
management scripts provided for
PBS-based clusters).</td>
</tr>
<tr><td>P14: use of HPC
resources</td>
<td>Fully Supported</td>
<td>The engine is able to run on
PBS-based HPC clusters, and
some manycore architectures
(Tilera cards) will be
supported soon.</td>
</tr>
<tr><td>P15: extensibility</td>
<td>Fully supported</td>
<td>Models can be added very easily,
with no additional compilation.
Some practise with the Erlang
language is needed.
As few constraints as possible
weight on models.</td>
</tr>
<tr><td>P16: high-level
modelling language</td>
<td>Moderate support</td>
<td>No model-specific language is
used, but the high-level
constructs of Erlang, the
OOP services of WOOPER and the
simulation services of Sim-Diasca
are available and can be easily
reused. Nothing though that can
be compared with formal proof or
model checking.</td>
</tr>
<tr><td>P17: integration with
real devices</td>
<td>Not supported yet</td>
<td>Although this is theoretically
feasible, this topic has not
been explored yet.</td>
</tr>
<tr><td>P18: model composition</td>
<td>Supported</td>
<td>A model can create, remove,
configure, update other models.
Composition must be done with
care though, to deal with any
latency induced by layers of
models.</td>
</tr>
<tr><td>P19: interface to
third-party tools</td>
<td>Fully Supported</td>
<td>Erlang provides several means
of doing so, which is especially
useful for post-processing.</td>
</tr>
<tr><td>P20: open-source</td>
<td>Fully Supported</td>
<td>Erlang and WOOPER are
open-source, and as of September
2010 Sim-Diasca has been
released.by EDF R&amp;D in LGPL.</td>
</tr>
<tr><td>P21: result management</td>
<td>Fully Supported</td>
<td>Results are automatically
selected, produced, retrieved
despite their distribution.
The result management is both
very flexible (smart
specification language) and
efficient (only relevant results
are produced).</td>
</tr>
<tr><td>P22: reliability</td>
<td>Supported</td>
<td>Simulation will properly crash
if any constraint is violated.
A simulation stall/deadlock
detection and diagnosis system
will be triggered if ever issues
arise (ex: faulty model).</td>
</tr>
</tbody>
</table>
<p>The Sim-Diasca functional coverage increased over time, first to support a better distributed mode of operation, then to provide more complete support for the management of results.</p>
<p>Although we cannot guarantee that they will be fulfilled, we are always interested into requests for enhancement, provided they are reasonable:</p>
<p><span class="raw-html"><center><img src="xkcd-spinal_tap_amps.png" id="responsive-image-medium"></img></center></span>
</p>
<p>The planned future changes are listed in the <a class="reference internal" href="#enhancements">enhancements</a> section.</p>
<p></p>
</div>
<div class="section" id="modelling-approach">
<h1><a class="toc-backref" href="#id167">Modelling Approach</a></h1>
<p><span class="raw-html"><center><img src="xkcd-physicists.png" id="responsive-image-small"></img></center></span>
</p>
<div class="section" id="questions-metrics-models">
<h2><a class="toc-backref" href="#id168">Questions, Metrics &amp; Models</a></h2>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Only some basic, general considerations about modelling are given here. To focus on the actual modelling that shall be operated in practice with the engine, one should refer to the <em>Sim-Diasca Modeller Guide</em>.</p>
</div>
<p>Depending on the question one is asking about the target system (ex: &quot;<em>What is the mean duration of that service request?</em>&quot;) or on the properties that one wants to evaluate (ex: robustness, availability, cost, etc.), <strong>metrics</strong> (a.k.a. <em>system observables</em>), which are often macroscopic, system-wide, have to be defined. For example: round-trip time elapsed for a service request, or yearly total operational cost for the GPRS infrastructure.</p>
<p>These specific metrics will have to be computed and monitored appropriately during the corresponding simulations.</p>
<p>To do so, the behaviour of the elements of the system that have an impact on these values must be reproduced. For example,  when evaluating a distributed information system, business-specific elements like devices, network components, etc. must be taken into account.</p>
<p>The simulator will manage all these elements based on simplified representations of them (<em>models</em>), selected to be relevant for the behavioural traits which matter for the question being studied.</p>
<p>Therefore the choice of the elements to take into account will depend on the selected metrics: if for example one is only interested in the volume of data exchanged in nominal state, deployment policies or failures of some devices might not be relevant there. On the contrary, evaluating reliability may not require to go into deeper details about each and every exchanged byte on the wire.</p>
<p>Moreover, the same element of the target system might be modeled differently depending on the chosen metrics: for example, for a network-based metrics, a device may be modeled merely as a gateway, whereas for reliability studies it will be seen as an equipment able to fail and be repaired according to stochastic models.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Simply put, a question asked to the simulator results in a choice of metrics, which in turn results in a choice of appropriate models.</p>
</div>
<p>Therefore each element of the system can be represented by a set of models, of various nature and level of detail, results of the work of experts on various subjects, according to the following theoretical diagram:</p>
<p><span class="raw-html"><center><img src="modelling-approach-english.png" id="responsive-image-large"></img></center></span>
</p>
<p>Different fields of expertise (notably functional and technical experts) have to define the simulation goals, metrics, and to work collaboratively on a set of common models, which form the modelling framework.</p>
<p>Once specified, the pool of models can be reused at will in the context of different experiments: these models can be assembled together and projected in various execution environments, with different purposes and level of detail.</p>
</div>
<div class="section" id="implementation-of-models">
<h2><a class="toc-backref" href="#id169">Implementation Of Models</a></h2>
<p>Uncoupling as much as possible models from implementations allows to reduce the dependency on a specific set of simulation tools, even though inevitably constraints remain.</p>
<p>In the case of the AMM project, two completely different simulation environments were developed, based on a common view of the system:</p>
<ul class="simple">
<li><strong>AMM-Jade</strong>, making use of the <a class="reference external" href="https://jade.tilab.com/">Jade</a> multi-agent system, for fast prototyping purposes</li>
<li><strong>Sim-Diasca</strong>, discussed here, making use of <a class="reference external" href="http://www.erlang.org/">Erlang</a> and of various custom-made layers, for finer modelling and HPC simulation purposes</li>
</ul>
<p>These two threads of activity did not share any code but had a common approach to modelling.</p>
<p>In both cases, simulations operate on <em>instances</em> of models.</p>
<p>A model must be understood here in its wider sense: real system elements, such as meters or concentrators, are of course models, but abstract elements, like deployment policies or failure laws, can be models as well. Basically every stateful interacting simulation element should be a model, notably so that it can be correctly synchronised by the simulation engine.</p>
<p>A model can be seen roughly as a class in object-oriented programming (OOP).</p>
<p>Then each particular element of the simulation - say, a given meter - is an instance of a model - say, the <tt class="docutils literal">AMM Meter</tt> model.</p>
<p>In agent-based simulations like the ones described here, all instances communicate <em>only</em> by message passing, i.e. shared (global) variables are not allowed. Added to code that is free from side-effects, seamless distribution of the processing becomes possible.</p>
<p>Unlike OOP though, the instances are not only made of a state and of code operating on them (methods): each and every instance also has its own thread of execution. All instances live their life concurrently, independently from the others. This is the concept of <a class="reference external" href="http://en.wikipedia.org/wiki/Intelligent_agent">agents</a>.</p>
<p>Relying on them is particularly appropriate here, as the reality we want to simulate is itself concurrent: in real life, the behaviour of all meters is concurrent indeed. Thus using concurrent software is a way of bridging the semantic gap between the real elements and their simulated counterparts, so that models can be expressed more easily and executed more efficiently.</p>
<p>Besides, these agents have to follow some conventions, some technical rules, to ensure that the aforementioned list of simulation properties can be met.</p>
<p>We finally call such a well-behaving agent a <em>simulation actor</em>, or simply an <em>actor</em>.
The simulator can therefore be seen as a set of technical components that allow to operate on actors, notably in order to manage their scheduling and communication.</p>
<p>This topic is directly in relation with the issue of time management, which is discussed below.</p>
<p></p>
</div>
</div>
<div class="section" id="a-short-overview-of-simulation-services">
<h1><a class="toc-backref" href="#id170">A Short Overview of Simulation Services</a></h1>
<p>From the point of view of a model writer, the main <strong>functional</strong> simulation services offered by Sim-Diasca are:</p>
<ul class="simple">
<li>simulation case definition: see how to choose the simulation settings (<tt class="docutils literal">simulation_settings</tt> record), to specify how the deployment should be performed (<tt class="docutils literal">deployment_settings</tt> record), to define the initial state of the simulation (see the creation API of <tt class="docutils literal">class_Actor</tt>), to parametrise the load-balancing (<tt class="docutils literal">load_balancing_settings</tt> record), to control the simulation (starting time, ending criteria, console tracking, result browsing, etc.)</li>
<li>time management: see <tt class="docutils literal">class_TimeManager</tt>, that drives the scheduling of all <tt class="docutils literal">class_Actor</tt> instances</li>
<li>state management, interactions: see <tt class="docutils literal">class_Actor</tt> and, for specific needs, <tt class="docutils literal">class_BroadcastingActor</tt></li>
<li>stochastic support: see <tt class="docutils literal">class_RandomManager</tt>, <tt class="docutils literal">class_StochasticActor</tt> and, more importantly, the stochastic API of <tt class="docutils literal">class_Actor</tt></li>
<li>specific data exchanges: see <tt class="docutils literal">class_DataExchanger</tt></li>
<li>result management: see <tt class="docutils literal">class_ResultManager</tt> and <tt class="docutils literal">class_ResultProducer</tt> (for the overall organisation), <tt class="docutils literal">class_Probe</tt> and <tt class="docutils literal">class_DataLogger</tt> (for the actual result generation) and <tt class="docutils literal">simulation_settings</tt> record</li>
</ul>
<p>The main underlying <strong>technical</strong> simulation services are:</p>
<ul class="simple">
<li>automatic distributed deployment: see <tt class="docutils literal">class_DeploymentManager</tt> and <tt class="docutils literal">class_ComputingHostManager</tt></li>
<li>load balancing: see <tt class="docutils literal">class_LoadBalancer</tt></li>
<li>instance tracking: see <tt class="docutils literal">class_InstanceTracker</tt></li>
<li>robustness and reliability: see <tt class="docutils literal">class_ResilienceManager</tt> and <tt class="docutils literal">class_ResilienceAgent</tt></li>
<li>performance tracking: see <tt class="docutils literal">class_PerformanceTracker</tt></li>
<li>lower-level services: see <tt class="docutils literal">class_Mesh</tt> for graph support</li>
<li>trace management: see the <tt class="docutils literal">Traces</tt> layer</li>
<li>object-oriented support: see the <tt class="docutils literal">WOOPER</tt> layer</li>
<li>distribution, parallelism, process-level scheduling and memory management, etc.: see the <tt class="docutils literal">Erlang</tt> language</li>
</ul>
<p></p>
</div>
<div class="section" id="sim-diasca-time-management-explained">
<h1><a class="toc-backref" href="#id171">Sim-Diasca Time Management Explained</a></h1>
<p><span class="raw-html"><center><img src="xkcd-time_management.png" id="responsive-image-medium"></img></center></span>
</p>
<p>As already mentioned, the approach to the management of simulation time is most probably the key point of the design of a parallel, distributed simulation engine like the one discussed here.</p>
<p>There are several options to manage time, and, depending on the simulation properties that are needed, some methods are more appropriate than others.</p>
<p>Their main role is to uncouple the <em>simulation</em> time (i.e. the virtual time the model instances live in) from the <em>wall-clock</em> time (i.e. the actual time that we, users, experience), knowing that the powerful computing resources available thanks to a parallel and distributed context may only be used at the expense of some added complexity at the engine level.</p>
<div class="section" id="some-general-technical-considerations-first">
<h2><a class="toc-backref" href="#id172">Some General Technical Considerations First</a></h2>
<p>In the context of interest here, a scheduler is a software component of a simulation engine that is specifically in charge of the management of the simulation time.</p>
<p>Its purpose is to preserve the simulation properties (ex: uncoupling of the virtual time from the wall-clock one, respect of causality, management of concurrent events, management of stochastic behaviours, guarantee of total reproducibility, providing of some form of &quot;ergodicity&quot; - more on that later) while performing a correct evaluation of the model instances involved in that simulation.</p>
<p>It must induce as little constraint on the models as possible (ex: in terms of fan-in, fan-out, look-ahead, etc.) and, as a bonus, it can evaluate them efficiently.</p>
<p>A scheduler can certainly be &quot;ad hoc&quot; (written in a per-simulation basis), but in the general cases we do not consider that this is a relevant option. Indeed much duplication of efforts would be involved, as such a scheduling feature would have to be repeatedly
developed, from a simulation case to another, most probably in a very limited and limiting way.</p>
<p>Moreover ad hoc scheduling often results in <em>static</em> scheduling, where the modeller unwinds by himself the logic of the interaction of the various models federated by the simulation, and hardcodes it. We believe that much of the added value of a simulation is then lost in this case, the modeller removing many degrees of freedom and independence by emulating manually the role of a scheduler: in the general case, semantically the behaviour of a target system is best described as the natural by-product of several autonomous interacting entities, rather than as a predetermined series of events.</p>
</div>
<div class="section" id="preservation-of-properties">
<h2><a class="toc-backref" href="#id173">Preservation of Properties</a></h2>
<div class="section" id="maintaining-causality">
<h3>Maintaining Causality</h3>
<p>In the context of a distributed simulation, should no special mechanism be used, the propagation of simulated events would depend on the propagation of messages in the actual network of computing nodes, which offers no guarantee in terms of respective timing and therefore order of reception.</p>
<p>As the minimal example below <a class="footnote-reference" href="#id11" id="id10">[5]</a> shows, a simulation cannot work correctly as such:</p>
<p><span class="raw-html"><center><img src="causality-issues-english.png" id="responsive-image-intermediate"></img></center></span>
</p>
<table class="docutils footnote" frame="void" id="id11" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id10">[5]</a></td><td>The military setting is due to the fact their simulations have been ahead of civil ones for long.</td></tr>
</tbody>
</table>
<p>There are three simulation actors here, which are supposed to be instantiated each on a different computing node. Thus, when they communicate, they exchange messages over the network on which the distributed simulator is running.</p>
<p>Actor #1 is a rocket launcher that fires to actor #2, which is a tank. Thus actor #1 sends a message, M1, to all simulation actors that could be interested by this fact (including actor #2 and actor #3), to notify them of the rocket launch.</p>
<p>Here, in this technical context (computers and network), actor #2 (the tank) happens to receive M1 before actor #3 (the observer).</p>
<p>According to its model, the tank, when hit by a rocket, must explode. Therefore it sends a message (M2) to relevant actors (among which there is the observer), to notify them it exploded and that the corresponding technical actor is removed from the simulation.</p>
<p>The problem lies in the point of view of actor #3. Indeed in that case the observer received:</p>
<ol class="arabic simple">
<li>M2, which told it that a tank exploded for no reason (unexpected behaviour)</li>
<li>then M1, which tells it that a rocket was fired to a simulation actor that actually does not even exist</li>
</ol>
<p>This situation makes absolutely no sense for this actor #3. At best, the model of the observer should detect the inconsistency and stop the simulation. At worse, the actor received incorrect inputs, and in turn injected incorrect outputs in a simulation that should not be trusted anymore.</p>
<p><span class="raw-html"><center><img src="xkcd-protocol.png" id="responsive-image-small"></img></center></span>
</p>
<p>The root of the problem is that here there is no guarantee that received messages will respect their timely constraints - whereas (at least in synchronous approaches) no return to the past shall be considered, however tempting.</p>
<p><span class="raw-html"><center><img src="xkcd-the_past.png" id="responsive-image-tiny"></img></center></span>
</p>
<p>This faulty behaviour would be all the more unfortunate that the incorrect outputs are likely to be indistinguishable from correct ones (i.e. they can go unnoticed in the simulation), distorting the results invisibly, a bit like a pocket calculator which would silently ignore parentheses, and would nevertheless output results that look correct, but are not.</p>
</div>
<div class="section" id="maintaining-reproducibility">
<h3>Maintaining Reproducibility</h3>
<p><span class="raw-html"><center><img src="xkcd-the_difference.png" id="responsive-image-medium"></img></center></span>
</p>
<p>Let's suppose for now we somehow managed to preserve causality. This does not imply that reproducibility is ensured.</p>
<p>Using the same example where actor #1 launches a rocket (sending the M1 message), actor #3 can in the meantime develop its own behaviour, which may imply this observer detected the tank. This can lead the observer notifying the tank, thus to its sending the M3 message.</p>
<p><span class="raw-html"><center><img src="reproducibility-issues-english.png" id="responsive-image-intermediate"></img></center></span>
</p>
<p>The point here is that there is no direct nor causal relationship between M1 and M3. These are truly concurrent events, they may actually happen in any order. Therefore concurrent events are not expected to be reordered by the mechanism used to maintain causality, since situations A and B are equally correct.</p>
<p>However, when the user runs twice exactly the same simulation, she most probably expects to obtain the same result <a class="footnote-reference" href="#id13" id="id12">[6]</a>: here M1 should be received by actor #2 <em>always</em> before M3, or M3 <em>always</em> before M1, and the implicit race condition should not exist in that context.</p>
<table class="docutils footnote" frame="void" id="id13" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id12">[6]</a></td><td>Otherwise she would not be able to interpret the consequences of a change in the simulation parameters unless she runs thousands of simulations to monitor macroscopic values only, instead of running two simulations (with and without the change) and comparing just the outcome of these two particular trajectories of the system.</td></tr>
</tbody>
</table>
<p>In that case, causality is not enough, some additional measures have to be taken to obtain reproducibility as well.</p>
<p>With some time management approaches, once causality is restored, ensuring reproducibility is only a matter of enforcing an arbitrary order (i.e. which depends only on these messages, not in any way on the context) on concurrent events.</p>
</div>
<div class="section" id="allowing-for-ergodicity">
<h3>Allowing For Ergodicity</h3>
<p>The context-free message reordering allows to recreate the arbitrary order we need to ensure reproducibility.</p>
<p>However the simulator should offer the possibility to go beyond this mechanism, otherwise &quot;ergodicity&quot; (a term we chose in reference to Monte-Carlo computations) cannot be achieved: in some cases we want all combinations of concurrent events to be able to occur, not only the ones that correspond to the arbitrary order we enforced.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Just disabling the reproducibility mechanism would not be a solution: if no reordering at all was enabled, the natural sequence of concurrent events (which would then be dictated by the computing infrastructure) would not guarantee any ergodicity; some sequences of events would happen a lot more frequently than others, although they should not.</p>
</div>
<p>The best solution we know here is, in a time-stepped context, to let the reproducibility mechanism activated, but, in addition to the sorting into an arbitrary order, to perform then an uniform random shuffle: then we are able not only to recreate <em>all</em> licit combinations of events during a given simulation tick at the level of each actor, but also to ensure that all these combinations have <em>exactly</em> the same probability of showing up.</p>
<p><span class="raw-html"><center><img src="ergodicity-issues-english.png" id="responsive-image-intermediate"></img></center></span>
</p>
<p></p>
</div>
</div>
<div class="section" id="approaches-to-time-management">
<h2><a class="toc-backref" href="#id174">Approaches to Time Management</a></h2>
<p>As far as we know, there are mainly four ways of managing time correctly, in a distributed context, in the context of a simulation in discrete time.</p>
<div class="section" id="approach-a-use-of-a-centralised-queue-of-events">
<h3>Approach A: use of a centralised queue of events</h3>
<p>A unique centralised queue of simulation events is maintained, events are sorted chronologically, and processed one after the other.</p>
<p>Pros:</p>
<ul class="simple">
<li>purely sequential, incredibly simple to implement</li>
</ul>
<p>Cons:</p>
<ul class="simple">
<li>splendid bottleneck, not able to scale at all, no concurrent processing generally feasible, distribution not really usable there; would be painfully slow on most platforms as soon as more than a few hundreds of models are involved</li>
</ul>
</div>
<div class="section" id="approach-b-use-a-time-stepped-approach">
<h3>Approach B: use a time-stepped approach</h3>
<p>The simulation time is chopped in intervals short enough to be able to consider the system as a whole as constant during a time step, and the simulator iterates through time-steps.</p>
<p>Pros:</p>
<ul class="simple">
<li>still relatively simple to understand and implement</li>
<li>may allow for a massive, yet rather effective, parallelization of the evaluation of model instances</li>
<li>the simulation engine may be able to automatically jump over ticks that are identified as being necessarily idle, gaining most of the advantages of event-driven simulations</li>
<li>the resulting simulator can work in batch mode or in interactive mode with very small effort, and with no real loss regarding best achievable performance</li>
</ul>
<p>Cons:</p>
<ul class="simple">
<li>not strictly as simple as one could think, but doable (ex: reordering of events must be managed, management of stochastic values must be properly thought of, induced latency may either add some constraints to the implementation of models or require a more complex approach to time management)</li>
<li>a value of the time step must be chosen appropriately (although we could imagine that advanced engines could determine it automatically, based on the needs expressed by each model)</li>
</ul>
</div>
<div class="section" id="approach-c-use-a-conservative-event-driven-approach">
<h3>Approach C: use a <em>conservative</em> event-driven approach</h3>
<p>The simulation time will not advance until all model instances know for sure they will never receive a message from the past.</p>
<p>Pros:</p>
<ul class="simple">
<li>efficient for systems with only few events occurring over long periods</li>
<li>there must be other advantages (other than the fact it is still a field of actual academic research) that I overlooked or that do not apply to the case discussed here</li>
</ul>
<p>Cons:</p>
<ul class="simple">
<li>complex algorithms are needed: it is proven that this mechanism, in the general case, leads to deadlocks. Thus a mechanism to detect them, and another one to overcome them, must be implemented</li>
<li>deadlock management and attempts of avoidance induce a lot of null (empty) messages to be exchanged to ensure that timestamps make progress, and this generally implies a significant waste of bandwidth (thus slowing down the whole simulation)</li>
</ul>
</div>
<div class="section" id="approach-d-use-an-optimistic-event-driven-approach">
<h3>Approach D: use an <em>optimistic</em> event-driven approach</h3>
<p>For each model instance (actor), simulation time will advance carelessly, i.e. disregarding the fact that other model instances might not have reached that point in time yet.</p>
<p>Obviously it may lead to desynchronised times across actors, but when such an actor receives a message from its past, it will rewind its logic and state in time and restart from that past. The problem is that it will likely have sent messages to other actors in-between, so it will have to send anti-messages that will lead to cascading rewinds and anti-messages...</p>
<p>Pros:</p>
<ul class="simple">
<li>efficient in some very specific situations where actors tend to nevertheless advance spontaneously at the same pace, thus minimising the number of messages in the past received (not the case here, I think)</li>
<li>there must be other advantages (other than the fact it is still a field of actual academic research) that I overlooked or that do not apply to the case discussed here</li>
</ul>
<p>Cons:</p>
<ul class="simple">
<li>overcoming messages in the past implies developing a generic algorithm allowing for distributed roll-backs over a graph of model instances. This is one of the most complex algorithm I know and for sure I would not dare to implement and validate it, except maybe in a research-oriented project</li>
<li>even when correctly implemented, each simulation roll-back is likely to be a real performance killer</li>
</ul>
<p></p>
</div>
</div>
<div class="section" id="sim-diasca-time-management-algorithm">
<h2><a class="toc-backref" href="#id175">Sim-Diasca Time Management Algorithm</a></h2>
<div class="section" id="general-principles">
<h3>General Principles</h3>
<p><span class="raw-html"><center><img src="xkcd-debugger.png" id="responsive-image-medium"></img></center></span>
</p>
<div class="section" id="scheduling-approach">
<h4>Scheduling Approach</h4>
<p>Sim-Diasca is based on approach B, i.e. it uses a synchronous (discrete time, <em>time-stepped</em>) algorithm for time management.</p>
<p>It has been deemed to be the most interesting trade-off between algorithmic complexity and scalability of the result. The manageable complexity of this approach allowed to bet on a rather advanced scheduler, featuring notably:</p>
<ul class="simple">
<li>massive scalability, thanks to a fully parallel and distributed mode of operation yet with direct actor communication (i.e. inter-actor messages are never collected into any third-party agenda)</li>
<li>the ability to automatically jump over any number of idle ticks</li>
<li>the &quot;zero time bias&quot; feature, allowing to avoid any model-level latency in virtual time (causality solving does not make the simulation time drift)</li>
</ul>
<p>The simplicity of approach A was surely tempting, but when it evaluates one model instance at a time, the other approaches can potentially evaluate for example 35 millions of them in parallel. Fearless researchers might go for C or D. Industrial feedback about approach B was encouraging.</p>
</div>
<div class="section" id="architecture">
<h4>Architecture</h4>
<p>In Sim-Diasca, the scheduling service is implemented thanks to an arbitrarily deep hierarchy of distributed time managers. Their role is to agree on the progress of simulation time and to allow model instances (actors) to be evaluated as much as possible in parallel.</p>
<p>More precisely, the simulation time is split according to a fundamental simulation frequency (ex: 50 Hz, or vastly inferior ones for yearly temporalities) which defines the finest tick granularity (ex: 20 milliseconds) on which model instances are free to develop their behaviour, however erratic and complex they may be.</p>
<p>Of course the time management service may then be able to perform &quot;time-warp&quot;, i.e. to skip any series of ticks that it can determine as being idle.</p>
<p>However Sim-Diasca introduces a still finer, more flexible time management, as any scheduled tick will be automatically split by the engine in the minimal series of logical moments (named <em>diascas</em>) that is necessary to sort out causality <a class="footnote-reference" href="#id15" id="id14">[7]</a>. This also allow for arbitrarily complex interactions while not inducing any time biases. And the point is that, inside a diasca, the engine is able to evaluate all scheduled model instances concurrently (in a parallel, possibly distributed way), and efficiently.</p>
<table class="docutils footnote" frame="void" id="id15" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id14">[7]</a></td><td>A simulation timestamp can be represented as a <tt class="docutils literal">(tick,diasca)</tt> pair: when a new tick T is scheduled, it will start at diasca zero, and the current diasca will be incremented as interactions are chained.
More precisely, if the current timestamp is <tt class="docutils literal">(T,D)</tt> and a then scheduled actor A1 performs an interaction, i.e. sends an inter-actor message M (a method, possibly with parameters) to an actor A2, then M will be sent by A1 and received by A2 during <tt class="docutils literal">(T,D)</tt>, yet A2 will process M (once automatically reordered with the other received messages, if any) only at <tt class="docutils literal">(T,D+1)</tt>, ensuring causality is met (effects happening strictly after their causes). A2, when executing the method corresponding to M, will be free to send in turn any number of actor messages to any actors; as soon as at least one message has been sent by one actor, <tt class="docutils literal">(T,D+2)</tt> will be scheduled, and so on until no actor has a message to send. It will then be the last diasca for this tick <tt class="docutils literal">T</tt>, and, if not terminated, the simulation will schedule the next tick according to the overall agenda, i.e. the next simulation timestamp will be  <tt class="docutils literal"><span class="pre">(T',0)</span></tt>, with <tt class="docutils literal">T' &gt; T</tt>.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="implementation">
<h4>Implementation</h4>
<p>The message-based synchronisation is mostly implemented in the <tt class="docutils literal">class_TimeManager</tt> module; the complementary part of the applicative protocol is in the <tt class="docutils literal">class_Actor</tt> module, including the logic implementing the automatic message reordering (which happens to be fully concurrent).</p>
<p>Both can be found in the <tt class="docutils literal"><span class="pre">sim-diasca/src/core/src/scheduling</span></tt> directory.</p>
</div>
</div>
<div class="section" id="simplified-mode-of-operation">
<h3>Simplified Mode of Operation</h3>
<p>A time step will be generally mentioned here as a <em>simulation tick</em>.</p>
<p>Sim-Diasca uses a special technical component - a process with a specific role - which is called the <strong>Time Manager</strong> and acts as the simulation scheduler.</p>
<p>It will be the sole controller of the overall simulation time. Once created, it is notably given:</p>
<ul class="simple">
<li>a simulation start time, for example: <tt class="docutils literal">Thursday, November 13, 2008 at 3:19:00 PM</tt>, from which the initial simulation tick will be deduced</li>
<li>an operating frequency, for example: 50 Hz, which means each virtual second will be split in 50 periods, with therefore a (constant) simulation tick whose duration - in virtual time - will be <tt class="docutils literal">1000/50 = 20 ms</tt>; this time step must be chosen appropriately, depending on the system to simulate <a class="footnote-reference" href="#id17" id="id16">[8]</a></li>
<li>an operating mode, i.e. batch or interactive</li>
</ul>
<table class="docutils footnote" frame="void" id="id17" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id16">[8]</a></td><td>Currently 50 Hz has been the highest frequency that was deemed useful for our application cases, knowing that this corresponded to a device scheduled by the 50 Hz electric power transmission.</td></tr>
</tbody>
</table>
<p>In batch mode, the simulation will run as fast as possible, whereas in interactive mode, the simulator will be kept on par with the user (wall-clock) time. If the simulation fails to do so (i.e. if it cannot run fast enough), the user is notified of the scheduling failure, and the simulator tries to keep on track, on a best-effort basis.</p>
<p>Not depending on the operating mode, when started the <tt class="docutils literal">Time Manager</tt> will always follow the same algorithm, shown below:</p>
<p><span class="raw-html"><center><img src="tick-timescale-english.png" id="responsive-image-intermediate"></img></center></span>
</p>
<p>At the beginning of a new tick, the <tt class="docutils literal">Time Manager</tt> will notify all subscribed simulation actors that a new tick began, thanks to a <tt class="docutils literal">top</tt> message.</p>
<p>Each actor will then process all the actor messages it received during the last tick, reordered appropriately, as explained in the <a class="reference internal" href="#maintaining-causality">Maintaining Causality</a> and <a class="reference internal" href="#maintaining-reproducibility">Maintaining Reproducibility</a> sections. This deferred message processing ensures the simulation time always progresses forward, which is a property that simplifies considerably the time management.</p>
<p><span class="raw-html"><center><img src="xkcd-time_machines.png" id="responsive-image-medium"></img></center></span>
</p>
<p>Processing these actor messages may imply state changes in that actor and/or the sending of actor messages to other actors.</p>
<p>Once all past messages have been processed, the actor will go on, and act according to its spontaneous behaviour. Then again, this may imply state changes in that actor and/or the sending of actor messages to other actors.</p>
<p>Finally, the actor reports to the time manager that it finished its simulation tick, thanks to a <tt class="docutils literal">done</tt> message.</p>
<p>The key point is that all actors can go through these operations <em>concurrently</em>, i.e. there is no limit on the number of actors that can process their tick simultaneously.</p>
<p>Therefore each simulation tick will not last longer than needed, since the time manager will determine that the tick is over as soon as the last actor reported it has finished processing its tick.</p>
<p>More precisely, here each simulation tick will last no longer than the duration took by the actor needing the most time to process its tick, compared to a centralised approach where it would last as long as the sum of all the durations needed by each actor. This is a tremendous speed-up indeed.</p>
<p>Then the time manager will determine that the time for the next tick has come.</p>
</div>
<div class="section" id="actual-mode-of-operation">
<h3>Actual Mode of Operation</h3>
<p>For the sake of clarity, the previous description relied on quite a few simplifications, that are detailed here.</p>
<div class="section" id="distributed-mode-of-operation">
<h4>Distributed Mode Of Operation</h4>
<p>The scheduling service has been presented as if it was centralised, which is not the case: it is actually fully distributed, based on a hierarchy of <tt class="docutils literal">Time Manager</tt> instances.</p>
<p>Indeed they form a scheduling tree, each time manager being able to federate any number of child managers and of local actors. They recursively establish what is the next tick to schedule, each based on its own sub-hierarchy. The root time manager is then able to determine what is the next overall tick which is to be scheduled next (jumping then directly over idle ticks).</p>
<p>The current deployment setting is to assign exactly one time manager per computing host, and, for a lower latency, to make all time managers be direct children of the root one (thus the height of the default scheduling tree is one).</p>
<p>Other settings could have been imagined (balanced tree of computing hosts, one time manager per processor or even per core - rather than one per host, etc.).</p>
</div>
<div class="section" id="actual-fine-grain-scheduling">
<h4>Actual Fine-Grain Scheduling</h4>
<p>The simulation time is discretised into fundamental time steps (<tt class="docutils literal">ticks</tt>, which are positive, unbounded integers) of equal duration in virtual time (ex: 10ms, for a simulation running at 100 Hz) that are increased monotonically.</p>
<p>From the user-specified simulation start date (ex: <tt class="docutils literal">Monday, March 10, 2014 at 3:15:36 PM</tt>), a simulation initial tick <tt class="docutils literal">Tinitial</tt> is defined (ex: <tt class="docutils literal">Tinitial = 6311390400000</tt>).</p>
<p><span class="raw-html"><center><img src="xkcd-unique_date.png" id="responsive-image-tiny"></img></center></span>
</p>
<p><tt class="docutils literal">Tick offsets</tt> can be used instead of absolute ticks; these offsets are defined as a difference between two ticks, and represent a duration (ex: at 100Hz, <tt class="docutils literal">Toffset=15000</tt> will correspond to a duration of 2 minutes and 30 seconds in virtual time).</p>
<p>Internally, actors use mostly tick offsets defined relatively to the simulation initial tick.</p>
<p>During a tick T, any number of logical moments (<tt class="docutils literal">diascas</tt>, which are positive, unbounded integers) can elapse. Each tick starts at diasca D=0, and as many increasing diascas as needed are created to solve causality.</p>
<p>All diascas of a tick occur at the same simulation timestamp (which is this tick), they solely represent logical moments into this tick, linked by an &quot;happen before&quot; relationship: if two events E1 and E2 happen respectively at D1 and D2 (both at the tick T), and if D1 &lt; D2, then D1 happened before D2.</p>
<p>So the full timestamp for an event is a Tick-Diasca pair, typically noted as <tt class="docutils literal">{T,D}</tt>.</p>
<p>Diascas allows to manage causality despite parallelism: effects will always happen <em>strictly later</em> than their cause, i.e. at the very least on the diasca immediately following the one of the cause, if not in later diascas or even ticks, depending on the intended timing of the causal mechanism: causes can follow effects either immediately or after any specified duration in virtual time <a class="footnote-reference" href="#id19" id="id18">[9]</a>.</p>
<table class="docutils footnote" frame="void" id="id19" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id18">[9]</a></td><td>Durations shall been specified by modellers regardless of a simulation frequency, in absolute terms (ex: &quot;6 minutes and 20 seconds&quot;), rather than directly as a number of ticks: the engine is indeed able to convert the former to the latter at runtime, and to stop automatically if the conversion resulted in a rounding error higher than a threshold (either the default one, or a user-specified one for that duration). As much as possible, models should be uncoupled from the simulation frequency.</td></tr>
</tbody>
</table>
<p>This is what happens when an actor A1 sends a message to an actor A2 at tick T, diasca D (i.e. at {T,D}). A2 will process this message at {T,D+1}. If needing to send back an answer, it may do it directly (while still at {T,D+1}), and A1 will be able to process it at {T,D+2}.</p>
<p>This allows immediate exchanges in virtual time (we are still at tick T - and A2 could have similarly triggered any number of third parties before answering to A1, simply resulting in an increase of the current diasca), while still being massively parallel and preserving causality and other expected simulation properties. Of course non-immediate exchanges are also easily done, since A2 may wait for any number of ticks before sending its answer to A1.</p>
</div>
<div class="section" id="consensus-on-the-end-of-tick">
<h4>Consensus on the End of Tick</h4>
<p>There must be a consensus between the actors to decide whether the current tick can be ended. One of the most effective way of obtaining that consensus is to rely on an arbitrator (the <tt class="docutils literal">Time Manager</tt>) <em>and</em> to force the acknowledgement of all actor messages, from the recipient to the sender.</p>
<p>In the lack of such of an acknowledgement, if, at tick T, an actor A1 sent a message M to an actor A2, which is supposed here to have already finished its tick, and then sent immediately a <tt class="docutils literal">done</tt> message to the <tt class="docutils literal">Time Manager</tt> (i.e. without waiting for an acknowledgement from A2 and deferring its own end of tick), then there would exist a race condition for A2 between the message M and the <tt class="docutils literal">top</tt> notification of the <tt class="docutils literal">Time Manager</tt> for tick T+1.</p>
<p>There would exist no guarantee that M was received before the next <tt class="docutils literal">top</tt> message, and therefore the M message could be wrongly interpreted by A2 as being sent from T+1 (and thus processed in T+2), whereas it should be processed one tick earlier.</p>
<p>This is the reason why, when an actor has finished its spontaneous behaviour, it will:</p>
<ul class="simple">
<li>either end its tick immediately, if it did not send any actor message this tick</li>
<li>or wait to have received all pending acknowledgements corresponding to the actor messages it sent this tick, before ending its tick</li>
</ul>
</div>
<div class="section" id="scheduling-cycle">
<h4>Scheduling Cycle</h4>
<p>Before interacting with others, each actor should register first to the time manager. This allows to synchronise that actor with the current tick and then notify it when the first next tick will occur.</p>
<p>At the other end of the scheduling cycle, an actor should be able to be withdrawn from the simulation, for any reason, including its removal decided by its model.</p>
<p>To do so, at the end of the tick, instead of sending to the <tt class="docutils literal">Time Manager</tt> a <tt class="docutils literal">done</tt> message, it will send a <tt class="docutils literal">terminated</tt> message. Then the time manager will unregister that actor, and during the next tick it will send it its last <tt class="docutils literal">top</tt> message, upon which the actor will be considered allowed to be de-allocated.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">The removal cannot be done during the tick where the actor sent its <tt class="docutils literal">terminated</tt> message, as this actor might still receive messages from other actors that it will have to acknowledge, as explained in the previous section.</p>
</div>
<p>As for the management of the time manager itself, it can be started, suspended, resumed, stopped at will.</p>
</div>
<div class="section" id="criterion-for-simulation-ending">
<h4>Criterion for Simulation Ending</h4>
<p>Once started, a simulation must evaluate on which condition it should stop. This is usually based on a termination date (in virtual time), or when a model determines that an end condition is met.</p>
</div>
<div class="section" id="need-for-higher-level-actor-identifiers">
<h4>Need for Higher-Level Actor Identifiers</h4>
<p>When actors are created, usually the underlying software platform (ex: the multi-agent system, the distribution back-end, the virtual machine, the broker, etc.) is able to associate to each actor a unique <em>technical distributed identifier</em> (ex: a platform-specific process identifier, a networked address, etc.) which allows to send messages to this actor regardless of the location where it is instantiated.</p>
<p>However, as the reordering algorithms rely - at least partly - onto the senders of the messages to sort them, the technical distributed identifiers are not enough here.</p>
<p>Indeed, if the same simulation is run on different sets of computers, or simply if it runs on the same computers but with a load-balancer which takes into account the effective load of the computing nodes, then, from a run to another, the same logical actor may not be created on the same computer, and hence may have a different technical distributed identifier, which in turn will result in different re-orderings being enforced and, finally, different simulation outcomes to be produced, whereas for example reproducibility was wanted.</p>
<p>Therefore higher-level identifiers must be used, named here <em>actor identifiers</em>, managed so that their value will not depend on the technical infrastructure.</p>
<p>Their assignment is better managed if the load balancer take care of them.</p>
<p>On a side note, this actor identifier would allow to implement dynamic actor migration quite easily.</p>
</div>
<div class="section" id="load-balancing">
<h4>Load-balancing</h4>
<p>Being able to rely on a load balancer to create actors over the distributed resources allows to run simulations more easily (no more hand-made dispatching of the actors over varying sets of computers) and, with an appropriate placing heuristic, more efficiently.</p>
<p>Moreover, as already mentioned, it is the natural place to assign actor identifiers.</p>
<p>The usual case is when multiple actors (ex: deployment policies) need to create new actors simultaneously (at the same tick).</p>
<p>In any case the creating actors will rely on the engine-provided API (ex: in <tt class="docutils literal">class_Actor</tt>, for creations in the course of the simulation, <tt class="docutils literal">create_actor/3</tt> and <tt class="docutils literal">create_placed_actor/4</tt> shall be used), which will result in sending actor messages to the load balancer, which is itself a (purely passive) actor, scheduled by a time manager. These creation requests will be therefore reordered as usual, and processed one by one.</p>
<p>As for initial actor creations, still in <tt class="docutils literal">class_Actor</tt>, different solutions exist as well:</p>
<ul class="simple">
<li><tt class="docutils literal"><span class="pre">create_initial_actor/{2,3}</span></tt>, for a basic creation with no specific placement</li>
<li><tt class="docutils literal"><span class="pre">create_initial_placed_actor/{3,4}</span></tt>, for a creation based on a placement hint</li>
<li><tt class="docutils literal"><span class="pre">create_initial_actors/{1,2}</span></tt>, for an efficient (batched and parallel) creation of a (potentially large) set of actors, possibly with placement hints</li>
</ul>
<p>When the load balancer has to create an actor, it will first determine what is the best computing node on which the actor should be spawned. Then it will trigger the (synchronous and potentially remote) creation of that actor on that node, and specify what its Abstract Actor Identifier (AAI) will be (it is simply an integer counter, incremented at each actor creation).</p>
<p>As the operation is synchronous, for single creations the load balancer will wait for the actor until it has finished its first initialisation phase, which corresponds to the technical actor being up and ready, for example just having finished to execute its constructor.</p>
<p>Then the load balancer will have finished its role for that actor, once having stored the association between the technical identifier (PID) and the actor identifier (AAI), for later conversion requests (acting a bit like a naming service).</p>
</div>
<div class="section" id="actor-time-manager-relationships">
<h4>Actor - Time Manager Relationships</h4>
<p>We have seen how a load balancer creates an actor and waits for its construction to be over.</p>
<p>During this phase, that actor will have to interact with its (local) time manager: first the actor will request the scheduling settings (ex: what is the fundamental simulation frequency), then it will subscribe to its time manager (telling it how it is to be scheduled: step by step, passively, periodically, etc.), which will then answer by specifying all the necessary information for the actor to enter the simulation: what will be the current tick, whether the simulation mode targets reproducibility or ergodicity (in this latter case, an appropriate seed will be given to the actor), etc.</p>
<p>These exchanges will be based on direct (non-actor) messages, as their order does not matter and as they all take place during the same simulation tick, since the load balancer is itself a scheduled actor that will not terminate its tick as long as the actors have not finished their creation.</p>
</div>
<div class="section" id="related-agents">
<h4>Related agents</h4>
<p>Time managers (implemented in <tt class="docutils literal">class_TimeManager</tt>) are at the heart of the engine; they interact mostly with:</p>
<ul class="simple">
<li>other time managers, for synchronisation</li>
<li>with actors (inheriting, directly or not, from <tt class="docutils literal">class_Actor</tt> or its child classes, like <tt class="docutils literal">class_BroadcastingActor</tt>), in order to schedule them</li>
</ul>
<p>Time managers are created by the deployment manager (<tt class="docutils literal">class_DeploymentManager</tt>) and may interact with its computing host managers (<tt class="docutils literal">class_ComputingHostManager</tt>).</p>
<p>The actors that time managers schedule are created by the load balancer (<tt class="docutils literal">class_LoadBalancer</tt>), which does its best to even the load on the corresponding computing hosts.</p>
<p>Time managers also drive the data-exchanging distributed service (<tt class="docutils literal">class_DataExchanger</tt>), and the performance tracker (<tt class="docutils literal">class_PerformanceTracker</tt>) monitors them (among other agents).</p>
</div>
<div class="section" id="actor-start-up-procedure">
<h4>Actor Start-up Procedure</h4>
<p>When models become increasingly complex, more often than not they cannot compute their behaviour and interact with other models <em>directly</em>, i.e. as soon as they have been synchronised with the time manager.</p>
<p>For instance, quite often models need some random variables to define their initial state. This is the case for example of low voltage meshes, which typically have to generate at random their supply points and their connectivity. As explained in the <a class="reference internal" href="#actual-management-of-randomness">Actual Management of Randomness</a> section, this cannot be done when the model is not synchronised yet with the time manager: reproducibility would not be ensured then.</p>
<p>Therefore the complete initialisation of such an actor cannot be achieved from its constructor only, and it needs an appropriate mechanism to determine at which point it is finally ready.</p>
<p>Moreover, as the start-up of an actor may itself depend on the start-up of other actors (ex: the low-voltage mesh needs to wait also for its associated stochastic deployment policy to be ready, before being able in turn to live its life), Sim-Diasca provides a general mechanism that allows any actor to:</p>
<ul class="simple">
<li>wait for any number of other actors to be ready</li>
<li>perform then some model-specific operations</li>
<li>declare itself ready, immediately or not, and notify all actors (if any) that were themselves waiting for that actor</li>
</ul>
<p>The graph of waiting actors will be correctly managed as long as it remains acyclic.</p>
<p>This automatic coordinated start-up is directly available when inheriting from the <tt class="docutils literal">Actor</tt> class.</p>
</div>
<div class="section" id="non-termination-of-ticks">
<h4>Non-Termination Of Ticks</h4>
<p>Some models can be incorrectly implemented. They may crash or never terminate, or fail to report they finished their tick.</p>
<p>The simulator will wait for them with no limit of time (as there is no a priori upper bound to the duration needed by a model to process its tick), but in batch mode a <tt class="docutils literal">watchdog</tt> process is automatically triggered.</p>
<p>It will detect whenever the simulation is stalled and notify the user, telling her which are the guilty process(es), to help their debugging.</p>
<p>There could different reasons why an actor does not report its end of tick, notably:</p>
<ul class="simple">
<li>its internal logic may be incorrectly implemented, resulting in that actor being unable to terminate properly (ex: infinite loop)</li>
<li>the lingering actor (actor A) might be actually waiting for the acknowledgement from another actor (actor B) to which that actor A sent an actor message this tick</li>
</ul>
<p>In the latter case the guilty process is in fact actor B, not actor A.</p>
<p>Both cases should be easy to interpret, as the time manager will gently nudge the lingering actors, ask them what they are doing, and then output a complete diagnosis, both in the console and in the simulation traces:</p>
<pre class="literal-block">
Simulation currently stalled at tick #3168318240271, waiting for following actor(s): [&lt;0.50.0&gt;,&lt;0.57.0&gt;].
Current tick not ended yet because:
 + actor &lt;0.50.0&gt; is waiting for an acknowledgement from [&lt;0.1.0&gt;]
 + actor &lt;0.57.0&gt; is waiting for an acknowledgement from [&lt;0.1.0&gt;,&lt;0.38.0&gt;]
</pre>
<p>Now moreover the engine is able most of the time to also specify the name of the actors that are involved, for a better diagnosis.</p>
</div>
<div class="section" id="distributed-execution-in-practise">
<h4>Distributed Execution In Practise</h4>
<p>For the scenario test case to be able to run a simulation on a set of computing nodes from the user node, that node must be able to trigger the appropriate Sim-Diasca daemon on each computing node.</p>
<p>To do so, a SSH connection is established and the appropriate daemon is run. The recommended set-up is to be able to run a password-less connection to the computing nodes. This involves the prior dispatching of a private key is these nodes, and the use of the corresponding public key by the user host.</p>
<p>See, in the <tt class="docutils literal"><span class="pre">Sim-Diasca</span> Installation Guide</tt>, the <tt class="docutils literal">Enabling The Distributed Mode Of Operation</tt> section for the corresponding technical procedure.</p>
</div>
<div class="section" id="model-development">
<h4>Model Development</h4>
<p>All generic mechanisms discussed here (actor subscription, synchronisation, reordering and acknowledgement of actor messages, removal, waiting to be ready, etc.) have been abstracted out and implemented in a built-in <tt class="docutils literal">Actor</tt> class, to further ease the development of models.</p>
<p>They should therefore inherit from that class and, as a consequence, they just have to focus on their behavioural logic.</p>
</div>
<div class="section" id="of-times-and-durations">
<h4>Of Times And Durations</h4>
<div class="section" id="user-time-versus-simulation-time">
<h5>User Time Versus Simulation Time</h5>
<p>Regarding simulation timing, basically in <strong>batch</strong> mode the actual <em>user time</em> (i.e. wall-clock time) is fully ignored, and the simulation engine handles only timestamps expressed in <em>virtual time</em>, also known as <em>simulation time</em>. The objective there is to evaluate model instances as fast as possible, regardless of the wall-clock time.</p>
<p>In <strong>interactive</strong> mode, the engine still bases all its computations on virtual time, but it forces the virtual time to match the real time by slowing down the former as much as needed to keep it on par with the latter (possibly making use of a scale factor).</p>
<p>Therefore the engine mostly takes care of simulation time, regardless of any actual duration measured in user time (except for technical time-outs).</p>
</div>
<div class="section" id="units-of-virtual-time-versus-simulation-ticks">
<h5><em>Units</em> of Virtual Time Versus Simulation <em>Ticks</em></h5>
<p>Virtual time can be expressed according to various forms (ex: a full time and date), but the canonical one is the <strong>tick</strong>, a quantum of virtual time whose duration is set by the simulation user (see the <tt class="docutils literal">tick_duration</tt> field of the <tt class="docutils literal">simulation_settings</tt> record). For example the duration (in virtual time) of each tick can be set to 20ms to define a simulation running at 50Hz.</p>
<p><strong>Ticks</strong> are absolute ticks (the number of ticks corresponding to the duration, initially evaluated in gregorian seconds, between year 0 and the specified date and time), ans as such are often larger integers.</p>
<p>For better clarity and performances, the simulation engine makes heavy use of <strong>tick offsets</strong>, which correspond to the number of ticks between the simulation initial date (by default a simulation starts on Saturday, January 1st, 2000 at midnight, in virtual time) and the specified timestamp. So <tt class="docutils literal">#4000</tt> designates a tick offset of 4000 ticks.</p>
<p>Note that one can sometimes see expressions like <tt class="docutils literal">this happened at tick #123</tt>. The dash character (<tt class="docutils literal">#</tt>) implies that this must be actually understood as a tick offset, not as an (absolute) tick.</p>
<p>Models should define all durations in terms of (non-tick) time units, as actual, plain durations (ex: 15 virtual seconds), rather than directly in ticks or tick offsets (like <tt class="docutils literal">#143232</tt>). Indeed these former durations are absolute, context-less, whereas the corresponding number of simulation ticks depends on the simulation frequency: one surely does not want to have to update all the timings used in all models as soon as the overall simulation frequency has been modified.</p>
<p>So the recommended approach for models (implemented in child classes of <tt class="docutils literal">class_Actor</tt>) is to define, first, durations in time units (ex: 15s), and then only to convert them, as soon as an actor is created (i.e. at simulation-time), into a corresponding number of ticks (ex: at 2Hz, 15s becomes 30 ticks) thanks to the <tt class="docutils literal"><span class="pre">class_Actor:convert_seconds_to_ticks/{2,3}</span></tt> helper functions <a class="footnote-reference" href="#id21" id="id20">[10]</a>.</p>
<table class="docutils footnote" frame="void" id="id21" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id20">[10]</a></td><td>A corresponding method (<tt class="docutils literal">convertSecondsToTicks/2</tt>) could be used instead, however this method has virtually no chance of being overloaded any day, so using the helper functions is not a problem.</td></tr>
</tbody>
</table>
<p>This <tt class="docutils literal">class_Actor:convert_seconds_to_ticks/2</tt> function converts a duration into a non-null integer number of ticks, therefore a rounding is performed, and the returned tick count is at least one (i.e. never null), in order to prevent that a future action ends up being planned for the current tick instead of being in the future, as then this action would never be triggered.</p>
<p>Otherwise, for example a model could specify a short duration that, if run with lower simulation frequencies, could be round off to zero. Then an actor could behave that way:</p>
<ul class="simple">
<li>at tick #147: set action tick to current tick (147) + converted duration (0) thus to #147; declaring then its end of tick</li>
<li>next tick: #148, execute:</li>
</ul>
<pre class="code erlang literal-block">
<span class="k">case</span> <span class="nv">CurrentTick</span> <span class="k">of</span>

  <span class="nv">ActionTick</span> <span class="o">-&gt;</span>

      <span class="n">do_action</span><span class="p">();</span>
      <span class="p">...</span>
</pre>
<p>However <tt class="docutils literal">CurrentTick</tt> would be 148 or higher, never matching <tt class="docutils literal">ActionTick=147</tt>, thus the corresponding action would never be triggered.</p>
</div>
<div class="section" id="ticks-versus-tick-offsets">
<h5>Ticks Versus Tick Offsets</h5>
<p><em>Ticks</em> are absolute ticks (thus, generally, huge integers), whereas <em>tick offsets</em> are defined relatively to the absolute tick corresponding to the start of the simulation.</p>
<p>Of course both are in virtual time only (i.e. in simulation time).</p>
<p>Tick offsets are used as much as possible, for clarity and also to improve performances: unless the simulation runs for a long time or with an high frequency, tick offsets generally fit into a native integer of the computing host. If not, Erlang will transparently expand them into infinite integers, which however incur some overhead.</p>
<p>So, in the Sim-Diasca internals, everything is based on <em>tick offsets</em>, and:</p>
<ul class="simple">
<li>when needing <em>absolute ticks</em>, the engine just adds to the target offset the initial tick of the simulation</li>
<li>when needing a <em>duration</em> in simulation time, the engine just converts tick offsets into (virtual, floating-point) seconds</li>
<li>when needing a <em>date</em> in simulation time, the engine just converts a number of seconds into a proper gregorian date</li>
</ul>
</div>
<div class="section" id="starting-times">
<h5>Starting Times</h5>
<p>By default when a simulation is run, it starts at a fixed initial date, in virtual time <a class="footnote-reference" href="#id23" id="id22">[11]</a>, i.e. Friday, January 1, 2010, at midnight. Of course this default date is generally to be set explicitly by the simulation case, for example thanks to the <tt class="docutils literal">setInitialTick/2</tt> or <tt class="docutils literal">setInitialSimulationDate/3</tt> methods. These timings are the one of the simulation as a whole.</p>
<table class="docutils footnote" frame="void" id="id23" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id22">[11]</a></td><td>This arbitrary date was previously set to the current real time, so that the simulations started from the present time of the user. However we could then have variations in the results despite reproducible simulations, if using models depending on the absolute (virtual) date (ex: in the simulation, <tt class="docutils literal">each 1st of April, do something</tt>).</td></tr>
</tbody>
</table>
<p>Simulations will always start at tick offset #0 (constant offset against a possibly user-defined absolute tick) and diasca 0.</p>
<p>On the actor side, each instance has its own <tt class="docutils literal">starting_time</tt> attribute, which records at which global overall simulation tick it was synchronized to the simulation.</p>
</div>
</div>
</div>
<div class="section" id="implementing-an-actor">
<h3>Implementing an Actor</h3>
<p>Each model must inherit, directly or not, from the actor class (<tt class="docutils literal">class_Actor</tt>).
As a consequence, its constructor has to call the one of at least one mother class.</p>
<p>Each constructor should start by calling the constructors of each direct parent class, preferably in the order in which they were specified; a good practice is to place the model-specific code of the constructor after the call to these constructors (not before, not between them).</p>
<p>An actor determines its own scheduling by calling oneways <a class="footnote-reference" href="#id25" id="id24">[12]</a> helper functions offered by the engine (they are defined in the <tt class="docutils literal">class_Actor</tt> module):</p>
<ul class="simple">
<li><tt class="docutils literal">addSpontaneousTick/2</tt> and <tt class="docutils literal">addSpontaneousTicks/2</tt>, to declare additional ticks at which this instance requires to develop a future spontaneous behaviour (at their diasca 0)</li>
<li><tt class="docutils literal">withdrawnSpontaneousTick/2</tt> and <tt class="docutils literal">withdrawnSpontaneousTicks/2</tt>, to withdraw ticks that were previously declared for a spontaneous behaviour but are not wanted anymore</li>
<li><tt class="docutils literal">declareTermination/1</tt>, to trigger the termination of this actor</li>
</ul>
<table class="docutils footnote" frame="void" id="id25" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id24">[12]</a></td><td>Note that corresponding helper functions are also defined (ex: <tt class="docutils literal">class_Actor:add_spontaneous_tick/2</tt>); they can be called directly if the user is sure that he will never need to override their oneway counterpart.</td></tr>
</tbody>
</table>
<p>An actor is to call these helper functions from its <tt class="docutils literal">actSpontaneous/1</tt> oneway or any of its actor oneways. This includes its <tt class="docutils literal">onFirstDiasca/2</tt> actor oneway, which is called as soon as this actor joined the simulation, so that it can define at start-up what it intends to do next, possibly directly at this very diasca (no need for example to wait for the first next tick).</p>
<p>Even if actors are evaluated in parallel, the code of each actor is purely sequential (as any other Erlang process). Hence writing a behaviour of an actor is usually quite straightforward, as it is mostly a matter of:</p>
<ul class="simple">
<li>updating the internal state of that actor, based on the changes operated on the value of its attributes (which is an immediate operation)</li>
<li>sending actor message(s) to other actors (whose processing will happen at the next diasca)</li>
</ul>
<p>On each tick the engine will automatically instantiate as many diascas as needed, based on the past sending of actor messages and on the management of the life cycle of the instances.</p>
<p>So the model writer should consider diascas to be opaque values that just represent the &quot;happened before&quot; relationship, to account for causality; thanks to these logical moments which occur during the same slot of simulated time, effects always happen strictly after their causes.</p>
<p>As a consequence, the model writer should not base a behaviour onto a specific diasca (ex: &quot;at diasca 7, do this&quot;); the model should send information to other instances or request updates from them (in both cases thanks to other messages) instead.</p>
<p>So, for example, if an actor asks another for a piece for information, it should just expect that, in a later diasca (or even tick, depending on the timeliness of the interaction), the target actor will send it a message back with this information.</p>
<p>The point is that if the model-level protocol implies that a target actor is expected to send back an answer, it <em>must</em> do so, but at any later, unspecified time; not necessarily exactly two diascas after the request was sent: we are in the context of asynchronous message passing.</p>
<p>This allows for example an actor to forward the request to another, to fetch information from other actors, or simply to wait the duration needed (in virtual time) to account for any modelled processing time for that request (ex: &quot;travelling from A to B shall last for 17 minutes&quot;).</p>
<p>When actor decides it is to leave the simulation and be deleted, it has to ensure that:</p>
<ul class="simple">
<li>it has withdrawn all the future spontaneous ticks it may have already declared</li>
<li>it calls its <tt class="docutils literal"><span class="pre">declareTermination/{1,2}</span></tt> oneway (or the <tt class="docutils literal"><span class="pre">class_Actor:declare_termination/{1,2}</span></tt> helper function)</li>
</ul>
<p>The actor must ensure that no other actor will ever try to interact with it once it will have terminated, possibly using its deferred termination procedure to notify these actors that from now they should &quot;forget&quot; it.</p>
<p>Please refer to the <tt class="docutils literal"><span class="pre">Sim-Diasca</span> Developer Guide</tt> for more information.</p>
<p></p>
</div>
<div class="section" id="latest-enhancements">
<h3>Latest Enhancements</h3>
<p>These evolutions have been implemented for the <tt class="docutils literal">2.0.x</tt> versions of Sim-Diasca, starting from 2009.</p>
<div class="section" id="distributed-time-manager">
<h4>Distributed Time Manager</h4>
<p>The <tt class="docutils literal">Time Manager</tt> was described as a centralised actor, but actually, for increased performances, the time management service is fully distributed, thanks to a hierarchy of time managers.</p>
<p>By default there is exactly one time manager per computing host, federating in an Erlang node all cores of all its processors and evaluating all the actors that are local to this host (and only them).</p>
<p>One of these time managers is selected (by the deployment manager) as the root time manager, to be the one in charge of the control of the virtual time. The other time managers are then its direct children (so the height of the scheduling tree is by default equal to 1).</p>
<p>Other kinds of trees could be chosen: they might be unbalanced, have a different heights (ex: to account for multiple clusters/processors/cores), etc., as shown in the physical diagram below:</p>
<p><span class="raw-html"><center><img src="Sim-Diasca-physical-dispatching-english.png" id="responsive-image-large"></img></center></span>
</p>
<p>The overall objective is to better make use of the computing architecture and also to minimize the induced latency, which is of paramount importance for synchronous simulations (we want to be able to go through potentially short and numerous time-steps as fast as possible).</p>
<p>Two protocols are involved in terms of scheduling exchanges, as shown in the logical diagram:</p>
<ul class="simple">
<li>one for higher-level synchronisation, between time managers</li>
<li>another for lower-level actor scheduling, between a local time manager and the actors it drives</li>
</ul>
<p><span class="raw-html"><center><img src="Sim-Diasca-logical-dispatching-english.png" id="responsive-image-full"></img></center></span>
</p>
<p>Of course there will be many more actors than displayed on the diagram created on each computing node (typically dozens of thousands of them), therefore a lot of scheduling messages will be exchanged between these actors and their local time manager instance.</p>
<p>The point is that these (potentially numerous) messages will incur as little overhead as possible, since they will be exchanged inside the same computing node: only very few scheduling messages will have to cross the node boundaries, i.e. to be conveyed by the bandwidth-constrained network. We trade the number of messages (more numerous then) for their network cost, which is certainly a good operation.</p>
<p>The load balancer has to be an actor as well (the only special one, created at start-up), since, when the simulation is running, it must be able to enforce a consistent order in the actor creations, which, inside a time step, implies the use of the same message reordering as for other actors.</p>
<p>In the special case of the simulation set-up, during which the initial state of the target system is to be defined, the initial actors have to be created, <em>before</em> the simulation clock is started. Only one process (generally, directly the one corresponding to the simulation case being run; otherwise the one of a scenario) is expected to create these initial actors. Therefore there is no reordering issues here <a class="footnote-reference" href="#id27" id="id26">[13]</a>.</p>
<table class="docutils footnote" frame="void" id="id27" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id26">[13]</a></td><td>However race conditions must be avoided there (between creations and also with the simulation start), this is why all initial creations are by design synchronous.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="advanced-scheduling">
<h4>Advanced Scheduling</h4>
<p>Each model may have its own temporality (ex: a climate model should imply a reactivity a lot lower than the one of an ant), and the most reactive models somehow dictate the fundamental frequency of the simulation.</p>
<p>A synchronous simulation must then be able to rely on a fundamental frequency as high as needed for the most reactive models, yet designed so that the other models, sometimes based on time-scales many orders of magnitude larger, can be still efficiently evaluated; scalability-wise, scheduling all actors at all ticks is clearly not an option (short of wasting huge simulation resources).</p>
<p>Moreover most models could not simply accommodate a sub-frequency of their choice (ex: being run at 2 Hz where the fundamental frequency is 100 Hz): their behaviour is not even periodic, as in the general case it may be fully erratic (ex: determined from one scheduling to the next) or passive (only triggered by incoming actor messages).</p>
<p>So Sim-Diasca offers not only a full control on the scheduling of models, with the possibility of declaring or withdrawing ticks for their spontaneous behaviours, but also can evaluate model instances in a rather efficient way: this is done fully in parallel, only the relevant actors are scheduled, and jumps over any idle determined to be idle are automatically performed (based on a consensus established by the time managers onto the next virtual time of interest; if running in batch, non-interactive, mode).</p>
<p>With this approach, and despite the synchronous simulation context (i.e. the use of a fixed, constant time step), the constraints applied to models are very close to the ones associated to event-driven simulations: the difference between these two approaches is then blurred, and we have here the best of both worlds (expressiveness and performance).</p>
<p>Finally, models ought to rely as much as possible on durations (in virtual time) that are expressed in absolute units (ex: &quot;I will wait for 2 hours and a half&quot;) instead of in a frequency-dependent way (ex: &quot;I will wait for 147 ticks&quot;): the conversion is done automatically at runtime by the engine (with a mechanism to handle acceptable thresholds in terms of relative errors due to the conversions), and the model specifications can be defined as independently as possible from the fundamental frequency chosen by the simulation case.</p>
</div>
<div class="section" id="zero-time-bias-modelling">
<h4>Zero-Time Bias Modelling</h4>
<p>Despite such a tick-level flexibility, by default time biases cannot be avoided whenever solving causality over ticks. Indeed, if, to ensure effects can only happen strictly after their causes, actor messages are evaluated on the tick immediately following the one of their sending, then for example all request/response exchange patterns will induce a two-tick latency.</p>
<p>This is unfortunate, as this latency is not wanted (not present in the models), and moreover depends on the fundamental frequency of the simulation. No immediate interaction can happen then, and if the target of a request needs to get information from other actors, the latency will still increase, with no upper limit.</p>
<p>To solve this significant modelling constraint, a zero-time bias feature has been added to Sim-Diasca (in 2012), introducing the notion of <em>diascas</em>, which are numbered logical moments inside a tick. A tick is then actually composed of an unbounded series of diascas, the first one (diasca 0) corresponding to the time when all actors having planned a spontaneous behaviour are to develop it. This may include the sending of actor messages, which in turn leads to the creation of the next diasca: each actor having received a message at a diasca will then be scheduled accordingly at the next diasca, and may then send messages, and so on.</p>
<p>As a consequence, the advanced scheduling, once enriched with diascas, is able to adapt to any model-level scheduling, and to support all interactions, either immediate or delayed, involving any communication chain underneath, in a causality-free way, and still in a massively parallel manner.</p>
<p>This flexibility regarding virtual time with no biases opens in turn new outlooks, for example to run in parallel, with Sim-Diasca, models that are written in the context of a mere sequential simulator, or, possibly, to go towards hybrid simulations, where some models are ruled by continuous equations yet are to be integrated with the discrete part of the simulation, helped by a numerical solver and further integration efforts.</p>
</div>
</div>
</div>
<div class="section" id="how-virtual-time-is-managed">
<h2><a class="toc-backref" href="#id176">How Virtual Time is Managed</a></h2>
<div class="section" id="virtual-time-versus-real-time">
<h3>Virtual Time Versus Real Time</h3>
<p>In batch mode, the time of the simulation (a.k.a. virtual time) is fully decorrelated from the user, wall-clock time: the engine will run as fast as possible, but will take as long as needed to fully evaluate simulated events. As a consequence, depending on the computer resources that are used, the resulting simulation might be faster or slower than real-time.</p>
<p>In interactive mode, provided that the hardware is able to run the simulation faster than the real time (possibly once a user-specified scaling factor has been applied), the engine will perform the necessary waiting so that the virtual time stays on par with the real time, allowing for possible third-party interactions with the simulation (actual devices, humans in the loop, etc.).</p>
</div>
<div class="section" id="quantification-timings">
<h3>Quantification &amp; Timings</h3>
<p>The virtual time is quantised, i.e. chunked into slices of equal durations (this is why Sim-Diasca is a discrete <em>synchronous</em> simulation engine). These periods are called <tt class="docutils literal">simulation ticks</tt> (often shorten as <tt class="docutils literal">ticks</tt> here).</p>
<p>For example, if the user specifies a tick duration of 20ms, then all durations will be multiples of 20ms (possibly 0ms - instant actions are supported) and the simulation will run at 50Hz.</p>
<p>Note that, for the models to be as much as possible uncoupled from the simulation frequency, they should express their timings in terms of actual &quot;absolute&quot; durations (ex: 100ms), rather than in terms of a number of ticks (ex: 5 ticks, at 50Hz).</p>
<p>This way, changing the simulation frequency (ex: setting it to 100Hz) will not imply that all models need to have their internal timing settings updated accordingly; indeed the engine is able to convert at runtime such actual durations into the relevant number of ticks, and will automatically ensure that the relative quantification error that is then induced stays below a threshold (either the default one or a user-defined one). If the quantification error is too high, the simulation will just report it and stop.</p>
</div>
<div class="section" id="spontaneous-behaviours-triggered-actions">
<h3>Spontaneous Behaviours &amp; Triggered Actions</h3>
<p>At its creation (whether initial or in the course of the simulation), each actor is scheduled once and is able to tell the engine at which tick (if any) it plans to develop its next spontaneous behaviour.</p>
<p>The engine (actually, the root time manager) is then able to know for each new tick whether it should be scheduled (this will happen iff at least one actor planned a spontaneous action for that tick). This knowledge will then allow the simulation to automatically jump over ticks that are known to be idle (i.e. with no actor to schedule). This feautre allows such a synchronous engine to provide features that are quite similar to the ones provided by asynchronous engines.</p>
<p>However, such a simulation would be useless if the actors could not interact with other actors: during a tick, any actor is able to trigger actions on any other actor.</p>
</div>
<div class="section" id="causality-diasca">
<h3>Causality &amp; Diasca</h3>
<p>To ensure, even in a parallel and/or distributed setting, that no cause can happen after its effects, the model instances can only communicate through the exchange of <em>actor messages</em>.</p>
<p>These messages can be seen as method calls which are properly intercepted, reordered and actually triggered by the engine.</p>
<p>For that the notion of diasca is introduced: each tick is evaluated as a series of diascas (starting at diasca <tt class="docutils literal">D=0</tt>), each of them being a logical moment inside that tick.</p>
<p>The purpose of diascas is to split each tick so that the consequence of an event (an actor message is sent at diasca <tt class="docutils literal">D</tt>) happens at the next diasca (the actor message is processed by its recipient at diasca <tt class="docutils literal">D+1</tt>).</p>
<p>These triggered actions may in turn result in new actor messages being sent, resulting in as many diascas as needed (<tt class="docutils literal">D+2</tt>, <tt class="docutils literal">D+3</tt>, etc.) being instantiated. The current tick will terminate only when no more diascas are requested, i.e. when there is no more immediate action declared. Then the next tick will be scheduled, and will start from diasca 0 again.</p>
<p>As such, diascas do not correspond to any specific duration within a tick (which is by design the finest observable simulated duration): their purpose is just to allow to determine that some events happen before others, i.e. to maintain causality.</p>
</div>
<div class="section" id="next-steps-time-generalization">
<h3>Next Steps: Time Generalization</h3>
<p>We plan to support the following time-related generalizations:</p>
<ul class="simple">
<li>to provide more flexibility and granularity, ticks could be of a parametrised type, i.e. a user-decided, simulation-specific type (ex: they could be floats instead of being integers), provided that they respect a (simple) contract specified by the engine; see <tt class="docutils literal">class_TimeManager:tick()</tt> for more details</li>
<li>to allow for recursive, imbricated/nested actors (actors containing, or being made of actors) and time refinement, diascas could be tuples (ex: <tt class="docutils literal">{17,5,0}</tt>, <tt class="docutils literal">{17,5,1}</tt>, etc. being between <tt class="docutils literal">{17,5}</tt> and <tt class="docutils literal">{17,6}</tt>, themselves being between <tt class="docutils literal">17</tt> and <tt class="docutils literal">18</tt>); see <tt class="docutils literal">class_TimeManager:diasca()</tt> for more details</li>
</ul>
</div>
</div>
<div class="section" id="in-depth-scheduling-implementation">
<h2><a class="toc-backref" href="#id177">In-Depth: Scheduling Implementation</a></h2>
<p>The simulations being distributed, the time management is itself distributed.</p>
<p>For that, a hierarchy of time managers is defined. Any scheduling tree can be defined, knowing that by default there will be one time manager per computing host (thus federating all cores of all local processors), and that they will form a flat tree: the engine will select an appropriate host for the root time manager (which will the sole manager of virtual time), and all others will be direct children of it.</p>
<p>Each time manager will schedule all the actors that are local to its node. This way, the large majority of scheduling messages will remain local to an Erlang node (i.e. potentially millions), and only the inter-manager ones (i.e. a few) will be exchanged over the network.</p>
<p>At the beginning of a tick T that is to be scheduled (as idle ticks will be jumped over automatically), the root time manager will trigger a <tt class="docutils literal">{beginTimeManagerTick,T}</tt> to all its direct children, which will forward it recursively to their own children, if any. Then each time manager will send a <tt class="docutils literal">{beginTick,T}</tt> messages to all its local actors that were scheduled for a spontaneous action this tick.</p>
<p>They will develop then each (in parallel) their spontaneous behaviour, being implicitly at diasca D0=0 for that tick T. Each actor can then update its state and/or send inter-actor messages.</p>
<p>Sending an actor message in asynchronous (not blocking) and results in the recipient actor storing the corresponding method call for a deferred execution (at the next diasca), and to send a <tt class="docutils literal">{scheduleTrigger,T,D}</tt> message to its own local time manager (which might already have terminated its diasca) so that it knows that this actor will have then to be triggered. Once its manager acknowledged that message (needed to prevent race conditions) thanks to a <tt class="docutils literal">`trigger_planned</tt> message, the recipient actor can then directly acknowledge to the sending actor that its message was processed, thanks to a <tt class="docutils literal"><span class="pre">{acknowledgeActorMessage,T,D,...}</span></tt> message.</p>
<p>Once a scheduled actor will have completed its spontaneous actions and received all acknowledgements for the actor messages it sent this diasca, it will notify its time manager by sending it a <tt class="docutils literal">{spontaneous_behaviour_completed,T,D0,DiascaOutcome}</tt> message, where DiascaOutcome is <tt class="docutils literal">no_diasca_requested</tt> if it did not send any actor message, or <tt class="docutils literal">next_diasca_needed</tt> otherwise.</p>
<p>Once all actors scheduled by a time manager complete a given diasca, this manager will report to its direct parent manager (if any) whether or not a new diasca is needed, by sending it a <tt class="docutils literal"><span class="pre">{childManagerSpontaneousActionsCompleted,...}</span></tt> message specifying, among other information, either <tt class="docutils literal">no_diasca_requested</tt> or <tt class="docutils literal">next_diasca_needed</tt>.</p>
<p>As soon as at least one actor among all the scheduled actors for this diasca sent at least one actor message, the root time manager is notified that a new diasca D (still for tick T) is needed. Time managers will then recursively receive a <tt class="docutils literal">{beginTimeManagerDiasca,T,D}</tt> message and in turn will send, to the actors they schedule that received during the previous diasca an actor message, a <tt class="docutils literal">{beginDiasca,T,D}</tt> message.</p>
<p>Each of these triggered actors will then reorder all the messages it received during the previous diasca, and then process them in turn, possibly changing its state and/or sending new actor messages, which will in turn lead to a new diasca being needed, etc.</p>
<p>Once such a triggered actor completed its diasca, it sends back to its time manager a <tt class="docutils literal">{diasca_completed,T,D}</tt> message. Once all the local actors triggered for this diasca did so, their time manager sends a <tt class="docutils literal"><span class="pre">{child_manager_diasca_completed,...}</span></tt> message specifying, among other information, either <tt class="docutils literal">no_diasca_requested</tt> or <tt class="docutils literal">next_diasca_needed</tt> to its own direct parent manager.</p>
<p></p>
</div>
</div>
<div class="section" id="sim-diasca-management-of-probabilistic-laws">
<h1><a class="toc-backref" href="#id178">Sim-Diasca Management of Probabilistic Laws</a></h1>
<div class="section" id="principles">
<h2><a class="toc-backref" href="#id179">Principles</a></h2>
<p>Quite often models rely on the use of stochastic variables.</p>
<p>Such variables - respecting a given probabilistic law - are very useful to model the behaviours of simulation actors.</p>
<p>For example, in terms of reliability, the approach is generally to define per-equipment average constants like the <em>Mean Time To Failure</em> (MTTF) and the <em>Mean Time To Repair</em> <a class="footnote-reference" href="#id29" id="id28">[14]</a> (MTTR), and to express reliability models thanks to stochastic laws parameterised by these constants (in that case: exponential and Gaussian laws, respectively).</p>
<table class="docutils footnote" frame="void" id="id29" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id28">[14]</a></td><td>MTTR is also known as <em>Mean Time To Recovery</em>.</td></tr>
</tbody>
</table>
<p>Stochastic variables are also very useful when <em>generating</em> variations on a theme, in the context of the simulation of a large number of instances of a given case.</p>
<p>For example, when wanting to simulate a wide range of different low-voltage meshes, one can either:</p>
<ul class="simple">
<li>load a set of externally-defined descriptions of real meshes coming from the field (should such descriptions be available, accurate and numerous enough)</li>
<li>or, more easily, one can <em>generate</em> these different meshes according to some probabilistic rules, which would give, for example, the number of supply points of a given mesh, depending on its profile (ex: rural, urban, etc.), so that the pool of generated meshes follows the real-life statistics</li>
</ul>
<p>The objective here is therefore to provide model developers with all the facilities needed to easily specify and implement stochastic models, in full compliance with the aforementioned simulation properties. This involves a little more than that:</p>
<p><span class="raw-html"><center><img src="xkcd-random_number.png" id="responsive-image-medium"></img></center></span>
</p>
</div>
<div class="section" id="built-in-random-distributions">
<h2><a class="toc-backref" href="#id180">Built-in Random Distributions</a></h2>
<p>Although any probabilistic distribution (i.e. probability density) can be defined and added to the framework, Sim-Diasca provides some built-in distributions, listed below, that are among the most common.</p>
<p>They are proposed by the <tt class="docutils literal">RandomManager</tt>, a specific technical component helping to manage stochastic variables in the context of a distributed simulation, notably so that causality and reproducibility are preserved.</p>
<div class="section" id="uniform-law">
<h3>Uniform Law</h3>
<p>This &quot;white noise&quot; generator will draw values into a user-parameterised range, all samples having an equal probability of being chosen.</p>
<p>When placing a Sim-Diasca <a class="reference internal" href="#probe">probe</a> at the output of a RandomManager set to deliver a uniform law, we have the following result:</p>
<p><span class="raw-html"><center><img src="RandomManager-Uniform_probe.png" id="responsive-image-intermediate"></img></center></span>
</p>
<p>By setting the appropriate flag, Sim-Diasca can also be configured to use a uniform generator of superior quality, which was designed for cryptography.</p>
<p>This uniform distribution is often the basis to generate in turn more complex distributions.</p>
</div>
<div class="section" id="exponential-law">
<h3>Exponential Law</h3>
<p>This distribution, defined by a single parameter, <tt class="docutils literal">lambda</tt>, leads to the following result:</p>
<p><span class="raw-html"><center><img src="RandomManager-Exponential_probe.png" id="responsive-image-intermediate"></img></center></span>
</p>
<p>This distribution is directly generated by Sim-Diasca from the previous white noise source.</p>
</div>
<div class="section" id="gaussian-law">
<h3>Gaussian Law</h3>
<p>Two parameters, <tt class="docutils literal">mu</tt>, the mean value, et <tt class="docutils literal">sigma</tt>, the variance (whose positive square root is the standard deviation), define the Gaussian law <a class="footnote-reference" href="#id31" id="id30">[15]</a>.</p>
<table class="docutils footnote" frame="void" id="id31" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id30">[15]</a></td><td>It is also known as the normal law.</td></tr>
</tbody>
</table>
<p>This results in the following curve:</p>
<p><span class="raw-html"><center><img src="RandomManager-Gaussian_probe.png" id="responsive-image-intermediate"></img></center></span>
</p>
<p>The Sim-Diasca white noise generator is used to generate this Gaussian law as well.</p>
</div>
</div>
<div class="section" id="user-specified-random-distributions">
<h2><a class="toc-backref" href="#id181">User-Specified Random Distributions</a></h2>
<p>Non-uniform, arbitrarily-defined probability density functions are supported.</p>
<p>For that, refer, in the <tt class="docutils literal">random_utils</tt> module, to the <tt class="docutils literal">generate_random_state_from/2</tt>, <tt class="docutils literal">get_sample_from/1</tt> and <tt class="docutils literal">get_sample_from/2</tt> functions, and to the corresponding <a class="reference external" href="http://myriad.esperide.org/#randomness">Myriad section</a>.</p>
</div>
<div class="section" id="actual-management-of-randomness">
<h2><a class="toc-backref" href="#id182">Actual Management of Randomness</a></h2>
<div class="section" id="random-generators">
<h3>Random Generators</h3>
<p>At the core of most implementations, one relies on a random generator, which usually outputs floating-point values uniformly distributed between 0.0 and 1.0.</p>
<p>For a better stochastic management, the engine does not rely anymore on the basic <tt class="docutils literal">random</tt> module of Erlang; it may operate instead with the <tt class="docutils literal">crypto</tt> module (if available and enabled), otherwise it will default on the newer <tt class="docutils literal">rand</tt> module, which offers various algorithms, including:</p>
<ul class="simple">
<li><tt class="docutils literal">exsplus</tt>: Xorshift116+, 58 bits precision and period of 2^116-1 (state uses 320 bytes on 64-bit platforms)</li>
<li><tt class="docutils literal">exs64</tt>: Xorshift64*, 64 bits precision and a period of 2^64-1 (state of 336 bytes on 64-bit platforms)</li>
<li><tt class="docutils literal">exs1024</tt>: Xorshift1024*, 64 bits precision and a period of 2^1024-1 (state of 856 bytes on 64-bit platforms)</li>
</ul>
<p>Unless overridden (see <tt class="docutils literal">random_utils.erl</tt>), the algorithm used by the engine is <tt class="docutils literal">exsplus</tt>.</p>
<p>Based on a uniform random value in <tt class="docutils literal">[0.0,1.0]</tt>, one can generate uniform values in any other range, and values that respect all kinds of non-uniform laws (like the Gaussian one).</p>
<p>However a question still remains: how many instances of random generators should we use?</p>
</div>
<div class="section" id="mode-of-operation">
<h3>Mode Of Operation</h3>
<p>Random generators usually have a state, which is initialised with a seed - either set by default, or specifically given.</p>
<p>From a seed a series of random numbers can be generated, and as such it can be reproduced identically, as long as the same seed is used.</p>
<p>The trouble comes from the fact that, during any given logical moment (diasca), multiple simulation actors may require - and therefore request from a random generator - any number of values complying to any number of probabilistic laws, each parameterised as wished, in any order. And of course we do not want to loose the reproducibility of simulations because of that.</p>
<p>Initially the engine was relying on a limited number of centralised random manager instances (possibly even just one), each used by a (potentially large) set of model instances.</p>
<p>Each of these model instances would then interact with its random manager(s) in a consistent manner, through actor messages to preserve simulation properties.</p>
<p>Such an approach induces many constraints, like the additional synchronisation and diasca creation involved (hence significant runtime overhead), a more complex model-level logic to request and wait for these values, etc.</p>
<div class="section" id="detailed-why-centralised-random-managers-are-evil">
<h4>Detailed: Why Centralised Random Managers are Evil</h4>
<p>(please feel free to skip this section if not having historical curiosity)</p>
<p>The most obvious approach for stochastic management is to have actors require the random values they need to a centralised random manager.</p>
<p>This solution is simple, but has some pitfalls, particularly if the engine does not provide a concept of &quot;logical moments&quot;, i.e. diascas here.</p>
<p>A central objective is of course <strong>not to break reproducibility</strong>. Indeed, without any specific measure, actors would request their value to the centralised random manager during the execution of their tick, with no particular order enforced between requests, since they would be concurrent in that context.</p>
<p>Therefore, if, thanks to the seeding, they would indeed consume collectively always the same random series, the values of this series would be differently dispatched among actors, depending on the chronological order of reception of their requests by the random manager.</p>
<p>A solution is to <strong>have the random manager become a simulator actor</strong> as well. Then it would be appropriately synchronised by the mechanisms provided by the time manager, and stochastic actors would thus behave correctly and in a reproducible way.</p>
<p>There is an issue there nevertheless. Indeed, if the model of an actor required that actor to use a random value at a given tick N, then to have that value the actor would have to send a request during this tick to the random manager, which would process that request during the next tick (i.e. N+1) and send back the determined value to the requesting actor, which would in turn be able to process it no sooner than the next tick (N+2).</p>
<p>Therefore this would induce by default an <strong>unwanted 2-tick latency</strong> each time an actor would require a random value, whereas the model would not tell us so. As some actors can consume at least one value per tick, the system cannot work as is.</p>
<p>Moreover, not all actors are able to anticipate on their needs of random values, and, in the cases where it would be possible, doing so would make their implementation a lot more complex than needed.</p>
<p>Hence, before diascas were introduced, a generic solution had been designed instead - which would manage transparently these needs, i.e. with no impact on the writing of models.</p>
<p>The solution consists on having each actor that uses stochastic variables define, for each one of them, not only which distribution law with which settings should be used, but also an <strong>upper bound to the number of values following that law that may be drawn during any single tick</strong>, for this actor and this distribution.</p>
<p>Such an upper bound should be possible to define for most if not all models and, if ever the upper bound was incorrectly evaluated (i.e. if it was set to a too small value, leading to an exhaustion of the corresponding random buffer), then at simulation time the issue would be detected and the simulation would stop. Then the upper-bound could just be set to a higher value, and the simulation be run again.</p>
<p>With these information, the generic <em>stochastic actor</em> (a Sim-Diasca built-in) was able to transparently cache full lists of random variables obtained from the (centralised) random manager, and to manage their refilling appropriately in the background, so that the corresponding random values could be always obtained with zero latency by an actor.</p>
<p>Thus <strong>the implementation of models was considerably simplified</strong>, since they can be developed as if they could rely on local infinite random sources, which additionally would not raise issues about reproducibility.</p>
<p>This was coming at the expense of extra diascas being instantiated (forcing models to manage them and hitting the runtime performances) and a few extra constraints.</p>
<p>For example, apart from the already mentioned constraint regarding the upper bound in terms of the number of drawn samples, some stochastic actors need random variables whose probabilistic distributions can change during a simulation. For example, if a meter determines its connectivity by drawing, even with equal probability, a given number of meters out of its functional upstream meters, this translates into a uniform law whose range can change at each tick (depending on how many upstream meters are functional); this is a problem for this kind of approaches based on transparent buffering.</p>
<p>The specialised generic actor, the <tt class="docutils literal">Stochastic Actor</tt> - which can be reused at will by all stochastic models to simplify their development - used to rely on this mechanism. Since then, we opted for a simpler and more efficient system, explained below.</p>
</div>
<div class="section" id="current-mode-of-operation">
<h4>Current Mode of Operation</h4>
<p>A more flexible approach has been finally retained: each model instance embeds its <strong>own, private, random generator</strong> (to which it can readily and freely access without constraint), which is seeded appropriately (on a reproducible manner, each actor having its own, specific seed) when that actor is created.</p>
<p>This removes all drawbacks previously mentioned, at the expense of:</p>
<ul class="simple">
<li>a more complex actor creation done by the load balancer (in charge of a parallel yet proper seeding - itself based on its own random generator)</li>
<li>an increased memory footprint of the stochastic actors, as each must store the state of its random generator (typically ranging from 32 bytes to a few kilobytes)</li>
</ul>
<p>Thanks to this on-creation seeding, reproducibility is ensured, and stochastic actors are able to interact with their embedded random generator with no further synchronisation effort, i.e. with no delay nor message (actor or not).</p>
</div>
</div>
</div>
<div class="section" id="randomness-pitfalls">
<h2><a class="toc-backref" href="#id183">Randomness Pitfalls</a></h2>
<p>All model instances are automatically correctly seeded, so all probabilistic laws can be readily used from them with no effort.</p>
<p>However, in some cases (typically for initialisation purposes, in the simulation case) it may be useful to rely on basic processes, WOOPER or not (i.e. not actors), and some of them might have to be stochastic (ex: when generating a given road network following specific constraints). <strong>These helper processes should have their random source explicitly seeded</strong> (using <tt class="docutils literal"><span class="pre">random_utils:start_random_source/{1,3}</span></tt> for that), otherwise a non-constant seed will be assigned to each of them, and it will break reproducibility.</p>
<p>Another potential cause of issue is the change of a random source: if not explicitly seeded, some of them will default on a constant seed (ex: <tt class="docutils literal">random</tt>) while others not (ex: <tt class="docutils literal">rand</tt>, the current default source).</p>
<p>As a result, <strong>all non-actor processes having to generate, directly or not, random values shall be explicitly seeded</strong>, typically thanks to:</p>
<pre class="code erlang literal-block">
<span class="nn">random_utils</span><span class="p">:</span><span class="nf">start_random_source</span><span class="p">(</span> <span class="n">default_seed</span> <span class="p">)</span>
</pre>
<p></p>
</div>
</div>
<div class="section" id="sim-diasca-management-of-simulation-inputs">
<h1><a class="toc-backref" href="#id184">Sim-Diasca Management of Simulation Inputs</a></h1>
<div class="section" id="id32">
<h2><a class="toc-backref" href="#id185">Principles</a></h2>
<p>A simulation is defined primarily by its simulation case, which shall specify the simulation inputs.</p>
<p>These inputs are mostly:</p>
<ul class="simple">
<li>the <strong>technical settings</strong>, like the various simulation, deployment and load balancing settings (see the corresponding records to properly specify these inputs)</li>
<li>the <strong>initial state</strong> of the simulation, i.e. what are the initial actors and scenarios, and in which state they shall be when the simulation begins</li>
</ul>
</div>
<div class="section" id="requirements">
<h2><a class="toc-backref" href="#id186">Requirements</a></h2>
<p>The initial state of the simulation is by far the most challenging input to manage. In simple cases, it can be seen as a series of (synchronous) creations of initial instances (actors or scenarios, no difference from the engine's point of view), which can be done:</p>
<ul class="simple">
<li>either <em>programmatically</em> - directly from the simulation case or from a scenario (in both cases typically thanks to a series of <tt class="docutils literal"><span class="pre">class_Actor:create_initial_actor/{2,3}</span></tt> calls, with the relevant parameters in terms of model construction)</li>
<li>or based on <em>initialisation data</em>, read from any kind of information stream (typically user-specified initialisation files)</li>
</ul>
<p>Initialisation may not be straightforward, notably because actors may have to know others, forming a directed graph that may comprise cycles.</p>
<p>A simple example would be when two actors (A and B) have to know each other initially. This initial state cannot be created in one pass as, when the first actor is created (let's say: A), the second (B) does not even exist yet - so A will have to be created as if it were alone, and must be notified afterwards that it is to know B - once B will have been created as well <a class="footnote-reference" href="#id34" id="id33">[16]</a>.</p>
<table class="docutils footnote" frame="void" id="id34" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id33">[16]</a></td><td>B then could be fully created in one pass, since A is existing at this point. However, to preserve symmetry and homogeneity, and avoid being associated to a A instance that is partly initialised (it does not know B yet), probably B should be created in two passes, exactly as A.</td></tr>
</tbody>
</table>
<p>Furthermore, in order to designate instances, most simulation projects tend to rely on identifier conventions of their own, that are specific to these simulations and may be of approximately any datatype.</p>
<p>For example some projects will rely on numerical instance identifiers (ex: <tt class="docutils literal">1275411</tt>), other may use names (ex: <tt class="docutils literal">1600 Pennsylvania Ave NW, Washington, DC 2050012, United State</tt>) while some simulations could rely on more complex data structures (ex: <tt class="docutils literal">(12,3.0,45)</tt>, whatever this may mean).</p>
<p>Qualities of an input management system include:</p>
<ul class="simple">
<li>allowing most kinds of user-specific instance identifiers</li>
<li>managing its own, private identifiers transparently for the user</li>
<li>being able to sort out all cyclic dependencies</li>
<li>not preventing at least some sort of efficient distributed mode of operation afterwards, notably with regard to smart placement and load-balancing</li>
<li>relying on an expressive, yet compact and human-readable, form to specify the initial instances</li>
<li>managing this initialisation data as much as possible in parallel</li>
</ul>
</div>
<div class="section" id="creation-of-the-initial-state-of-the-simulation">
<h2><a class="toc-backref" href="#id187">Creation of the Initial State of the Simulation</a></h2>
<div class="section" id="how-to-create-initial-instances-programmatically">
<h3>How to Create Initial Instances Programmatically</h3>
<p>This is the easiest, yet most limited, approach. No external identifier needs to be involved here.</p>
<p>If wanting to create two instances that have to know each other, one may use, possibly directly from the simulation case:</p>
<pre class="code erlang literal-block">
<span class="nv">A</span> <span class="o">=</span> <span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_initial_actor</span><span class="p">(</span> <span class="n">class_Foo</span><span class="p">,</span> <span class="p">[</span> <span class="nv">Xa</span><span class="p">,</span> <span class="nv">Ya</span> <span class="p">]</span> <span class="p">),</span>
<span class="nv">B</span> <span class="o">=</span> <span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_initial_actor</span><span class="p">(</span> <span class="n">class_Bar</span><span class="p">,</span> <span class="p">[</span> <span class="nv">Xb</span><span class="p">,</span> <span class="nv">Yb</span><span class="p">,</span> <span class="nv">Zb</span> <span class="p">],</span>
   <span class="s">&quot;My placement hint&quot;</span> <span class="p">),</span>

<span class="nv">A</span> <span class="o">!</span> <span class="p">{</span> <span class="n">declareBar</span><span class="p">,</span> <span class="nv">B</span><span class="p">,</span> <span class="n">self</span><span class="p">()</span> <span class="p">},</span>
<span class="nv">B</span> <span class="o">!</span> <span class="p">{</span> <span class="n">declareFoo</span><span class="p">,</span> <span class="nv">A</span><span class="p">,</span> <span class="n">self</span><span class="p">()</span> <span class="p">},</span>

<span class="n">bar_declared</span> <span class="o">=</span> <span class="n">test_receive</span><span class="p">(),</span>
<span class="n">foo_declared</span> <span class="o">=</span> <span class="n">test_receive</span><span class="p">(),</span>

<span class="p">[...]</span>
</pre>
<p>A few remarks here:</p>
<ul class="simple">
<li><tt class="docutils literal">A</tt> and <tt class="docutils literal">B</tt> are PIDs</li>
<li>this mutual recognition requires a specific method to be added in both classes (namely <tt class="docutils literal"><span class="pre">declare{Foo,Bar}/2</span></tt>)</li>
<li>one can guess that the <tt class="docutils literal"><span class="pre">declare{Foo,Bar}/2</span></tt> methods exposed here are requests (even if no particular result had to be returned), for synchronicity reasons (otherwise there could be a race condition between these messages and the ones related to the start of the simulation); this is why we have to receive the <tt class="docutils literal">*_declared</tt> messages from the simulation case</li>
<li>we can see that here A will be created using default placement policy, when B will be created by the load balancer according to the specified hint: when created programmatically, all instances specifying the same placement hint will be created on the same computing node (as chosen by the load balancer)</li>
</ul>
</div>
<div class="section" id="how-to-use-initialisation-data-to-create-initial-actors">
<h3>How to Use Initialisation Data to Create Initial Actors</h3>
<div class="section" id="specifying-the-data-source">
<h4>Specifying the Data Source</h4>
<p>The user shall call, either directly from the simulation case or from a scenario: <tt class="docutils literal">sim_diasca:create_initial_instances/1</tt> <a class="footnote-reference" href="#id36" id="id35">[17]</a></p>
<table class="docutils footnote" frame="void" id="id36" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id35">[17]</a></td><td>We use <em>instances</em>, as they may be actors or scenarios.</td></tr>
</tbody>
</table>
<p>or use the <tt class="docutils literal">initialisation_files</tt> field of the <tt class="docutils literal">simulation_settings</tt> (see <tt class="docutils literal">soda_loading_test.erl</tt> for an example).</p>
<p>In both cases we expect a list of filenames to be specified, each being a path (absolute, or relative to the directory from which Sim-Diasca was launched) to a file containing initialisation data of interest.</p>
<p>Each of them should be a text file (whose name is arbitrary, but we recommend using the <tt class="docutils literal">.init</tt> file extension; for example: <tt class="docutils literal"><span class="pre">my-case-instances.init</span></tt>), containing a series of lines, either:</p>
<ul class="simple">
<li>blank</li>
<li>or containing a comment</li>
<li>or containing a creation specification, ending with a dot</li>
</ul>
<p>Any line may have any number of leading and/or trailing whitespaces.</p>
<p>Each non-empty line that is not a comment is to create an instance, hence shall specify the class name and actual construction parameters that correspond to this instance.</p>
<p>See the <tt class="docutils literal"><span class="pre">soda-instances.init</span></tt> file (in the <tt class="docutils literal"><span class="pre">soda-test</span></tt> mock simulator) for a full example.</p>
</div>
<div class="section" id="regarding-actor-identifiers">
<h4>Regarding Actor Identifiers</h4>
<p>To better integrate into most architectures, Sim-Diasca manages two kinds of identifiers for actor instances created from data:</p>
<ul class="simple">
<li><strong>external</strong> ones, i.e. the arbitrary identifiers that are provided by the user, which are often simulation-specific</li>
<li><strong>internal</strong> ones, i.e. identifiers that are managed internally by the engine, and which are mostly transparent for the user</li>
</ul>
<p>External identifiers can be arbitrary strings, which are processed as are (no attempt of checking, parsing or enforcing any convention on their content is made there) <a class="footnote-reference" href="#id38" id="id37">[18]</a>.</p>
<table class="docutils footnote" frame="void" id="id38" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id37">[18]</a></td><td>We could even imagine that these identifiers be of any type, however this would offer little practical interest.</td></tr>
</tbody>
</table>
<p>The internal identifiers are simply the PID of the corresponding instances.</p>
<p>Thus the engine takes care of letting the user rely on any convention, while maintaining a two-way translation scheme to benefit from the best of both worlds.</p>
</div>
<div class="section" id="format-of-a-line-for-basic-creation">
<h4>Format of a Line for Basic Creation</h4>
<p>Such a line is made of a pair, whose first element is the class (as an atom) of the instance to create and whose second element is a list containing its construction parameters, that may be approximately any Erlang terms <a class="footnote-reference" href="#id40" id="id39">[19]</a>.</p>
<table class="docutils footnote" frame="void" id="id40" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id39">[19]</a></td><td>We will see below that actually only tuples whose first element is the <tt class="docutils literal">user_id</tt> atom are not accepted as actual initialisation data, since, in this context, they would be ambiguous.</td></tr>
</tbody>
</table>
<p>A simple line, designated as a &quot;creation clause&quot;, could then be:</p>
<pre class="code erlang literal-block">
<span class="p">{</span><span class="n">class_Foo</span><span class="p">,[</span><span class="s">&quot;Hello world!&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">.</span><span class="mi">4</span><span class="p">]}.</span>
</pre>
<p>One can see this data-based initialisation as a simple counterpart to this programmatic form:</p>
<pre class="code erlang literal-block">
<span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_initial_actor</span><span class="p">(</span><span class="n">class_Foo</span><span class="p">,[</span><span class="s">&quot;Hello world!&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">.</span><span class="mi">4</span><span class="p">])</span>
</pre>
<p>Such a data-based initialisation allows expressing all creations of initial instances - except the ones that start interlinked and thus that must rely on some sort of (user-defined) instance identifiers.</p>
<p>A basic creation can also be performed with an additional parameter, which is a placement hint (which can be any term). This tells the load balancer to create all instances that are specified with the same placement hint on the same computing node.</p>
<p>Such a creation clause can then be, if using an atom as hint:</p>
<pre class="code erlang literal-block">
<span class="p">{</span><span class="n">class_Foo</span><span class="p">,[</span><span class="s">&quot;Hello world!&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">.</span><span class="mi">4</span><span class="p">],</span><span class="n">my_placement_hint</span><span class="p">}.</span>
</pre>
<p>The corresponding programmatic form being then:</p>
<pre class="code erlang literal-block">
<span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_initial_placed_actor</span><span class="p">(</span><span class="n">class_Foo</span><span class="p">,</span>
  <span class="p">[</span><span class="s">&quot;Hello world!&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">.</span><span class="mi">4</span><span class="p">],</span><span class="n">my_placement_hint</span><span class="p">)</span>
</pre>
</div>
<div class="section" id="format-of-a-line-specifying-a-user-identifier">
<h4>Format of a Line <em>Specifying</em> a User Identifier</h4>
<p>The following syntax allows, in addition to the aforementioned creation, to define and associate a specific user-provided identifier to that newly created instance.</p>
<p>We can see that the same basic creation pair as before is now prefixed by its user identifier and an arrow:</p>
<pre class="code erlang literal-block">
<span class="s">&quot;My first instance&quot;</span> <span class="o">&lt;-</span> <span class="p">{</span><span class="n">class_Foo</span><span class="p">,[</span><span class="s">&quot;Hello world!&quot;</span><span class="p">,</span><span class="mi">1</span><span class="p">.</span><span class="mi">4</span><span class="p">]}.</span>
</pre>
<p>As a consequence, the engine will see the <tt class="docutils literal">&quot;My first instance&quot;</tt> string as a user identifier associated to the PID of the corresponding <tt class="docutils literal">class_Foo</tt> initial instance that will be created.</p>
<p>The user identifiers are arbitrary strings, except that they should not contain any double quote (<tt class="docutils literal">&quot;</tt>) character (to simplify their parsing).</p>
<p>For the engine, <em>defining</em> a user identifier results in selecting a related placement of the upcoming instance. Hence no placement hint can be specified with this form.</p>
<p>Of course defining identifiers would be useless if they could not be used afterwards.</p>
</div>
<div class="section" id="format-of-a-line-making-use-of-a-user-identifier">
<h4>Format of a Line <em>Making Use of</em> a User Identifier</h4>
<p>Such a line would be for example:</p>
<pre class="code erlang literal-block">
<span class="p">{</span><span class="n">class_Bar</span><span class="p">,[</span><span class="n">an_atom</span><span class="p">,</span><span class="mi">3</span><span class="p">,{</span><span class="n">user_id</span><span class="p">,</span><span class="s">&quot;My first instance&quot;</span><span class="p">},</span><span class="mi">7</span><span class="p">]}.</span>
</pre>
<p>We can see here that the user identifier previously defined for the <tt class="docutils literal">class_Foo</tt> instance (i.e. <tt class="docutils literal">My first instance</tt>) will be used in order to create the <tt class="docutils literal">class_Bar</tt> instance, so that the latter can know the former (i.e. have its PID) from its start (on its creation).</p>
<p>When referenced (as opposed to being defined), user identifiers are to be tagged thanks to a <tt class="docutils literal">user_id</tt> pair. For example <tt class="docutils literal"><span class="pre">{user_id,&quot;My</span> first instance&quot;}</tt> is to be specified, instead of a mere <tt class="docutils literal">&quot;My first instance&quot;</tt> (which would be interpreted as any random string).</p>
<p>Otherwise simple parameter strings and user identifiers could not be discriminated properly; the <tt class="docutils literal">user_id</tt> atom is thus reserved for such use.</p>
<p>No user identifier being <em>defined</em> here, a placement hint can also be specified. For example as a string (here, &quot;Milky Way&quot;):</p>
<pre class="code erlang literal-block">
<span class="p">{</span><span class="n">class_Dalek</span><span class="p">,[</span><span class="n">true</span><span class="p">,{</span><span class="n">user_id</span><span class="p">,</span><span class="s">&quot;EXTERMINATE&quot;</span><span class="p">}],</span><span class="s">&quot;Milky Way&quot;</span><span class="p">}.</span>
</pre>
</div>
<div class="section" id="format-of-a-line-in-the-general-case">
<h4>Format of a Line in the General Case</h4>
<p>Often a given instance will reference some others (i.e. rely on their user identifier) <em>and</em> have its own user identifier defined, like in:</p>
<pre class="code erlang literal-block">
<span class="s">&quot;John&quot;</span> <span class="o">&lt;-</span> <span class="p">{</span><span class="n">class_Beatle</span><span class="p">,[{</span><span class="n">user_id</span><span class="p">,</span><span class="s">&quot;Paul&quot;</span><span class="p">},{</span><span class="n">user_id</span><span class="p">,</span><span class="s">&quot;George&quot;</span><span class="p">}]}.</span>
</pre>
<p>Here John will know from the start Paul and George, and later in the initialisation phase any Ringo could know John as well, using <tt class="docutils literal"><span class="pre">{user_id,&quot;John&quot;}</span></tt> for that.</p>
<p>As always, a user identifier being defined here, no placement hint can be specified.</p>
</div>
<div class="section" id="more-information-about-placement-hints">
<h4>More Information About Placement Hints</h4>
<p>We can see that no placement hint could be specified in the creation lines above, as they defined a user identifier.</p>
<p>Indeed, with data-based initialisations, placement derives naturally from user identifiers:</p>
<ul class="simple">
<li>if a user identifier is specified (ex: <tt class="docutils literal">&quot;My Foo&quot; &lt;- <span class="pre">{class_Foo,[...]}</span></tt>), then this identifier (<tt class="docutils literal">&quot;My Foo&quot;</tt>) will be used as a placement hint</li>
<li>if no user identifier is specified:<ul>
<li>if a placement hint is specified, then it will be used directly</li>
<li>if no placement hint is specified either:<ul>
<li>if no user identifier is referenced either (ex: <tt class="docutils literal"><span class="pre">{class_Foo,[&quot;Hello</span> <span class="pre">world!&quot;,1.4]}.</span></tt>), then the corresponding instance will be placed according to the default policy of the load balancer</li>
<li>if at least one user identifier is referenced (ex: <tt class="docutils literal"><span class="pre">{class_Foo,[2,{user_id,&quot;AA&quot;},0.0,{user_id,&quot;BB&quot;},</span> <span class="pre">my_atom]}.</span></tt>), then the corresponding instance will be placed according to the first user identifier found when parsing the construction parameters; so, in this example, this <tt class="docutils literal">class_Foo</tt> instance would be created on the same computing node on which the instance designated by user identifier <tt class="docutils literal">&quot;AA&quot;</tt> will be</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>This allows an automatic, implicit placement of instances which by design are likely to interact.</p>
</div>
<div class="section" id="comments">
<h4>Comments</h4>
<p>An initialisation file may also contain comments. They have to be on a dedicated line, starting with the character <tt class="docutils literal">%</tt>. Then the full line is ignored.</p>
</div>
<div class="section" id="empty-lines">
<h4>Empty Lines</h4>
<p>There are ignored.</p>
</div>
<div class="section" id="inner-workings-explained">
<h4>Inner Workings Explained</h4>
<p>The initialisation data is read and, in parallel, is parsed and checked by a set of creator processes (one per core of the user host).</p>
<p>One instance is created per read creation line (provided it is neither blank nor a comment), and the engine ensures that a hosting process is available for each instance <em>referenced</em> in that creation line: any user identifier referenced before being defined will result in a blank process being spawned on the relevant computing node (determined solely from this user identifier); this process will embody the corresponding instance, once its definition will be processed.</p>
<p>The PID of each of these created processes is recorded in a translation table, so that user identifiers can be related to these processes.</p>
<p>Despite the arbitrary creation order induced by parallelism, the engine takes care of assigning reproducible AAIs and random seeds.</p>
<p>In the meantime the read initialisation terms are transformed, replacing each <tt class="docutils literal">{user_id,UserIdentifier}</tt> pair (of course these information can be arbitrarily nested in any kind of data-structure, discovered at runtime) by the corresponding PID (that is either already pre-spawned or created at this moment), and the corresponding instances are initialised (their constructor being called with the relevant, transformed construction parameters).</p>
<p>Each user identifier must be defined exactly once; any user identifier:</p>
<ul class="simple">
<li>referenced to, but never defined, results in an error</li>
<li>defined more than once results in an error</li>
</ul>
<p>A user identifier that is defined but never referenced is not considered as an error.</p>
<p>When the parsing of a creation line fails, a detailed context is given (with the faulty line verbatim, the file name and line number, and an interpretation of the error).</p>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/JSON">JSON syntax</a> could have been used here (for example relying on <a class="reference external" href="https://github.com/davisp/jiffy">jiffy</a> or on <a class="reference external" href="https://github.com/talentdeficit/jsx">jsx</a>), but it would not be nearly as compact and adequate as the custom syntax proposed here.</p>
</div>
<div class="section" id="model-initialisation">
<h4>Model Initialisation</h4>
<p>One must understand that the indirection level provided by user identifiers allows the engine to create initial instances in any order (regardless on any potentially cyclic dependency), thus at full speed, in parallel, with no possible deadlock and while preserving total reproducibility.</p>
<p>This system is designed not to add any constraint onto the actors or scenarios; this however implies that, once a given instance is constructed, any other instance it references (through <tt class="docutils literal">user_id</tt>) may or may not be already constructed; nevertheless its PID is already available and given to the referencing instance, and thus once constructed it will be able to answer any pending message(s) transparently.</p>
<p>The model developer of course should ensure that the deadlocks spared by this instance creation system are not re-introduced by their initialisation logic.</p>
<p>This should not be a real problem, as the trickiest issue, the exchange of references, is already solved by design here.</p>
<p></p>
</div>
</div>
</div>
</div>
<div class="section" id="sim-diasca-management-of-simulation-outputs">
<h1><a class="toc-backref" href="#id188">Sim-Diasca Management of Simulation Outputs</a></h1>
<div class="section" id="id41">
<h2><a class="toc-backref" href="#id189">Principles</a></h2>
<p>A simulator allows to run virtual experiments, involving input parameters and models, and producing corresponding outputs, a subset of it being tagged as the actual results awaited by the user. Some post-processing can then be later applied to these results, which are usually rather raw by-products.</p>
<p>The overall goal is to obtain, from known facts and thanks the simulations, new knowledge that was not necessarily anticipated.</p>
<p>Indeed, in the same way as one may rely on a (hopefully <a class="reference internal" href="#validated">validated</a>) oracle or a gyroscope, the outcome of a simulation cannot be really precisely foreseen (otherwise it would be plain useless):</p>
<p><span class="raw-html"><center><img src="xkcd-gyroscopes.png" id="responsive-image-intermediate"></img></center></span>
</p>
</div>
<div class="section" id="managing-the-outputs">
<h2><a class="toc-backref" href="#id190">Managing The Outputs</a></h2>
<p>In the general case, simulation outputs comprise results, traces, user interface data, etc. We focus below on the simulation <em>results</em>.</p>
<div class="section" id="general-mode-of-operation">
<h3>General Mode of Operation</h3>
<p>Sim-Diasca offers a <strong>fully concurrent support for simulation results</strong> (from their generation to their retrieval), so that they are efficiently produced (only the relevant ones, and in a massively parallel way) and automatically returned back to the user in its launching directory, knowing that on a distributed context the output data is by design scattered across the various networked computing nodes.</p>
<p>For that, if and if only the simulation finishes successfully, a directory specific to that simulation run (based on simulation name, time and date, user and a rather unique identifier <a class="footnote-reference" href="#id44" id="id42">[20]</a>) is created in the current directory (i.e. the directory from which <tt class="docutils literal">make My_Case_run</tt> was executed) of the user node; this result directory bears a name like:</p>
<pre class="literal-block">
Sim-Diasca_My_Case-on-2015-12-10-at-10h-05m-59s-by-boudevil-1f793a6ba507
</pre>
<p>Results of interest are automatically transferred there (otherwise one would have to log in on each and every computing node <a class="footnote-reference" href="#id45" id="id43">[21]</a> to select and retrieve these results by hand).</p>
<table class="docutils footnote" frame="void" id="id44" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id42">[20]</a></td><td>An effort is made to generate names for result directories that can hardly collide, as for example in the context of parametric studies a launcher script may trigger, from the same location and on behalf of the same user, the execution of multiple simulation cases per second. The identifier mentioned here is the <tt class="docutils literal">SII</tt>, detailed in the <em>What is the Simulation Instance Identifier?</em> section of the <em>Sim-Diasca Developer Guide</em>.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id45" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id43">[21]</a></td><td>All computing nodes uses a temporary directory for their work, which includes extracting the deployment archive to access to the simulation input data and code, and storing locally the results being produced. The name of this directory (by default placed under <tt class="docutils literal">/tmp/</tt>) is forged in order to be reasonably unique (ex: <tt class="docutils literal"><span class="pre">sim-diasca-My_Case-boudevil-2015-12-10-at-10h-05m-59s-1f793a6ba507</span></tt>), to avoid clashes between simulations that would run concurrently on shared computing hosts.</td></tr>
</tbody>
</table>
<p>Results are handled by:</p>
<ul class="simple">
<li>the overall <em>Result Manager</em> (a <tt class="docutils literal">class_ResultManager</tt> singleton, automatically created at deployment time on the user node), which keeps track of results and drive them</li>
<li><em>Result producers</em> (all <tt class="docutils literal">class_ResultProducer</tt> instances, like probes, either basic or datalogger-based), which provide support to declare, aggregate and send their results</li>
</ul>
<p>Following mode of operation allows to handle results:</p>
<ol class="arabic simple">
<li>the simulation user specifies initially, in the simulation case, what are the results he is interested in, thanks to a <em>Result Specification</em> (detailed below)</li>
<li>the result manager checks this specification, and precomputes what will be needed to discriminate between wanted and unwanted simulation results</li>
<li>when the creation of result producers (typically probes instantiated from models or scenarios) is considered (either initially or at simulation-time), it is declared automatically to the result manager, which is then able to tell whether a given result producer is wanted or not (then only the necessary producers will be created and fed); this allows a given model to support any number of probes, and to enable only the relevant ones on a per-simulation case basis</li>
<li>in the course of the simulation, result producers gather sample data, performing immediate or deferred writes (their volume usually exceeds the capacities of the overall distributed RAM), potentially terminating at any time and then performing operations on these data (ex: generating plots from them)</li>
<li>when (if) the simulation ends successfully, the result manager automatically requests the relevant results from all relevant producers, and copy them in the result directory (more precisely, it generates them only if appropriate, like in the case of plots, and send them in a compressed from over the network, to the user node)</li>
</ol>
</div>
<div class="section" id="result-specification">
<h3>Result Specification</h3>
<p>Which results are wanted is generally specified directly from the simulation case, among the simulation settings.</p>
<p>The selection is based on the <strong>names</strong> of the result producers to enable, since it is the only way the user can refer to them <em>a priori</em> (ex: of course no PID can be statically anticipated in the simulation case).</p>
<p>In the result specification, a simulation case may require:</p>
<ul class="simple">
<li>a binary selection: either <strong>all</strong> results are wanted or <strong>none</strong> of them</li>
<li>a type-based selection: either the results corresponding to <strong>plain probes</strong> or to <strong>virtual ones</strong> (i.e. based on the data-logger) are wanted</li>
<li>a finer pattern-based selection: only results whose name matches <strong>at least one targeted pattern</strong>, and <strong>none of the blacklisted patterns</strong>, are to be selected (most general case)</li>
</ul>
<p>Patterns are to be expressed according to the <em>Perl Compatible Regular Expressions</em> conventions, or <tt class="docutils literal">PCRE</tt> for short.</p>
<p>For more information on the pattern format, see the <a class="reference external" href="http://erlang.org/doc/man/re.html">re module</a>.</p>
<p><span class="raw-html"><center><img src="xkcd-perl_problems.png" id="responsive-image-medium"></img></center></span>
</p>
<p>The detailed supported syntax is specified in the <tt class="docutils literal"><span class="pre">sim-diasca/src/core/src/scheduling/class_TimeManager.hrl</span></tt> header file; see the <tt class="docutils literal">result_specification</tt> field of the <tt class="docutils literal">simulation_settings</tt> record. Examples can be found in the cases available in the <tt class="docutils literal"><span class="pre">mock-simulators</span></tt> directory.</p>
<p>Relying on these simulation settings allows to define which results are expected <em>statically</em>, which is fine for most uses. However, under some circumstances, it may be convenient to set or modify the result specification <em>dynamically</em> (ex: if it is difficult to anticipate on the name of a probe or whether it is actually wanted).</p>
<p>Thus result specification can be also modified at simulation-time, thanks to method calls (see the <tt class="docutils literal"><span class="pre">{add,remove,set}{Targeted,Blacklisted}Pattern*/2</span></tt> methods of <tt class="docutils literal">class_ResultManager</tt>).</p>
</div>
<div class="section" id="early-disabling-of-results">
<h3>Early Disabling of Results</h3>
<p>All results could be generated in all cases, and only be retrieved if requested.</p>
<p>However a better approach could be to collect data samples and process them (ex: in graphical plots) only if needed.</p>
<p>A still better approach is needed: as the result manager is able to tell directly whether a result is wanted, it will be able to disable unwanted results from the start, i.e. reject any attempt of creating a result producer (ex: a probe) whose results are not wanted by the user.</p>
<p>As a consequence, a classical, model-level probe may be created thanks to the <tt class="docutils literal">class_Probe:declare_result_probe/6</tt> static method, which will return either the PID of this newly created probe (if the name of that probe is acknowledged as a wanted result by the result manager), or the <tt class="docutils literal">non_wanted_probe</tt> atom.</p>
<p>Then the <tt class="docutils literal">class_Probe:send_data/3</tt> method can be called as often as needed by the model in order to potentially feed that probe with relevant sample data (the fact that this probe may not be enabled being then transparently managed).</p>
</div>
</div>
<div class="section" id="result-generation">
<h2><a class="toc-backref" href="#id191">Result Generation</a></h2>
<p>Often, many models are able to define various probes, and the corresponding number of instances is huge.</p>
<p>A large number of result producers may therefore exist, even after having selected (thanks to the result specification) only a subset of them.</p>
<p>The consequence is that the parallel, distributed result generation cannot be triggered as a whole, lest the most loaded computing nodes will simply crash (ex: RAM exhausted).</p>
<p>The result manager therefore implements a flow control mechanism, ensuring that all possible computing nodes work at full speed, while not being too much overloaded. Basically, at any time, up to twice as many generations are requested as there are cores on a given computing host. Any generation completion yields the requesting of another pending one (if any).</p>
</div>
<div class="section" id="post-processing-the-results">
<h2><a class="toc-backref" href="#id192">Post-Processing the Results</a></h2>
<p>Some approaches and tools can be used to transform results into knowledge. This involves generally synthesising the vast amount of data into a few relevant statistics or indicators.</p>
<p><span class="raw-html"><center><img src="xkcd-data_trap.png" id="responsive-image-small"></img></center></span>
</p>
<p>The post-processing to be done depends significantly on the specific problem being studied. Currently, except probe reports, Sim-Diasca outputs mainly time series, letting the user feed these raw data to the suitable tools, on a domain-specific way.</p>
</div>
<div class="section" id="interpreting-the-outcome">
<h2><a class="toc-backref" href="#id193">Interpreting the Outcome</a></h2>
<p>Once the right questions have been properly formalised, this step is probably, with the <a class="reference internal" href="#validation">validation</a> part, the trickiest part of a simulation work: what are the lessons learned, and to which extent can we trust them?</p>
<p>Providing detailed guidelines would be beyond the scope of this document. Here are nevertheless a few hints.</p>
<div class="section" id="identifying-reasons-for-observed-phenomena">
<h3>Identifying Reasons For Observed Phenomena</h3>
<p>Finding actual causes is seldom straightforward:</p>
<p><span class="raw-html"><center><img src="xkcd-correlation.png" id="responsive-image-medium"></img></center></span>
</p>
</div>
<div class="section" id="having-reasonable-expectations">
<h3>Having Reasonable Expectations</h3>
<p>A simulation is not the silver bullet that will ask the right questions on the user's behalf and answer them with infinite accuracy:</p>
<p><span class="raw-html"><center><img src="xkcd-science_montage.png" id="responsive-image-small"></img></center></span>
</p>
<p>Simulation being a rather expensive and time-consuming mode of evaluation, it should be used on carefully selected cases that cannot be solved satisfactorily thanks to other methods, like comparison with actual systems, expert assessments, coarse spreadsheet-based studies, etc.</p>
<p>Even in that case, a few well-selected metrics must be defined, that must be both helpful to the user and solvable by the simulation.</p>
</div>
<div class="section" id="extrapolating-results-really">
<h3>Extrapolating Results, Really?</h3>
<p>Unless it has been proven separately, one cannot arbitrarily reduce the problem size and expect that a small-scale experiment will still provide reliable insights about a real-sized system: <a class="reference external" href="http://en.wikipedia.org/wiki/Reductionism#Reductionism_and_science">reductionism</a> cannot be applied blindly.</p>
<p>This is why the scalability of a simulation engine is a key property: whenever smaller-scale experiments cannot be safely attempted (the general case), it offers a better chance of capturing the reality.</p>
<p>Indeed extrapolating becomes too often a wild guess:</p>
<p><span class="raw-html"><center><img src="xkcd-extrapolating.png" id="responsive-image-reduced"></img></center></span>
</p>
<p>In most cases, approaches based on extrapolations are hardly sustainable:</p>
<p><span class="raw-html"><center><img src="xkcd-sustainable.png" id="responsive-image-intermediate"></img></center></span>
</p>
</div>
<div class="section" id="sharing-the-findings-with-the-intended-audience">
<h3>Sharing the Findings With the Intended Audience</h3>
<p>The lessons learned thanks to the simulation must be synthesised appropriately, with proper wording for the targeted public, so that the conclusions are sufficiently emphasized to be well-understood:</p>
<p><span class="raw-html"><center><img src="xkcd-simple.png" id="responsive-image-small"></img></center></span>
</p>
<p>Concerns must be correctly shared among the people involved, with appropriate common metrics and goals:</p>
<p><span class="raw-html"><center><img src="xkcd-car_problems.png" id="responsive-image-large"></img></center></span>
</p>
</div>
<div class="section" id="making-good-use-of-the-new-knowledge">
<h3>Making Good Use of the New Knowledge</h3>
<p>It is certainly out of the scope of this document, but simulations may generate new knowledge, which must be carefully leveraged, lest it worsens the situation:</p>
<p><span class="raw-html"><center><img src="xkcd-conditional_risk.png" id="responsive-image-intermediate"></img></center></span>
</p>
<p></p>
</div>
</div>
</div>
<div class="section" id="sim-diasca-reliability">
<h1><a class="toc-backref" href="#id194">Sim-Diasca Reliability</a></h1>
<div class="section" id="context">
<h2><a class="toc-backref" href="#id195">Context</a></h2>
<p>The simulations of complex systems tend to be of a larger scale, and may last (at least in wall-clock time) very long.</p>
<p>Numerous computing hosts will then be involved in such simulations and, even if each of the cores of these hosts boasts a high <a class="reference external" href="http://en.wikipedia.org/wiki/Mean_time_between_failures">MTBF</a>, their number will imply that, if waiting for long enough, any proportion of them <em>will</em> fail <a class="footnote-reference" href="#id47" id="id46">[22]</a>. Not to mention that there <em>will</em> be as well network issues, transient or not.</p>
<table class="docutils footnote" frame="void" id="id47" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id46">[22]</a></td><td>The MTBF of a petascale system is not expected to exceed 10 hours, while reports about some Bluegene supercomputers suggests a MTBF of a few days (of course loosing a core may not take down the whole machine, but would &quot;only&quot; make the job(s) relying on that core fail themselves.</td></tr>
</tbody>
</table>
<p>As a result, without a specific mechanism for resilience, some demanding simulations would be (especially in future uses) unlikely to complete at all.</p>
<p>This is why a <em>k-crash resilience</em> feature has been added to the Sim-Diasca engine, starting from its 2.2.0 version.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>Many loosely related features have been improved or added since the introduction of resilience system, while some of them would have required to update accordingly that system.</p>
<p class="last">One should thus consider that, as long as the resilience mechanisms below have not been updated, the resilience feature as a whole is currently <em>not</em> available.</p>
</div>
</div>
<div class="section" id="a-tunable-resilience-service">
<h2><a class="toc-backref" href="#id196">A Tunable Resilience Service</a></h2>
<p>Now, at start-up, the user of a simulation is able to specify, among the simulation settings (see, in <tt class="docutils literal">class_DeploymentManager.hrl</tt>, the <tt class="docutils literal">crash_resilience</tt> field of the <tt class="docutils literal">deployment_settings</tt> record),  what is the required level of resilience of the simulation with regard to the loss of computing hosts in its course:</p>
<ul class="simple">
<li>either <tt class="docutils literal">none</tt> is required (the default mode), in which case the simulation will crash as soon as a computing host is deemed lost (while, on the other hand, no resilience-induced overhead will exist in this case)</li>
<li>or a positive integer <strong>k</strong> is specified, which designates the maximum number of simultaneous losses of computing hosts that the simulation will be able to overcome (a safety net which, of course, will imply some corresponding overhead - it is actually quite reasonable)</li>
</ul>
<p>For example, if <tt class="docutils literal">k=3</tt>, then as long as up to 3 computing hosts fail at the same time during a simulation, it will be nevertheless able to resist and continue after a short (bounded) automatic rollback in simulation-time.</p>
<p>This will include starting again from the last simulation snapshot (established automatically at the latest wall-clock simulation milestone, if any was met), converting back the states of simulation agents, actors and result producers (probes) which had been then serialised, re-dispatching (load-balancing-wise), re-creating, updating and linking the corresponding processes, before making the simulation time progress again from that milestone.</p>
<p>There is no upper bound in the number of <em>total</em> losses of computing hosts in the simulation that can be overcome, provided that at any time the k threshold is not exceeded <a class="footnote-reference" href="#id49" id="id48">[23]</a> and that the remaining hosts are collectively able to sustain the resulting load.</p>
<p>This last point implies that the resources of a fault-tolerant simulation <em>must</em> exceed the strict needs of a simulation offering no resilience. For example, if <tt class="docutils literal">N</tt> homogeneous hosts are assigned to a k-resilient simulation, then the user must ensure that the simulation <em>can</em> indeed fit at the very least in <tt class="docutils literal">N - k</tt> computing hosts, otherwise there is no point in requesting such a resilience.</p>
<table class="docutils footnote" frame="void" id="id49" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id48">[23]</a></td><td>Currently, hosts that departed the simulation cannot join back. As a consequence, the remaining ones must be able to cope with the load. Therefore the simulation user ought to allocate a little more resources than strictly necessary initially, to compensate for the <em>sum</em> of all later losses, as they will not be redeemed. The extra hosts introduced in this case behave as spare ones, except that they do not remain idle until a host crashes: they participate to the simulation from its very start, to further smooth the computing load.</td></tr>
</tbody>
</table>
<p>Note that this resilience applies only to the random &quot;workers&quot;, i.e. to the average computing hosts. For example, if the host of the root time manager is lost, the simulation will crash, regardless of the value of k. Depending on the optional services that are enabled (ex: performance tracker, data-logger, data-exchanger, etc.) other single points of failures may be introduced, as they tend to be deployed on different hosts (trade-off between load-balancing and resilience) <a class="footnote-reference" href="#id51" id="id50">[24]</a>. Currently, depending on the aforementioned enabled services, very few single points of failure remain (typically up to three, compared to a total number of computing hosts that may exceed several hundreds, if not thousands in the near future).</p>
<table class="docutils footnote" frame="void" id="id51" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id50">[24]</a></td><td>Most, if not all, services could be made resilient; we simply started with the key ones. As we are able to store most of the reproducible simulation state and reconstruct the purely technical, transient information, a given simulation might even survive the loss of <em>all</em> its computing nodes, and restart later from a blank state, just based on its serialisation data.</td></tr>
</tbody>
</table>
<p>Similarly, should a long-enough network split happen, the k threshold may be immediately reached. If running on production mode, extended time-outs should provide a first level of safety.</p>
<p>Currently no support is offered for hosts that would join in the course of the simulation to compensate for previous losses (for example if being rebooted after a watchdog time-out): usually dynamic additions are not in line with the practice of cluster job managers (it is simpler and more efficient to directly use a larger number of nodes upfront).</p>
<p>Besides the resilience level (i.e., the number k), a (possibly user-defined) serialisation period will apply. It corresponds to the lower bound in terms of (wall-clock <a class="footnote-reference" href="#id53" id="id52">[25]</a>) duration between two serialisations (default duration is two hours).</p>
<table class="docutils footnote" frame="void" id="id53" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id52">[25]</a></td><td>Since hardware and software faults are ruled by wall-clock time; simulation time may flow in a very different manner.</td></tr>
</tbody>
</table>
<p>This serialisation activity will run even before the simulation is started, so that even simulations needing a long time to recreate their initial situation benefit from some protection (typically such a serialisation will then happen at the very first evaluated diasca).</p>
<p>Finally, we ensured that this serialisation activity does not introduce a non-negligible latency (whether activated or not) - but, of course, once the regular serialisation is triggered, the whole simulation is bound to be stalled for some time (even if it is done in an almost fully parallel, distributed way). As a consequence, the resilience feature is only compatible with the batch mode of operation (i.e. not with the interactive one).</p>
</div>
<div class="section" id="id54">
<h2><a class="toc-backref" href="#id197">Mode of Operation</a></h2>
<div class="section" id="preparing-for-any-later-recovery">
<h3>Preparing for any later recovery</h3>
<p>Let's suppose that N computing hosts are assigned to a simulation having to exhibit a k-crash resiliency.</p>
<p>This resilience service is implemented internally by first establishing a &quot;k-map&quot;, which determines, for each of the N hosts, which of the k other hosts it backs-up and, reciprocally, which hosts back it up.</p>
<p>For example, if <tt class="docutils literal">N=6</tt>, hosts may be <tt class="docutils literal">[a,b,c,d,e,f]</tt>, and the k-map could then be, for a requested resilience level of <tt class="docutils literal">k=5</tt>:</p>
<pre class="literal-block">
For a resilience level of 5, result is: k-map for 6 nodes:
+ for node a:
 - securing nodes [b,c,d,e,f]
 - being secured by nodes [f,e,d,c,b]

+ for node b:
 - securing nodes [c,d,e,f,a]
 - being secured by nodes [f,e,d,c,a]

+ for node c:
 - securing nodes [d,e,f,a,b]
 - being secured by nodes [f,e,d,b,a]

+ for node d:
 - securing nodes [e,f,a,b,c]
 - being secured by nodes [f,e,c,b,a]

+ for node e:
 - securing nodes [f,a,b,c,d]
 - being secured by nodes [f,d,c,b,a]

+ for node f:
 - securing nodes [a,b,c,d,e]
 - being secured by nodes [e,d,c,b,a]
</pre>
<p>This example corresponds to, graphically (see <tt class="docutils literal">class_Resilience_test.erl</tt>):</p>
<p><span class="raw-html"><center><img src="Resilience_5-map_for_6_nodes.png" id="responsive-image-intermediate"></img></center></span>
</p>
<p>Of course this resilience feature is typically to be used with a far larger number of nodes; even with a slight increase, like in:</p>
<p><span class="raw-html"><center><img src="Resilience_10-map_for_20_nodes.png" id="responsive-image-large"></img></center></span>
</p>
<p>we see that any central point in the process would become very quickly a massive bottleneck.</p>
<p>This is why the actual work (both for serialisation and deserialisation tasks) is done in a purely distributed way, and exchanges are done in a peer-to-peer fashion, using the fastest available I/O for that <a class="footnote-reference" href="#id56" id="id55">[26]</a>, while the bulk of the data-intensive local work is mostly done in parallel (taking advantages of all local cores).</p>
<table class="docutils footnote" frame="void" id="id56" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id55">[26]</a></td><td>This includes tuned file writing and reading, operating on stripped-down binary compressed content, and relying on zero-copy <tt class="docutils literal">sendfile</tt>-based network transfers.</td></tr>
</tbody>
</table>
<p>To ensure a balanced load, each computing host is in charge of exactly k other hosts, while reciprocally k other hosts are in charge of this host. After failures, the k-map is recomputed accordingly, and all relevant instances are restored, both in terms of state and connectivity (yet, in the general case, on a different computing host), based on the serialisation work done during the last simulation milestone.</p>
</div>
<div class="section" id="actual-course-of-action">
<h3>Actual Course of Action</h3>
<p>Setting up the resilience service is a part of the deployment phase of the engine. Then the simulation is started and, whenever a serialisation wall-clock time milestone is reached, each computing host disables the simulation watchdog, collects and transforms the state of its simulation agents, actors and result producers (including their currently written data files), and creates a compressed, binary archive from that.</p>
<p>Typically, such an archive would be a <tt class="docutils literal"><span class="pre">serialisation-2503-17-from-tesla.bin</span></tt> file, for a host named <tt class="docutils literal">tesla.foobar.org</tt>, for a serialisation happening at the end of tick offset <tt class="docutils literal">2503</tt>, diasca <tt class="docutils literal">17</tt>. It would be written in the <tt class="docutils literal"><span class="pre">resilience-snapshots</span></tt> sub-directory of the local temporary simulation (for example in the default <tt class="docutils literal"><span class="pre">/tmp/sim-diasca-&lt;CASE</span> <span class="pre">NAME&gt;-&lt;USER&gt;-&lt;TIMESTAMP&gt;-&lt;ID&gt;/</span></tt> directory).</p>
<p>This archive is then directly sent to the k other hosts (as specified by the current version of the k-map), while receiving reciprocally the same type of information from k other hosts. One should note that this operation, which is distributed by nature, is also intensely done in parallel (i.e. on all hosts, all cores are used to transform the state of local instances into a serialised form, and the two-way transfers themselves are made in parallel).</p>
<p>Then, as long as up to k hosts fail, the simulation can still rely on a snapshot for the last met milestone, and restart from it (provided the remaining hosts are powerful enough to support the whole simulation by themselves).</p>
<p>The states then collected require more than a mere serialisation, as some elements are technical information that must be specifically handled.</p>
<p>This is notably the case for the PIDs that are stored in the state of an instance (i.e. in the value of an attribute, just by itself or possibly as a part of an arbitrarily complex data-structure).</p>
<p>Either such a PID belongs to a lower layer (<tt class="docutils literal">Myriad</tt>, <tt class="docutils literal">WOOPER</tt> or <tt class="docutils literal">Traces</tt>), or it is related directly to Sim-Diasca, corresponding typically to a simulation agent of a distributed service (ex: a local time manager, data exchanger or instance tracker), to a model instance (an actor) or to a result producer (a probe).</p>
<p>As PIDs are technical, contextual, non-reproducible identifiers (somewhat akin to pointers), they must be translated into a more abstract form prior to serialisation, to allow for a later proper deserialisation; otherwise these &quot;pointers&quot; would not mean anything for the deserialising mechanism:</p>
<p><span class="raw-html"><center><img src="xkcd-pointers.png" id="responsive-image-small"></img></center></span>
</p>
<ul class="simple">
<li>Lower layers are special-cased (we have mostly to deal with the WOOPER class manager and the trace aggregator)</li>
<li>Simulation agents are identified by <tt class="docutils literal">agent_ref</tt> (specifying the service they implement and the node on which they used to operate)</li>
<li>Model instances are identified by their <tt class="docutils literal">AAI</tt> (<em>Abstract Actor Identifier</em>), a context-free actor identifier we already need to rely upon for reproducibility purposes, at the level of the message-reordering system</li>
<li>Probes are identified based on their producer name (as a binary string); the data-logger service is currently not managed by the resilience mechanisms</li>
</ul>
<p>In the case of the probes, beyond their internal states, the engine has to take care also of the data and command files they may have already written on disk.</p>
<p>The result of this full state conversion could be stored on the k nodes either in RAM (with an obvious constraint in terms of memory footprint), but storing these information instead in dedicated files offers more advantages (but then a two-way serialisation service is needed).</p>
<p>For that we defined a simple file format, based on a header (specifying the version of that format) and a series of serialised entries, each of them being made of a type information (i.e. serialisation for a model instance, a probe instance or an agent instance) and a content, whose actual format depends on that type. The full specification of the format is documented in <tt class="docutils literal">class_ResilienceAgent.erl</tt>.</p>
<p>Multiple steps of this procedure are instrumented thanks to WOOPER; notably:</p>
<ul class="simple">
<li>once, with the help of the time manager, the resilience manager determined that a serialisation shall occur, it requests all its distributed resilience agents to take care of the node they are running on</li>
<li>to do so, each of them retrieves references (PID) of all local actors (from the corresponding local time manager), local simulation agents and local probes; then each of these instances is requested to serialise itself</li>
<li>such a serialisation involves transforming its current state, notably replacing PID (that are transient) by higher-level, reproducible identifiers (the conversion being performed by a distributed instance tracking service); for that, the underlying data-structure of each attribute value (ex: nested records in lists of tuples containing in some positions PID) is discovered at runtime, and recursively traversed and translated with much help from nested higher-order functions and closures; it results finally into a compact, binary representation of the state of each instance</li>
<li>on each node (thus, in a distributed way), these serialisations are driven by worker processes (i.e. in parallel, to take also advantage of all local cores), and the resulting serialised content is sent to a local writer process (in charge of writing the serialisation file), tailored not to be a bottleneck; reciprocally, the deserialisation is based on as many parallel processes (for reading, recreating and relinking instances) as there are serialisation files to read locally</li>
</ul>
<p>A few additional technical concerns had to be dealt with this resilience feature, like:</p>
<ul class="simple">
<li>The proper starting of Erlang VMs, so that the crash of a subset of them could be first detected, then overcome (initial versions crashed in turn; using now <tt class="docutils literal">run_erl</tt>/<tt class="docutils literal">to_erl</tt>)</li>
<li>The redeployment of the engine services onto the surviving hosts; for example, the loss of nodes used to result in reducing accordingly the number of time managers, and thus merging their serialised state; however this mode of operation has not been kept, as the random state of these managers cannot be merged satisfactorily (to preserve reproducibility, models but also time managers need to rely on the same separate, independent random series as initially, notwithstanding the simulation rollbacks)</li>
<li>Special cases must be accounted for, as crashes may happen while performing a serialisation snapshot or while being already in the course of recovering from previous crashes</li>
</ul>
<p>Currently, when recovering from a crash, by design there is at least one extra set of agent states to consider (corresponding to at least one crashed node). Either these information are merged in the state of agents running on surviving nodes, or more than one agent of a given kind is created on the same computing node.</p>
<p>The latter solution raises issues, as up to one agent of a kind can register locally, and multiplying agents that way may hurt the performances.</p>
<p>So we preferred the former solution, even if the agents have then to be merged, and also if it leads to having rollbacks break reproducibility: indeed, whenever a computing node has to manage more than one serialisation file, its time manager will inheritmore than one random seed, and it will not be able to reproduce the two different random series that existed before the crash.</p>
</div>
</div>
<div class="section" id="testing">
<h2><a class="toc-backref" href="#id198">Testing</a></h2>
<p>The initial testing was done by specifying more than one computing host, and emulating first the simultaneous crashes of all other hosts at various steps of the simulation. This is to be done either by unplugging the Ethernet cable of the user host or, from a terminal on that host, running as root a simple command-line script like <a class="footnote-reference" href="#id58" id="id57">[27]</a>:</p>
<pre class="code bash literal-block">
$ <span class="k">while</span> true<span class="p">;</span> <span class="k">do</span> <span class="nb">echo</span> <span class="s2">&quot;Disabling network&quot;</span><span class="p">;</span> ifconfig eth0 down<span class="p">;</span> <span class="se">\
</span>  read<span class="p">;</span> <span class="nb">echo</span> <span class="s2">&quot;Enabling network...&quot;</span><span class="p">;</span> dhclient eth0 <span class="o">&amp;&amp;</span>           <span class="se">\
</span>  <span class="nb">echo</span> <span class="s2">&quot;...enabled&quot;</span><span class="p">;</span> read<span class="p">;</span> <span class="k">done</span>
</pre>
<p>(hitting Enter allows to toggle between a functional network interface and one with no connectivity)</p>
<table class="docutils footnote" frame="void" id="id58" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id57">[27]</a></td><td><p class="first">Regarding the emulation of connections losses:</p>
<ul class="last simple">
<li><tt class="docutils literal">ifup</tt> and  <tt class="docutils literal">ifdown</tt> are a lot less appropriate than <tt class="docutils literal">ifconfig</tt> for that, notably as they apparently remove route definitions and DNS settings. Moreover even <tt class="docutils literal">ifdown <span class="pre">--force</span> eth0</tt> may fail to stop a currently used interface (<tt class="docutils literal">SIOCDELRT: No such process</tt>)</li>
<li>the <tt class="docutils literal">dhclient</tt> call here is not necessary for the current simulation to resume, but it is for the next launch, which will need DNS resolution</li>
</ul>
</td></tr>
</tbody>
</table>
<p>For a better checking of this feature, we then relied on a set of 10 virtual machines (<tt class="docutils literal"><span class="pre">HOSTS=&quot;host_1</span> <span class="pre">host_2...&quot;</span></tt>) on which we simply:</p>
<ul class="simple">
<li>updated the distribution with the right prerequisites: <tt class="docutils literal"><span class="pre">apt-get</span> update &amp;&amp; <span class="pre">apt-get</span> install g++ make <span class="pre">libncurses5-dev</span> openssl <span class="pre">libssl-dev</span> <span class="pre">libwxgtk2.8-dev</span> <span class="pre">libgl1-mesa-dev</span> <span class="pre">libglu1-mesa-dev</span> libpng3 gnuplot</tt></li>
<li>created a non-privileged user: <tt class="docutils literal">adduser <span class="pre">diasca-tester</span></tt></li>
<li>built Erlang on his account: <tt class="docutils literal">su <span class="pre">diasca-tester</span></tt> ; <tt class="docutils literal">cd <span class="pre">/home/diasca-tester</span> &amp;&amp; <span class="pre">./install-erlang.sh</span> <span class="pre">-n</span></tt></li>
<li>recorded a public key on each of these 10 computing hosts:</li>
</ul>
<pre class="code bash literal-block">
$ <span class="k">for</span> m in <span class="nv">$HOSTS</span> <span class="p">;</span> <span class="k">do</span> ssh diasca-tester&#64;<span class="nv">$m</span> <span class="se">\
</span><span class="s1">'mkdir /home/diasca-tester/.ssh &amp;&amp;          \
chmod 700 /home/diasca-tester/.ssh'</span> <span class="p">;</span> scp   <span class="se">\
</span>/home/diasca-tester/.ssh/id_rsa.pub         <span class="se">\
</span>diasca-tester&#64;<span class="nv">$m</span>:/home/diasca-tester/.ssh/authorized_keys<span class="p">;</span> <span class="se">\
</span><span class="k">done</span>
</pre>
<ul class="simple">
<li>ensured the right version of the Erlang VM is used:</li>
</ul>
<pre class="code bash literal-block">
$ <span class="k">for</span> m in <span class="nv">$HOSTS</span> <span class="p">;</span> <span class="k">do</span> ssh diasca-tester&#64;<span class="nv">$m</span>  <span class="se">\
</span><span class="s2">&quot;echo 'export PATH=~/Software/Erlang/Erlang-current-install/bin:\$PATH' \
| cat -  ~/.bashrc &gt; /tmp/bash-erl &amp;&amp;        \
/bin/mv -f /tmp/bash-erl ~/.bashrc&quot;</span>
</pre>
<p>This command is a tad complex, as some default <tt class="docutils literal"><span class="pre">~/.bashrc</span></tt> include:</p>
<pre class="code bash literal-block">
<span class="c1"># If not running interactively, don't do anything
</span><span class="o">[</span> -z <span class="s2">&quot;</span><span class="nv">$PS1</span><span class="s2">&quot;</span> <span class="o">]</span> <span class="o">&amp;&amp;</span> <span class="k">return</span>
</pre>
<p>So the path must be specified at the <em>beginning</em> of the file, rather than later.</p>
<p>Simulations can then run on the user host and the 10 additional ones.</p>
<p>Then their failure can be simulated from the command-line, using tools provided by the vendor of the virtual infrastructure (ex: <tt class="docutils literal">VBoxManage controlvm</tt> with <a class="reference external" href="https://www.virtualbox.org/">VirtualBox</a>, with VMWare vSphere command-line interface, etc.) or UNIX brutal kills through SSH.</p>
<p>Of course once the initial testing and troubleshooting has been done thanks to this setting, real-life situations (involving notably network links to be unplugged at random moments while a simulation is running) must be reproduced.</p>
<p>As sneaking into an HPC control room in order to perform selective sabotage on the relevant cables is not really an option, such a testing is better be done on a simple ad-hoc set of networked computers.</p>
</div>
<div class="section" id="future-improvements">
<h2><a class="toc-backref" href="#id199">Future Improvements</a></h2>
<p>Many enhancements could be devised, including:</p>
<ul class="simple">
<li>Merging all agents in each node, except the time managers, so that reproducibility (i.e. distinct random series) can be preserved</li>
<li>Increasing the compactness of serialisation archives (alleviating in turn the network transfers)</li>
<li>Tuning the resilience mechanisms thanks to larger-scale snapshots, to identify the remaining bottlenecks (profiling the whole serialisation process, meant to happen a lot more frequently to its counterpart deserialisation one)</li>
<li>Allowing for a “cold start”, i.e. restarting from only serialisation files (while Sim-Diasca is not running), even though collecting them post-mortem on various computing hosts is not nearly as convenient as having the engine perform directly an automatic, live rollback which might even remain unnoticed from the user</li>
<li>Applying a second pass of load-balancing, onto the serialised actors (this would probably require implementing actor migration), if the post-rollback computing and network load was found too uneven in some cases</li>
</ul>
<p>Anyway, to the best of our knowledge, at least for civil applications, there are very few other discrete time massively parallel and distributed simulation engines, and we do not know any that implements resilience features akin to the one documented here, so we already benefit from a pretty hefty solution.</p>
<p></p>
</div>
</div>
<div class="section" id="sim-diasca-technical-architecture">
<h1><a class="toc-backref" href="#id200">Sim-Diasca Technical Architecture</a></h1>
<div class="section" id="general-view">
<h2><a class="toc-backref" href="#id201">General View</a></h2>
<p><span class="raw-html"><center><img src="technical-architecture-english.png" id="responsive-image-medium"></img></center></span>
</p>
<p></p>
</div>
<div class="section" id="supported-platforms">
<h2><a class="toc-backref" href="#id202">Supported Platforms</a></h2>
<p>The development and use of Sim-Diasca is mostly focused on the GNU/Linux platform.</p>
<p>Sim-Diasca should be basically quite close to be able to run on most UNIX computers, yet some platform perks would have to be overcome beforehand.</p>
<p>At least one build on Mac OS X has been reported, yet the operated changes have not been shared. Patches welcome!</p>
<p>The Windows systems <em>could</em> be targeted as well, yet with probably more effort.</p>
<p>More generally, the ability to run on HPC <a class="footnote-reference" href="#id60" id="id59">[28]</a> clusters (<tt class="docutils literal">[S7]</tt>)  improves a lot the performances, not only because of the high-level of RAM and CPU they provide, but also, and maybe to a larger extent, because of the high-performance network links they makes use of: the shorter a tick lasts, the more low-latency networks, like Infiniband, boost the overall simulation performance.</p>
<table class="docutils footnote" frame="void" id="id60" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id59">[28]</a></td><td>HPC meaning <em>High Performance Computing</em> here.</td></tr>
</tbody>
</table>
<p>We made significant use of <a class="reference external" href="http://en.wikipedia.org/wiki/Portable_Batch_System">PBS-based</a> clusters, then of ones relying on <a class="reference external" href="https://slurm.schedmd.com/">SLURM</a>. A lightweight abstraction layer has been built over both (see <tt class="docutils literal"><span class="pre">sim-diasca/conf/clusters/sim-diasca-launcher.sh</span></tt>). Other cluster scripts have been developed to respectively deploy, launch and collect results for <em>sets</em> of experiments (ex: automating the launching of 72 simulations, to perform some parametric studies).</p>
</div>
<div class="section" id="tools-for-the-sim-diasca-simulation-engine-itself">
<h2><a class="toc-backref" href="#id203">Tools For the Sim-Diasca Simulation Engine Itself</a></h2>
<div class="section" id="id61">
<h3>Erlang</h3>
<p>Basically, <a class="reference external" href="http://www.erlang.org">Erlang</a> provides a full environment particularly suitable for multi-agent applications.</p>
<p>At this lower level of the architecture, we are dealing with <em>Erlang processes</em>, which are lightweight objects:</p>
<ul class="simple">
<li>having each their own execution thread (their mode of operation is inherently concurrent)</li>
<li>communicating between them only thanks to messages (pure asynchronous message passing, no memory is shared)</li>
</ul>
<p>Erlang processes are not mapped to any scheduling object provided by the operating system or by the general execution environment. Thus Erlang processes are not system processes nor threads.</p>
<p>The Erlang virtual machine schedules itself all the Erlang processes it is hosting <a class="footnote-reference" href="#id64" id="id63">[29]</a>. This is why the number of concurrent processes within the Erlang virtual machine can strongly outperform the number that could be achieved with any system-level thread of execution, as the overhead that Erlang processes induce is considerably smaller.</p>
<table class="docutils footnote" frame="void" id="id64" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id63">[29]</a></td><td>This is an example of the so-called <em>green threads</em>.</td></tr>
</tbody>
</table>
<p>Erlang processes execute <em>functions</em> that are gathered in <em>modules</em>. Being Erlang code, they are implemented in a declarative, functional way, with single-assignment, absence of side-effects, pattern-matching and recursive behaviour:</p>
<p><span class="raw-html"><center><img src="xkcd-dependencies.png" id="responsive-image-medium"></img></center></span>
</p>
<p>Although a bit disconcerting at first glance, these kinds of languages are very suitable to develop complex algorithms and, more generally, scalable and reliable software.</p>
<p>Notably they offer higher-level constructs that allow Erlang programs written for one node to be distributed on a set of machines seamlessly, i.e. with little or no changes in the code, since Erlang processes will in both cases only exchange messages, regardless of their actual location (either on the same node or in networked nodes).</p>
<p>Erlang is an open source software, and has been used for more than 20 years. Its future is bright: now that physical limits are almost reached, microprocessors are less and less able to increase their operating frequencies, therefore the only solution that remains is to multiply the number of cores and try to use them effectively.</p>
<p>However traditional sequential languages cannot cope gracefully with such a parallel context, as they cannot deal with concurrent accesses to shared memory without error-prone and resource-consuming solutions, like mutex and semaphores. Therefore concurrency-based languages like Erlang should be increasingly needed in the years to come.</p>
</div>
<div class="section" id="myriad">
<h3>Myriad</h3>
<p><a class="reference external" href="http://myriad.esperide.org/">Myriad</a> (precisely, Ceylan-Myriad) is a generic toolbox built on top of Erlang, offering many low-level services used by all the upper layers involved here.</p>
</div>
<div class="section" id="wooper">
<h3>WOOPER</h3>
<p>Erlang offers very suitable base services for our requirements, but when developing simulations one extra property would help a lot: the ability to model and implement simulated elements according to the Object-Oriented Paradigm.</p>
<p>Indeed, the modelling of numerous and complex behaviours is easier if being able to use the classical concepts of OOP like components, classes, instances, remote method invocations, inheritance, polymorphism, state management, etc.</p>
<p>Implementation is itself easier if the language supports some way of relying on a direct mapping between the OOP modelling concepts and the nuts and bolts offered by that language.</p>
<p>As classical Erlang is process-based and declarative, the OOP constructs have to added to the language. This is the task of <a class="reference external" href="http://wooper.esperide.org/">WOOPER</a>, which stands for <em>Wrapper for OOP in Erlang</em>.</p>
<p>WOOPER (precisely, Ceylan-Myriad) is a very lightweight layer that adds some code and conventions to Erlang so that a full-blown OOP approach can be applied directly to the language, at the expense of very little additional developing efforts and only a small run-time overhead.</p>
<p>Therefore, from that level on, we will not speak in terms of Erlang processes any more, we will mostly be dealing with instances of WOOPER classes.</p>
<p>WOOPER is an open source software (LGPL license).</p>
</div>
<div class="section" id="id67">
<h3>Sim-Diasca</h3>
<p>Such WOOPER instances are however not simulation actors yet: the support for the already mentioned mechanisms required in the context of a distributed simulation must be added, otherwise causality, reproducibility, etc. would not be ensured.</p>
<p>This is the task of the <tt class="docutils literal">core</tt> component of the Sim-Diasca simulation engine: it provides the required technical components (like the <tt class="docutils literal">TimeManager</tt> and the <tt class="docutils literal">RandomManager</tt>) and the counterpart behaviours that all simulation actors should develop to interact properly with these technical components.</p>
<p>More precisely, Sim-Diasca Core provides the <tt class="docutils literal">Actor</tt> class, from which all Sim-Diasca models should inherit (directly or not). Then they will automatically embed all the necessary logic to interact with the <tt class="docutils literal">TimeManager</tt>, which includes managing <tt class="docutils literal">top</tt> messages, tracking transparently acknowledgements of sent actor messages, dealing with errors and appropriate ends of ticks, etc.</p>
<p>Actors making use of random variables have also to interact correctly with the  <tt class="docutils literal">RandomManager</tt>. This is done similarly, just by inheriting from the <tt class="docutils literal">StochasticActor</tt> class, which itself is a child class of the <tt class="docutils literal">Actor</tt> class. Then all the mechanisms to find and use the <tt class="docutils literal">RandomManager</tt> will be readily available, like for example the algorithm to maintain automatically a buffer of cached random values.</p>
<p>Finally, thanks to these inheritances, the development of models will mostly consist on specifying the business-specific state changes and message exchanges supported by each type of simulated element. Most technical issues are hidden to the model developer, who will only have to define:</p>
<ul class="simple">
<li>how an actor will be initialised (i.e. the constructor of its class)</li>
<li>how an actor will be deleted (i.e. the destructor of its class)</li>
<li>how an actor will behave spontaneously at each tick (i.e. its <tt class="docutils literal">act</tt> method)</li>
<li>any other behaviours that could be triggered by notifications received from other actors (i.e. the methods other simulation actors might call, thanks to actor messages)</li>
</ul>
<p>These are totally model-specific, no simulation mechanism can provide them, only the model developer can know which code is relevant here.</p>
<p><tt class="docutils literal"><span class="pre">Sim-Diasca</span> Core</tt> provides as well useful technical components, like a full distribute trace system to be used by simulations.</p>
</div>
</div>
<div class="section" id="complementary-tools">
<h2><a class="toc-backref" href="#id204">Complementary Tools</a></h2>
<p>A few third-party tools are used in the context of Sim-Diasca. They are not direct parts of the simulation engine, but they are very useful to make a better use of the framework.</p>
<p>As they are already wrapped by the appropriate Sim-Diasca code, they will be automatically triggered and used by the simulator, with no further action from the user.</p>
<div class="section" id="logmx">
<h3>LogMX</h3>
<p><a class="reference external" href="http://www.logmx.com/">LogMX</a> is a simple yet quite powerful tool to view logs. In the context of Sim-Diasca it is the main part of the supervisor of simulation traces.</p>
<p>As stated earlier, a simulation-specific format for traces is needed, and of course LogMX cannot know it <em>a priori</em>. Therefore a small LogMX-compliant trace parser, written in Java, has been developed, which integrates to LogMX. This is the only bit of Java involved in Sim-Diasca.</p>
<p>LogMX is a rather inexpensive tool (at most $29 per user), and Sim-Diasca can make use of its evaluation version as well.</p>
</div>
<div class="section" id="gnuplot">
<h3>gnuplot</h3>
<p><a class="reference external" href="http://www.gnuplot.info/">gnuplot</a> is a very well-known portable data and function plotting utility.</p>
<p>It is notably used by Sim-Diasca probes when they are requested to output a graphical view of their state: they automatically generate the appropriate command and data files, then call gnuplot to have it render the corresponding curves in a graphic file that might be displayed if wanted.</p>
<p>gnuplot is freely distributed.</p>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">Ensure that the <tt class="docutils literal">gnuplot</tt> version installed on your system is not too obsolete. Version 4.2 and higher is recommended, otherwise the generation of some graph renderings might fail.</p>
</div>
</div>
<div class="section" id="graphviz-dot">
<h3>Graphviz Dot</h3>
<p><a class="reference external" href="http://www.graphviz.org/">Graphviz</a> is another quite widespread tool, which is a graph visualisation software.</p>
<p>Sim-Diasca uses it to generate graphical views of meshes: a <tt class="docutils literal">Mesh</tt> (directed graph) is able to output a suitable description of this vertices and edges so that the <tt class="docutils literal">dot</tt> program can generate from it a graphic file that might be displayed if wanted.</p>
<p>Various models make use of such meshes, like the <tt class="docutils literal">LowVoltageMesh</tt>.</p>
<p>Graphviz (including dot) is an open source software.</p>
</div>
<div class="section" id="image-viewer">
<h3>Image Viewer</h3>
<p>When Sim-Diasca needs to display a graphic file, it can drive various tools to do so, including the <tt class="docutils literal">eog</tt> viewer, which is open source.</p>
</div>
<div class="section" id="mplayer-mencoder">
<h3>Mplayer/Mencoder</h3>
<p><a class="reference external" href="http://www.mplayerhq.hu">Mplayer</a> is an open source software package that allows, among other things, to generate movies from a set of image files (with <tt class="docutils literal">mencoder</tt>), and to display them (with <tt class="docutils literal">mplayer</tt>).</p>
<p>Sim-Diasca uses them to aggregate a set of time stamped frames (each frame corresponding to one simulation tick) into a movie, so that the changes over time of graphical simulation results can be better monitored by the user.</p>
<p>For example, if, for a mesh, the generation of a time-based description of its state has been requested, a corresponding movie can be generated.</p>
</div>
</div>
<div class="section" id="other-tools">
<h2><a class="toc-backref" href="#id205">Other Tools</a></h2>
<p>They are not used at execution-time (i.e. during a simulation), but they are nevertheless involved in our daily usage of Sim-Diasca.</p>
<div class="section" id="gnu-make">
<h3>GNU make</h3>
<p>The <a class="reference external" href="http://www.gnu.org/software/make/manual/make.html">GNU make</a> utility, which determines automatically which pieces of a large program need to be recompiled, and issues the commands to recompile them, is intensively used by Sim-Diasca, to build and run the simulator itself but also to post-process some of its results.</p>
<p>GNU make is open source.</p>
</div>
<div class="section" id="version-control-git">
<h3>Version Control: GIT</h3>
<p><a class="reference external" href="http://git-scm.com/">GIT</a>, is a free and open source distributed version control system. It allows to keep track of the changes of the Sim-Diasca source code, and to share it among developers.</p>
</div>
<div class="section" id="docutils">
<h3>Docutils</h3>
<p><a class="reference external" href="http://docutils.sourceforge.net/">Docutils</a> is a set of open source documentation utilities. It operates on text files respecting the <em>reStructuredText</em> mark-up syntax, and is able to generate from it various formats, including LateX (hence PDF) and HTML.</p>
<p>This document has been generated thanks to Docutils.</p>
<p></p>
</div>
</div>
</div>
<div class="section" id="sim-diasca-building-blocks">
<h1><a class="toc-backref" href="#id206">Sim-Diasca Building Blocks</a></h1>
<div class="section" id="id72">
<span id="simulation-traces"></span><h2><a class="toc-backref" href="#id207">Simulation Traces</a></h2>
<div class="section" id="id73">
<h3>Principles</h3>
<p>Traces (a.k.a. simulation logs) are a way of recording for later use any event of interest, of any sort (technical or domain-specific), happening during a simulation. Traces allow to monitor selectively an execution, without recording each and every event that occurred.</p>
<p>Traces are not simulation results per se, their purpose is to make the technical troubleshooting easier, notably in order to help developing and debugging models.</p>
<p>Trace facilities are gathered in a separate layer, the <tt class="docutils literal">Traces</tt> one (in the <tt class="docutils literal">traces</tt> directory), which is used, among others, by Sim-Diasca. The <tt class="docutils literal">Traces</tt> service depends only on <tt class="docutils literal">WOOPER</tt> and on <tt class="docutils literal">Myriad</tt>. Refer to the <a class="reference external" href="https://olivier-boudeville.github.io/Ceylan-Traces/">Ceylan-Traces</a> official website for most information.</p>
<p>Please refer to the <em>Sim-Diasca Developer Guide</em> for information about the actual (practical) use of traces.</p>
<p>Defining a trace format allows to uncouple the execution of a simulation from the interpretation of what happened during its course of action (we can either monitor the simulation &quot;live&quot;, or study it &quot;post-mortem&quot;, i.e. after its termination).</p>
<p>If moreover the format is designed to be &quot;universal&quot; (in the context of discrete-time simulations), in order to be independent from a particular domain and from any trace generator or supervisor, then the post-processing toolchain of traces might be shared between several simulators.</p>
</div>
<div class="section" id="id74">
<h3>Architecture</h3>
<p>With Sim-Diasca, the management of distributed traces is split into the following roles:</p>
<ul class="simple">
<li>Each simulated object (model instance, i.e. actor), but also each technical agent or simulation case, may be led to send traces regarding its operation. The vast majority of them are <tt class="docutils literal">TrameEmitter</tt> instances (they inherit from that class, directly or not), other are not instances thereof but nevertheless need to be able to output traces (ex: test cases)</li>
<li>The distributed traces have to be collected and aggregated, this is done by a <tt class="docutils literal">TraceAggregator</tt> instance, which supports various output formats. Then overall analysis and search for event correlations are possible</li>
<li>The simulation user might want to monitor the system, based on the emitted traces. This can be done either at execution-time (in real time) or post-mortem (once the simulation is over), both thanks to a <tt class="docutils literal">TraceSupervisor</tt>, which can run from a remote host; moreover <tt class="docutils literal">TraceListener</tt> instances can be created, so that from any host one can connect to the simulation while it is running, catching up automatically (past traces being sent as a whole initially, in a compressed form, next ones being sent directly, so that none is lacking)</li>
</ul>
</div>
<div class="section" id="how-to-manage-the-trace-induced-overhead">
<h3>How to manage the trace-induced overhead</h3>
<p>Sending, collecting and aggregating traces proves very useful, but this feature demands resources, in terms of processing, memory and bandwidth: most of our models and agents by default emit many traces (they are intentionally very talkative), to help troubleshooting. As this is a distributed trace system, traces are emitted concurrently but at the end must be aggregated sequentially, in order to be consulted as a whole, in a single location. Therefore, beyond some simulation scale - and despite careful design - the trace aggregator is bound to become a bottleneck because of the massive message sending.</p>
<p>As a consequence, the point has been, for non-critical channels, to be able to disable trace sending as a whole, <em>without any performance penalty</em> compared to the same code in which there would not be any trace sending at all.</p>
<p>To disable trace sending and incur no runtime overhead, one should ensure that the compile-time make variable <tt class="docutils literal">ENABLE_TRACES</tt> is set to false <a class="footnote-reference" href="#id76" id="id75">[30]</a>. To do so, one should either specify it directly on the command-line (ex: <tt class="docutils literal">make clean all ENABLE_TRACES=false</tt>), or update directly the make files (typically by setting <tt class="docutils literal">ENABLE_TRACES := false</tt> in <tt class="docutils literal">traces/GNUmakevars.inc</tt>). Then everything above WOOPER (i.e. the Traces layer, the Sim-Diasca layer, and the code using it) should be rebuilt, as it is a compile-time (as opposed to runtime) option.</p>
<table class="docutils footnote" frame="void" id="id76" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id75">[30]</a></td><td>This will result in <em>not</em> having the  <tt class="docutils literal">TracingActivated</tt> preprocessor symbol defined.</td></tr>
</tbody>
</table>
<div class="admonition tip">
<p class="first admonition-title">Tip</p>
<p>If wanting to operate a selection on the classes whose instances must be able to send traces while others cannot, one may just keep the default <tt class="docutils literal">ENABLE_TRACES := true</tt> and compile everything with traces disabled (from the root: <tt class="docutils literal">make clean all ENABLE_TRACES=false</tt>, then  update the timestamp of the source files of the cherry-picked classes that are to be allowed to send traces (ex: <tt class="docutils literal">touch class_Foobar.erl</tt>), then run <tt class="docutils literal">make all</tt> from the root of the sources: all classes then rebuilt will have traces enabled.</p>
<p class="last">Of course this can be done the other way round, in order to just select the classes that are to be silenced.</p>
</div>
<p>Finally, one should know that, if going for higher simulation scales, traces shall not be the only feature to be appropriately managed. Please refer to the <a class="reference internal" href="#how-should-i-run-larger-simulations">How Should I run larger simulations?</a> section for a description of the relevant measures that shall be taken for that (this includes trace disabling).</p>
</div>
<div class="section" id="trace-channels">
<h3>Trace Channels</h3>
<p>There are eight built-in trace channels, of increasing severity:</p>
<ul class="simple">
<li><tt class="docutils literal">debug</tt></li>
<li><tt class="docutils literal">info</tt></li>
<li><tt class="docutils literal">notice</tt></li>
<li><tt class="docutils literal">warning</tt></li>
<li><tt class="docutils literal">error</tt></li>
<li><tt class="docutils literal">critical</tt></li>
<li><tt class="docutils literal">alert</tt></li>
<li><tt class="docutils literal">emergency</tt></li>
</ul>
<p>Depending on the nature of its message, a trace emitter can select in which channel its current trace should be output.</p>
<p>The five most critical - yet least used - trace channels (<tt class="docutils literal">warning</tt>, <tt class="docutils literal">error</tt>, <tt class="docutils literal">critical</tt>, <tt class="docutils literal">alert</tt> and <tt class="docutils literal">emergency</tt>) will always echo their messages on the console as well (to ensure none can remain unnoticed), and will not be disabled even if the trace system is deactivated (i.e. regardless of the <tt class="docutils literal">ENABLE_TRACES</tt> settings).</p>
<p>Depending on the needs of the simulation user, various types of trace outputs can be selected:</p>
<ul class="simple">
<li>traces integrated to an interactive graphical tool (LogMX)</li>
<li>traces in raw text (to be browsed thanks to any text editor)</li>
<li>PDF traces (any PDF viewer can then be used)</li>
</ul>
<p>The type of traces is by default based on LogMX.</p>
<p>This can be changed (<tt class="docutils literal">TraceType</tt> being then either <tt class="docutils literal">log_mx_traces</tt> or <tt class="docutils literal">{text_traces,T}</tt> where <tt class="docutils literal">T</tt> is either <tt class="docutils literal">text_only</tt> or <tt class="docutils literal">pdf</tt>):</p>
<ul>
<li><p class="first">one time for all, by editing the <tt class="docutils literal">TraceType</tt> define in <tt class="docutils literal">traces/src/traces.hrl</tt> (and then rebuilding all)</p>
</li>
<li><p class="first">on a per-case basis, still at compilation-time, by using the <tt class="docutils literal"><span class="pre">?case_start(TraceType)</span></tt> macro (ex: see <tt class="docutils literal">soda_stochastic_integration_test.erl</tt>)</p>
</li>
<li><p class="first">at runtime, by specifying the <tt class="docutils literal"><span class="pre">--trace-type</span> TraceSpecType</tt> command-line option, where <tt class="docutils literal">TraceSpecType</tt> is <tt class="docutils literal">logmx</tt>, <tt class="docutils literal">text</tt> or <tt class="docutils literal">pdf</tt>, like in:</p>
<pre class="literal-block">
$ make foobar_run CMD_LINE_OPT=&quot;--trace-type text --batch&quot;
</pre>
</li>
</ul>
</div>
<div class="section" id="traces-for-logmx">
<h3>Traces For LogMX</h3>
<p>The resulting interface when browsing the traces (written in a <tt class="docutils literal">*.traces</tt> file) with default aggregator output corresponds to:</p>
<p><span class="raw-html"><center><img src="logmx-interface.png" id="responsive-image-large"></img></center></span>
</p>
<p>Using the LogMX trace supervisor is surely the most useful way of monitoring the traces, in real-time or post-mortem. As such it is the trace supervisor that is by far the most frequently used.</p>
<p><a class="reference external" href="http://www.logmx.com/">LogMX</a> offers rich features that allow to:</p>
<ul class="simple">
<li>browse conveniently even large sets of traces</li>
<li>select the minimum level of detail for the traces to be displayed</li>
<li>search traces for specific patterns, or by emitter, date, location, etc.</li>
</ul>
<p>The only drawbacks of this trace mode are that:</p>
<ul class="simple">
<li>it requires a specific (commercial) tool (LogMX), properly obtained, installed and configured with the Sim-Diasca parser</li>
<li>the results cannot be directly integrated into a report</li>
</ul>
<p>LogMX-based traces are the default output type. Should the trace output type have been changed, it can be restored by setting <tt class="docutils literal">TraceType</tt> to <tt class="docutils literal">log_mx_traces</tt>, in <tt class="docutils literal">traces/src/traces.hrl</tt>.</p>
</div>
<div class="section" id="text-based-traces">
<h3>Text Based Traces</h3>
<p>Although it is generally less convenient, simulation traces can be inspected directly from any text viewer (hence without LogMX).</p>
<p>If such a reading could be directly performed on the trace file (typically named <tt class="docutils literal"><span class="pre">MY_CASE-by-MY_USER-MY_SII.traces</span></tt>) that is generated by default for LogMX, its formatting is designed for that latter tool rather than for humans, hence is a bit difficult to read in its raw form. A better option is in this case to select a trace format whose outputs are meant to be read directly as they are, as free text.</p>
<p>To do so, in <tt class="docutils literal">traces/src/traces.hrl</tt>, just define <tt class="docutils literal">TraceType</tt> to <tt class="docutils literal">{text_traces,text_only}</tt> instead of <tt class="docutils literal">log_mx_traces</tt>, and rebuild everything above <tt class="docutils literal">WOOPER</tt> (i.e. the <tt class="docutils literal">Traces</tt> package, the <tt class="docutils literal"><span class="pre">Sim-Diasca</span></tt> package, and the code using it).</p>
<p>As a result, simulation traces output in the aforementioned trace file will be in plain text and encoded for human readability (within a nice ASCII-art array); they can thus be then read as are thanks to any text viewer.</p>
<p>By default <tt class="docutils literal">gedit</tt> will be automatically triggered as a trace supervisor, and the user will be requested by the editor to reload that document as newer traces are appended.</p>
<p>If wanting to use another text viewer, just update accordingly the <tt class="docutils literal">executable_utils:get_default_wide_text_viewer/1</tt> function in the <tt class="docutils literal">Myriad</tt> package (in <tt class="docutils literal">myriad/src/utils/executable_utils.erl</tt>): <tt class="docutils literal">gedit</tt> might be replaced for example by <tt class="docutils literal">nedit</tt> or by <tt class="docutils literal">xemacs</tt>.</p>
<p>Note that only the most interesting trace fields are kept here (a well-chosen subset of the full, actual ones), for the sake of readability.</p>
</div>
<div class="section" id="pdf-trace-report">
<h3>PDF Trace Report</h3>
<p>When wanting to generate a trace report once the simulation is over - rather than monitoring the traces during the simulation, a PDF output can be retained.</p>
<p>To do so, in <tt class="docutils literal">traces/src/traces.hrl</tt>, just define <tt class="docutils literal">TraceType</tt> to <tt class="docutils literal">{text_traces,pdf}</tt> instead of the default <tt class="docutils literal">log_mx_traces</tt>, and rebuild everything above <tt class="docutils literal">WOOPER</tt> (i.e. the <tt class="docutils literal">Traces</tt> package, the <tt class="docutils literal"><span class="pre">Sim-Diasca</span></tt> package, and the code using it).</p>
<p>Then, as soon as the simulation will have stopped, the traces will be properly aggregated and formatted from Sim-Diasca, a PDF being generated and then automatically displayed. This PDF can be useful to share simulation results asynchronously (ex: with remote colleagues).</p>
<p>Only the most interesting trace fields are kept here (a well-chosen subset of the full, actual ones), for the sake of readability.</p>
<p>Note that this feature implies of course that you have already the proper documentation toolchain installed, which includes the RST converters (<tt class="docutils literal"><span class="pre">python-docutils</span></tt> package) and a PDF viewer (by default, <tt class="docutils literal">evince</tt> will be used).</p>
<p>In the future, we could imagine an enhancement that would allow to convert a trace file generated for LogMX into a PDF, so that the user can generate a report without having to run again the simulation with different trace settings.</p>
<p>However, as simulations are expected to be totally reproducible, it would just a matter of saving some runtime, so the priority of this enhancement is low.</p>
<p>If wanting to use another PDF reader than <tt class="docutils literal">evince</tt>, just update accordingly the <tt class="docutils literal">executable_utils:get_default_pdf_viewer/0</tt> function in the <tt class="docutils literal">Myriad</tt> package (in <tt class="docutils literal">myriad/src/utils/executable_utils.erl</tt>): <tt class="docutils literal">evince</tt> might be replaced for example by <tt class="docutils literal">mupdf</tt>, otherwise by <tt class="docutils literal">acroread</tt> or <tt class="docutils literal">xpdf</tt>.</p>
<p>Then recompiling this module should be enough.</p>
<p></p>
</div>
</div>
<div class="section" id="id78">
<span id="probes"></span><span id="probe"></span><h2><a class="toc-backref" href="#id208">Probes</a></h2>
<p>The Sim-Diasca <strong>probes</strong> can collect all kinds of numerical data produced during simulation, and generate a graphical view of them.</p>
<p>Probes are <em>result producers</em>, and as such are dealt with by the <em>result manager</em>.</p>
<p>There are two main kinds of built-in probes:</p>
<ul class="simple">
<li><em>basic probes</em>, the most resource-efficient, scalable ones</li>
<li><em>virtual probes</em>, based on the data-logger, the most flexible and powerful ones</li>
</ul>
<p>They are based on similar interfaces and share most features, including the management of their rendering.</p>
<p>Among the common features:</p>
<ul class="simple">
<li>a probe will be created if and only if it is to produce a result of interest for the simulation, i.e. iff it matches the result specification chosen by the user (in the simulation settings); otherwise this probe will be not created at all, sparing 100% of the resources it would require</li>
<li>their data files for time series all start with an header that lists meta-data like generation date and time, probe name, title, and the description of the curves involved</li>
</ul>
<p>As subclassing the basic probe or devising new ones (ex: web-based ones) is relatively straightforward, projects may start with built-in probes and define in their course specialised ones.</p>
<p>Another popular option is to switch to dedicated plotting/rendering libraries when post-processing the data resulting from the simulation. Then, in the simulation case of interest, the <tt class="docutils literal">data_only</tt> producer option might be specified in the patterns listed in the <tt class="docutils literal">result_specification</tt> field of the <tt class="docutils literal">simulation_settings</tt> record , in which case only the corresponding data files (<tt class="docutils literal">*.dat</tt> files) will be produced (no <tt class="docutils literal">*.png</tt> plot files).</p>
<div class="section" id="generic-probe">
<h3>Generic Probe</h3>
<p>A generic probe can be dynamically configured to gather any number of time series, and represent them with as many curves whose abscissa axis corresponds to the simulation time, like in:</p>
<p><span class="raw-html"><center><img src="xkcd-stove_ownership.png" id="responsive-image-reduced"></img></center></span>
</p>
<p>Samples may or may not be sent to their probe in chronological order (indeed, depending on their settings, probes may write directly their data to disk, yet timestamping them allows their renderer to reorder them if needed).</p>
<p>An example of the output rendering is:</p>
<p><span class="raw-html"><center><img src="Generic_probe_example.png" id="responsive-image-intermediate"></img></center></span>
</p>
<p>The generic probe is defined in <tt class="docutils literal">class_Probe.erl</tt>, and tested in <tt class="docutils literal">probe_rendering_test.erl</tt> (unit rendering test) and <tt class="docutils literal">class_Probe_test.erl</tt> (integration test).</p>
<p>By default:</p>
<ul class="simple">
<li>a probe will create a command file only when requested to generate a report (i.e. not when itself being created, in order to be able to take into account any later change in the curve declarations and rendering options before rendering is requested)</li>
<li>the sample data that it will receive will be written to disk on-the-fly (i.e. it will <em>not</em> be cached in memory, in order to minimise the memory footprint of the probes)</li>
</ul>
<p>Both behaviours can be changed, thanks to construction-time options (see, respectively, the <tt class="docutils literal">create_command_file_initially</tt> and <tt class="docutils literal">deferred_data_writes</tt> options).</p>
<p>As shown in the probe test, new curves can be dynamically declared, so that samples of increasing sizes can be sent over time (in the example, the fourth curve, the purple one, is dynamically added). The corresponding curves will be appropriately rendered the next time a report generation is requested. Existing curves can be renamed as well on-the-fly.</p>
<p>Full time-steps can be skipped, i.e. a new sample might be associated to a tick more than one tick after the previous one, and curve rendering will respect that time lapse (in the example, no sample at all was sent for ticks #4 and #9).</p>
<p>Partial samples can be sent as well, when no data is available for a given curve at a given tick (in the example, the second curve, the green one, had no relevant data for tick #3).</p>
<p>Finally, probes can also support the generation of histograms like this one:</p>
<p><span class="raw-html"><center><img src="xkcd-11th_grade.png" id="responsive-image-reduced"></img></center></span>
</p>
</div>
<div class="section" id="specialised-probes">
<h3>Specialised Probes</h3>
<div class="section" id="id79">
<span id="reliability-probes"></span><span id="reliability-probe"></span><h4>Reliability Probes</h4>
<p>Once associated with an equipment, a reliability probe, still based on a time series, records at each simulation tick the status of this equipment (functional or in failure), and can generate the chronology of status changes as shown here:</p>
<p><span class="raw-html"><center><img src="Reliability_probe_example.png" id="responsive-image-medium"></img></center></span>
</p>
<p>The reliability probe is defined in <tt class="docutils literal">class_ReliabilityProbe.hrl</tt>, and tested in <tt class="docutils literal">class_ReliabilityProbe.erl</tt>.</p>
</div>
</div>
<div class="section" id="probe-troubleshooting">
<h3>Probe Troubleshooting</h3>
<p>Here are some general troubleshooting hints about probes, when they seem to fail to produce their expected graph renderings.</p>
<p>First, no error nor warning should be output in the terminal or in the simulation traces; otherwise the user code must be fixed accordingly. It can happen for example when no data at all was sent to a probe, whereas it was requested to generate a report.</p>
<p>For each probe that was created, fed with data <em>and</em> requested to be output, a report (a graphical view of its data) should be made available to the user.</p>
<p>By default, a basic probe will perform immediate (non-deferred) writes: otherwise it would have to keep its sample in-memory, potentially exhausting the RAM if the simulation was long enough.</p>
<p>As a consequence, by default, each probe uses one opened file descriptor. This limits by default the maximum number of simultaneously existing basic probes per computing node to roughly one thousand on most systems; having too many of such probes created results in the <tt class="docutils literal">emfile</tt> error being reported - possibly as soon as probe creation, when each of them is to check that its prerequisites are met (typically regarding the gnuplot version available locally).</p>
<p>As this limit is just a <a class="reference external" href="https://linuxcommand.org/lc3_man_pages/ulimith.html">shell setting</a>, this can be overcome; for example <tt class="docutils literal">ulimit <span class="pre">-n</span> 20000</tt> will raise the maximum number of open file descriptors from the usual default <tt class="docutils literal">1024</tt> to <tt class="docutils literal">20000</tt>, which is likely to be sufficient for most simulations.</p>
<p>This is nevertheless a transient setting that will be reset at each new shell. This limit is not raised automatically by Sim-Diasca at start-up, as on most systems this would require root privileges - at least, in terms of file descriptor count, above some threshold. For example <tt class="docutils literal">ulimit <span class="pre">-n</span> 2000</tt> may be accepted, whereas <tt class="docutils literal">ulimit <span class="pre">-n</span> 20000</tt> may not, returning then:</p>
<pre class="literal-block">
ulimit: open files: cannot modify limit: Operation not permitted
</pre>
<p>A more permanent solution (requiring root privileges) is to use <tt class="docutils literal">nofile</tt> entries in <tt class="docutils literal">/etc/security/limits.conf</tt>. For example one may add following entries to the end of this file (or edit them if already existing):</p>
<pre class="literal-block">
root soft  nofile 20000
root hard  nofile 40000
</pre>
<p>As larger numbers of probes are unlikely to generate diagrams that will be actually viewed, just generating and storing the corresponding data samples (no image being then produced) might suffice, in which case the result specifications (as declared in the simulation case) may opt for the <tt class="docutils literal">data_only</tt> producer option (rather than <tt class="docutils literal">rendering_only</tt> or <tt class="docutils literal">data_and_rendering</tt>; refer to <tt class="docutils literal">class_ResultProducer:producer_option/0</tt>).</p>
<p>An even safer option (scalability-wise) is, if relevant, to also tell directly to the probes themselves that no rendering is to be prepared (see the <tt class="docutils literal">rendering_enabled</tt> field of the <tt class="docutils literal">probe_options</tt> record for that).</p>
<div class="section" id="probe-report-generation-issues">
<h4>Probe Report Generation Issues</h4>
<p>You must first check that you sent at least one data sample to your probe, and then that it is included in the result specification.</p>
<p>If, when the generation takes place, a warning about <tt class="docutils literal">bmargin</tt> is issued, then you must be using a <em>very</em> old version of <tt class="docutils literal">gnuplot</tt> (ex: 4.0).</p>
<p>In this case you can either:</p>
<ul class="simple">
<li>update your <tt class="docutils literal">gnuplot</tt> version</li>
<li>in <tt class="docutils literal"><span class="pre">sim-diasca/src/core/src/probe/class_Probe.erl</span></tt>, disable all key options: set the <tt class="docutils literal">key_options</tt> attribute to an empty string</li>
</ul>
<p>More generally, if a problems occurs, you should check first that the probe report (ex: <tt class="docutils literal">Test_probe.png</tt>) was indeed generated.</p>
<p>If yes, it must be a (minor) problem of the display tool, see the <a href="#id80"><span class="problematic" id="id81">``</span></a>Probe Report Display Issues``_ section.</p>
<p>If no, actually the PNG could not be generated. The next step is to check in your result directory that the data file (ex: <tt class="docutils literal">Test_probe.dat</tt>) and the command file (ex: <tt class="docutils literal">Test_probe.p</tt>) are correct, i.e. existing, not empty, and not corrupted.</p>
<p>If these files seem correct, you can just check that you can generate the lacking PNG by yourself, by issuing on the command line:</p>
<pre class="literal-block">
gnuplot Test_probe.dat
</pre>
<p>Depending on the outcome (the PNG is generated, or a <tt class="docutils literal">gnuplot</tt> error is raised), the diagnosis should be easy to determine. Please report to us if a problem remains.</p>
</div>
<div class="section" id="probe-report-display-issues">
<h4>Probe Report Display Issues</h4>
<p>Depending on the tool you use for image displaying, multiple graphs may be displayed in the same window: with the default one, <em>Geeqie</em> (<tt class="docutils literal">geeqie</tt>, previously known as <tt class="docutils literal">gqview</tt>), one window may pop up, listing all the graphical results.</p>
<p>If wanting to use another image viewer, you can just edit the <tt class="docutils literal">myriad/src/executable_utils.erl</tt> file, and update accordingly the <tt class="docutils literal">get_default_image_browser/1</tt> function.</p>
<p></p>
</div>
</div>
</div>
<div class="section" id="id82">
<span id="data-logger"></span><span id="datalogger"></span><h2><a class="toc-backref" href="#id209">Data-Logger</a></h2>
<p>The purpose of the data-logger is to store and manage simulation data in a more powerful and flexible way than with plain <a class="reference internal" href="#probes">probes</a>.</p>
<p>The data-logger allows any number of <em>virtual probes</em> to be created, and stores them in a distributed database. This allows queries to be done on these data, and outputs to be generated in a very similar way as when using plain probes.</p>
<p>This data service relies a lot on the <em>Mnesia</em> soft-realtime database, which is an Erlang built-in.</p>
<p>One of the objectives of the data-logger is also to allow for an increased scalability: whereas there is a hard limit to the number of co-existing plain probes on any given computing host <a class="footnote-reference" href="#id84" id="id83">[31]</a>, the underlying distributed tables of the data-logger allow to go one step further, scalability-wise.</p>
<table class="docutils footnote" frame="void" id="id84" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id83">[31]</a></td><td>Indeed, should probes keep their data in-memory only, their size would grow over simulation time until exhausting the system RAM. Therefore they store by default their data in a probe-specific file instead, but then the maximal number of per-process open file descriptors will kick in, and usually will limit the number of plain probes per simulation node to around one thousand, which may not be sufficient.</td></tr>
</tbody>
</table>
<p>Moreover some post-processing across tables can then be done more easily.</p>
<p>The data-logger is defined in the <tt class="docutils literal"><span class="pre">sim-diasca/src/core/src/data-management/data-storage</span></tt> directory.</p>
<p>When running for example the data-logger test (<tt class="docutils literal">datalogging_test.erl</tt>, thanks to <tt class="docutils literal">make datalogging_run</tt>), one can see:</p>
<p><span class="raw-html"><center><img src="datalogger-example.png" id="responsive-image-large"></img></center></span>
</p>
<p>In the stacking of windows, from the upper one to the lower one we can see:</p>
<ul class="simple">
<li>a rendering of a virtual probe</li>
<li>the list of all known virtual probes</li>
<li>the database table corresponding a virtual probe</li>
<li>a bit of the console tracking</li>
</ul>
<p></p>
</div>
<div class="section" id="id85">
<span id="console-tracker"></span><h2><a class="toc-backref" href="#id210">Console Tracker</a></h2>
<p>The <em>Console Tracker</em> is a lightweight Sim-Diasca built-in which displays live runtime information on a terminal, in order to allow the user to monitor concisely the progress of a running simulation.</p>
<p>A typical output is:</p>
<pre class="literal-block">
Simulation started at simulation time: 1/1/2000 0:00:00
(tick 3155695199999), real time: 4/12/2010 0:03:31
with a simulation frequency of 50.00 Hz (period of 20 ms).
Simulation will stop no later than tick 3155695260000
(i.e. after 60000 ticks).

Meaning of the console tracker columns:
- S: overall [S]imulation time (full time and date)
- T: overall simulation [T]ick
- R: [R]eal (wall-clock) time
- A: total (distributed) [A]ctor count (load balancer included)
- D: [D]etailed last-tick actor actions
(spontaneous/triggered/twofold counts)
- P: total (distributed) [P]rocess count
</pre>
<p>Then the tick table <a class="footnote-reference" href="#id87" id="id86">[32]</a>:</p>
<blockquote>
<table border="1" class="docutils">
<colgroup>
<col width="18%" />
<col width="13%" />
<col width="18%" />
<col width="12%" />
<col width="25%" />
<col width="13%" />
</colgroup>
<thead valign="bottom">
<tr><th class="head">Simulation Time</th>
<th class="head">Tick Offset</th>
<th class="head">Real Time</th>
<th class="head">Actor Count</th>
<th class="head">Detailed Actions</th>
<th class="head">Process Count</th>
</tr>
</thead>
<tbody valign="top">
<tr><td>S:       (not started)</td>
<td>T:             0</td>
<td>R:  3/12/2010  2:35:54</td>
<td>A:          0</td>
<td>D:        0|       0|       0</td>
<td>P:           64</td>
</tr>
<tr><td>S:   1/1/2000  0:00:00</td>
<td>T:             0</td>
<td>R:  3/12/2010  2:35:54</td>
<td>A:     900503</td>
<td>D:        0|       0|       0</td>
<td>P:           64</td>
</tr>
<tr><td>S:   1/1/2000  0:00:00</td>
<td>T:             1</td>
<td>R:  3/12/2010  2:35:55</td>
<td>A:     900503</td>
<td>D:   900503|       0|       0</td>
<td>P:       902626</td>
</tr>
<tr><td>S:   1/1/2000  0:00:00</td>
<td>T:             3</td>
<td>R:  3/12/2010  2:35:56</td>
<td>A:     900503</td>
<td>D:   900502|       0|       0</td>
<td>P:       902626</td>
</tr>
<tr><td>S:   1/1/2000  0:00:00</td>
<td>T:             6</td>
<td>R:  3/12/2010  2:35:57</td>
<td>A:     900503</td>
<td>D:   900502|       0|       0</td>
<td>P:       902626</td>
</tr>
<tr><td>S:   1/1/2000  0:00:00</td>
<td>T:             9</td>
<td>R:  3/12/2010  2:35:58</td>
<td>A:     900503</td>
<td>D:   900502|       0|       0</td>
<td>P:       902626</td>
</tr>
<tr><td>S:   1/1/2000  0:00:00</td>
<td>T:            12</td>
<td>R:  3/12/2010  2:35:59</td>
<td>A:     900503</td>
<td>D:   900502|       0|       0</td>
<td>P:       902626</td>
</tr>
<tr><td>S:   1/1/2000  0:20:00</td>
<td>T:         59998</td>
<td>R:  4/12/2010  9:39:00</td>
<td>A:     900503</td>
<td>D:   900502|       0|       0</td>
<td>P:       902626</td>
</tr>
<tr><td>S:   1/1/2000  0:20:00</td>
<td>T:         59999</td>
<td>R:  4/12/2010  9:39:00</td>
<td>A:     900503</td>
<td>D:   900502|       0|       0</td>
<td>P:       902626</td>
</tr>
</tbody>
</table>
</blockquote>
<table class="docutils footnote" frame="void" id="id87" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id86">[32]</a></td><td>The table has been pretty-printed and considerably shorten.</td></tr>
</tbody>
</table>
<p>Finally the simulation summary:</p>
<pre class="literal-block">
In batch mode, no browsing of results performed. Waiting for their
processing and retrieval.
Results are available now.
Simulation stopped at simulation time: 1/1/2000 0:20:00
(tick 3155695260000), real time: 3/12/2010 9:39:01, after a
duration of 20 minutes in simulation time (60000 ticks),
computed during a wall-clock duration of 7 hours, 3 minutes,
33 seconds and 22 milliseconds.
Simulation ran slower than the clock, with an acceleration factor
of x0.047.
</pre>
<p>The console tracker is notified of all ticks (and is given the corresponding information), but it selects for display only up to one tick information per second (the latest available), in order not to overwhelm the console and slow-down very fast simulations (thus, each line is a snapshot for a specific tick, not a cumulated value since the last output).</p>
<p>So a simulation run twice will probably display different ticks, thus different information, and this is normal.</p>
<p>One can change the console tracker behaviour so that all ticks are displayed. In this case the tick information from a simulation run twice should match. If it is not the case, there must be a bug, either in Sim-Diasca or in the models.</p>
<p>To switch from one console line per second to all lines being displayed, just edit, in <tt class="docutils literal"><span class="pre">sim-diasca/src/core/src/scheduling/class_TimeManager.erl</span></tt>, the <tt class="docutils literal">tick_tracker_main_loop/3</tt> function, apply the in-code comments (the ones starting with <tt class="docutils literal">(uncomment next line</tt>), and recompile this module.</p>
<p></p>
</div>
<div class="section" id="id88">
<span id="data-exchanger"></span><h2><a class="toc-backref" href="#id211">Data Exchanger</a></h2>
<p>The <em>Data Exchanger</em> is a distributed simulation service that allows to share conveniently and efficiently data among all actors, even if the data sets are large and the actors numerous.</p>
<div class="section" id="objectives">
<h3>Objectives</h3>
<p>More precisely, the data-exchanger fulfills two technical purposes:</p>
<ul class="simple">
<li>to allow for a more efficient, yet safe, sharing of data, based on an automatic distribution that allows all read requests (potentially very numerous) to be performed locally only (i.e. directly on the computing node on which each reading actor is running - thus with very low overhead)</li>
<li>to provide a way of propagating data conveniently and as quickly as possible in simulation time, latency-wise: an update made at tick T will be visible to all readers during the full T+1 tick, right from its start, and thus can then be accessed with zero-latency, through any number of direct reading messages per actor (without having to be synchronized thanks to actor messages that would be reordered and executed later); actor-wise, this allows to perform series of any number of (potentially conditional) read requests during the same tick, with potentially arbitrarily complex read patterns, at virtually no performance cost nor developing effort</li>
</ul>
<p>Each data that is shared according to following conventions:</p>
<ul class="simple">
<li>data is defined as key/value pairs, respectively an atom and any Erlang term</li>
<li>data can be <em>static</em>, i.e. be defined initially and thus be permanently available (ex: through the built-in support for reading from configuration files) and/or be introduced in the course of the simulation, i.e. be <em>dynamic</em></li>
<li>can be modified over time once defined (non-const, to be defined with the <tt class="docutils literal">mutable</tt> qualifier) or not (immutable, to be defined with the <tt class="docutils literal">const</tt> qualifier)</li>
</ul>
<p>Note that static/dynamic and mutable/const are orthogonal properties, all combinations of which making sense.</p>
<p>So, basically, compared to inter-actor messages, the data-exchanger offers an alternate, radically different paradigm to manage data, that can be seen as a DSM (i.e. a <em>Distributed Shared Memory</em>), somewhat a dual approach to the in-tick reordered actor messages. The point is that this service still allows to preserve simulation properties, and that the different trade-offs it offers may, depending on the situation, be more suitable for some needs of information sharings, notably in the <em>one writer/many readers</em> case.</p>
<p>These services had to be offered with care, as, for the model developer, unwanted side-effects or race conditions should not be made easier to perform, and for sure these sharing services must not become a means of bypassing the simulation mechanisms (ex: if instantaneous reads and writes were allowed, then the induced possible immediate inter-actor communication would break at least reproducibility).</p>
<p>Note that the only standard way of exchanging information and synchronising between actors (as opposed to the sharing of information) remains the sending of actor messages.</p>
</div>
<div class="section" id="sharing-constant-data">
<h3>Sharing Constant Data</h3>
<p>One of the notable use cases of the data exchange service is the sharing of simulation-specific configuration settings: then all actors can have access to the same static (<tt class="docutils literal">const</tt>) data sets, which will be available from the start, before the simulation is started, even before the first initial actor is created. It is then functionally equivalent to having each actor read these information from a common configuration file, except that the reading is done once for all actors on each node, instead of once per actor, avoiding the massive reading and parsing, etc. that would be incurred otherwise.</p>
<p><span class="raw-html"><center><img src="xkcd-x11.png" id="responsive-image-small"></img></center></span>
</p>
<p>These configuration files must respect the Erlang term syntax, with a <tt class="docutils literal">{Key,Value}</tt> pair or a <tt class="docutils literal">{Key,Value,Qualifier}</tt> triplet per logical line of the file, ending with a dot. <tt class="docutils literal">Qualifier</tt> is either <tt class="docutils literal">mutable</tt> or <tt class="docutils literal">const</tt>; not specifying a qualifier implies <tt class="docutils literal">const</tt> <a class="footnote-reference" href="#id90" id="id89">[33]</a></p>
<table class="docutils footnote" frame="void" id="id90" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id89">[33]</a></td><td>And modifying afterwards a (thus mutable) data without specifying a qualifier will make it <tt class="docutils literal">const</tt> then.</td></tr>
</tbody>
</table>
<p>Such configuration files are to be declared in the <tt class="docutils literal">enable_data_exchanger</tt> field of the deployment settings (see the detailed syntax in <tt class="docutils literal">class_DeploymentManager.hrl</tt>). They will be then automatically deployed <a class="footnote-reference" href="#id92" id="id91">[34]</a> and their corresponding data defined. As a convention, their recommended extension is <tt class="docutils literal">.cfg</tt> (ex: <tt class="docutils literal">my_simulation_parameters.cfg</tt>). See the <tt class="docutils literal">valid_example_configuration_file.cfg</tt> and <tt class="docutils literal">invalid_example_configuration_file.cfg</tt> as examples.</p>
<table class="docutils footnote" frame="void" id="id92" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id91">[34]</a></td><td>We preferred adding automatically these user-specified configuration files to the deployment archive and having them parsed once per computing node, rather than read only once and then be sent as messages over the network: for fairly large data-sets, we believe that being compressed in a data archive rather than being expanded as Erlang terms on the sender-side should result in better performances, network-wise.</td></tr>
</tbody>
</table>
<p>Of course the data-exchange distributed repository can also be fed at runtime, as opposed to statically (i.e. through configuration files). And this can be done initially (before the simulation is started), through method calls (see the <tt class="docutils literal"><span class="pre">define_initial_data/{1,2,3,4}</span></tt> static methods to define new data entries, and the <tt class="docutils literal"><span class="pre">modify_initial_data/{1,2,3,4}</span></tt> static methods to update them once defined) or  from an actor (see the <tt class="docutils literal"><span class="pre">class_Actor:define_data/{2,3,4}</span></tt> and <tt class="docutils literal"><span class="pre">class_Actor:modify_data/{2,3,4}</span></tt> counterparts helper functions), thus either initially as well, or in the course of the simulation.</p>
<p>For an actor to be able to use the data-exchange service, it must first update its state with the <tt class="docutils literal">class_Actor:enable_data_exchange/1</tt> helper function. See <tt class="docutils literal">class_DataExchangeTestActor.erl</tt> for a complete example. Note then that its subsequent reads (and commits) may happen whether the simulation is already running or not (the latter case applies to initial actors).</p>
<p>So, during any given tick, each actor can freely perform from the data exchanger immediate, direct (zero-latency, as not based on an actor message) read operations of any number of data-sets, and the developer can be confident that this will be done in the most convenient, safe and reliable, performance-efficient, scalable way.</p>
<p>Reciprocally, instead of being read, new data can be defined, or existing data can be modified, provided of course it was declared as non-const (i.e. with the <tt class="docutils literal">mutable</tt> qualifier), as discussed in the next section.</p>
</div>
<div class="section" id="modifying-data">
<h3>Modifying Data</h3>
<p>Any already-defined data, whose current qualifier is <tt class="docutils literal">mutable</tt>, can be modified, either initially (in this case the change will be immediate) or in the course of the simulation (in this case the change will occur only starting from the next tick).</p>
<p>This is done thanks to calls to the <tt class="docutils literal"><span class="pre">modify_data/{3,4,5}</span></tt> helper functions, which on each tick are synchronous operations resulting in the root data exchanger recording all commits that happen during the current tick, and checking them on the fly (ex: no change in <cite>const</cite> data, only up to one commit per data key per tick, etc.). A <tt class="docutils literal">commit</tt> request is implemented as a direct message sending, from an actor to the root data exchanger (thus not going through the data-exchange tree).</p>
<p>Once this tick is over, should at least one commit have been requested, the root time manager notifies the root data exchanger that we are in-between two ticks and that it can thus propagate safely its commit(s), down the exchanger hierarchy (tree-based propagation).</p>
<p>Once done (i.e. fully acknowledged by a reverse, leaves-to-root, traversal), the root exchanger notifies the root time manager that the next scheduled tick can be triggered.</p>
<p>That way, at the expense of a minimal (and conditional <a class="footnote-reference" href="#id95" id="id93">[35]</a>) inter-tick wall-clock latency <a class="footnote-reference" href="#id96" id="id94">[36]</a>, all subsequent <strong>readings</strong> then done can be performed locally (on an exact local clone of the root exchanger) and instantly (with a zero-tick latency in virtual time): indeed, during a tick, from the point of view of actors, no data can change; their update will happen only in-between ticks, so all reads can be done</p>
<table class="docutils footnote" frame="void" id="id95" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id93">[35]</a></td><td>If no commit is done during a tick, the data-exchanger will incur virtually no overhead, so this data-exchange service will cost resources <em>only</em> if used.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id96" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id94">[36]</a></td><td>For synchronisation reasons, the commit propagation has to be part of the critical path of the time manager (the period between two ticks during which no parallel operation can occur). As increasing too much that duration would directly impact the simulation overall performances, we did our best to minimise the inter-tick latency induced by the data-exchange service. For example most checkings are not once a write operation is requested, not later once it is to be actually committed.</td></tr>
</tbody>
</table>
<p>Note also that setting a data involves either defining a new key or modifying a value associated to an already-defined key, possibly also updating the qualifier of a key/value pair, provided these operations are licit (ex: a <tt class="docutils literal">mutable</tt> qualifier may be set to <tt class="docutils literal">const</tt>, not the other way round; a data can be defined only once, and modified any number of times once first defined).</p>
<p>More precisely, data <strong>modification</strong>, during the simulation, is to be done from actors, and is either:</p>
<ul class="simple">
<li>defining new data, with <tt class="docutils literal"><span class="pre">class_Actor:define_data/{2,3,4}</span></tt></li>
<li>or modifying pre-existing data, with <tt class="docutils literal"><span class="pre">class_Actor:modify_data/{2,3,4}</span></tt></li>
</ul>
<p>The point is that, once the simulation is started:</p>
<ul class="simple">
<li>a modification done at tick T will be visible (thanks to read operations) only at the next scheduled tick (ex: T+1)</li>
<li>a given data (i.e. a value associated to a key), provided it was declared as <tt class="docutils literal">mutable</tt>, can be modified during the simulation up to once per tick, otherwise the data exchanger will detect the mismatch (commit inconsistency, up to one writer per key and per tick) and crash on purpose the simulation with a relevant exception</li>
</ul>
<p>So if the data exchanger holds at tick T a <tt class="docutils literal">{my_data,AnyTerm}</tt> mutable entry, and if during this tick an actor commits a <tt class="docutils literal">{my_data,AnotherTerm}</tt> entry, then during T all read requests of <tt class="docutils literal">my_data</tt> will return <tt class="docutils literal">AnyTerm</tt>, and during T+1 they will all return <tt class="docutils literal">AnotherTerm</tt>. If more than one actor attempts to commit at T a change to <tt class="docutils literal">my_data</tt>, then the simulation will fail. Even if they try to commit the exactly the same value.</p>
</div>
<div class="section" id="practical-use">
<h3>Practical Use</h3>
<p>The data-exchange service is activated by default, as its runtime overhead in case it is not actually used is fairly low.</p>
<p>It can be explicitly enabled or disabled through the deployment settings, see the <tt class="docutils literal">enable_data_exchanger</tt> field of the <tt class="docutils literal">deployment_settings</tt> record, defined in <tt class="docutils literal">class_DeploymentManager.hrl</tt>. It is also the place where the list of configuration files to be used for static information (if any) can be specified.</p>
<p>Data can be defined, then modified and/or read.</p>
<p>When a data is to be read, only its key is to be specified.</p>
<p>When a data entry (key and at least value) is specified either for definition or for modification, if no qualifier is specified, then the default one (<tt class="docutils literal">const</tt>) will be implied. This means that requesting a modification with a data entry <tt class="docutils literal">{my_data,AnyTerm</tt>}`` implies notably that:</p>
<ul class="simple">
<li><tt class="docutils literal">my_data</tt> has already been defined</li>
<li>its previous qualifier was <tt class="docutils literal">mutable</tt> (thus was explicitly set as such), otherwise the modification would be bound to fail</li>
<li>its new qualifier will be <tt class="docutils literal">const</tt> (none was specified in the modification request), thus no further modification will be done on that data</li>
</ul>
<p>These data operations can be made either from the simulation case (thus, before the simulation is started) and/or from actors (before or during the simulation).</p>
</div>
<div class="section" id="implementation-details">
<h3>Implementation Details</h3>
<p>There is one data exchanger agent per computing node, and they form a tree (the exchanger hierarchy), whose root is the root data-exchanger, very much like the one of time managers.</p>
<p>That way commit consistency is verified by the root data exchanger, which holds the sole reference copy of the data repository, which is replicated on all non-root (i.e. local) data exchangers. As updates are made between ticks, during a tick the data is stable, and each actor will be able to read them locally, and at will.</p>
<p>Data definitions and modifications will be recorded during a tick, and applied once that tick is over, before the next scheduled one.</p>
<p>Data can also be defined and modified before the simulation is started. Definitions can be done through requests or through the reading of any number of configuration files.</p>
<p>For actors, data readings are just plain, direct, non-reordered, WOOPER requests that are made locally (on the node of the reading actor), thanks to the local exchanger that was automatically deployed there. Therefore readings should be considered as being by design fast and inexpensive.</p>
<p>From the simulation case, the readings are managed a bit differently internally, depending on whether the user host is included or not in the simulation.</p>
<p>If included, then on that same user host there is a computing node with its own local data-exchanger. As a consequence, to avoid a data duplication of the exchange repository on the user host, the user node will interact with the data-exchanger local to the computing node on the same host.</p>
<p>If the user node is not included in the simulation, then there is not computing host to rely upon, and a local data-exchanger dedicated to the user node is simply created and integrated in the data-exchange hierarchy.</p>
</div>
</div>
<div class="section" id="spatialised-support">
<h2><a class="toc-backref" href="#id212">Spatialised Support</a></h2>
<div class="section" id="overview">
<h3>Overview</h3>
<p>Currently only a support for 2D environments is provided - of course the user might define any number of other environments if wanted.</p>
<p>The spatial environment is embodied by an instance (a singleton) of <tt class="docutils literal">class_TwoDimensionalEnvironment</tt>.</p>
<p>The support for low-level spatial computations is provided by the <tt class="docutils literal">linear_2D</tt> module (in <tt class="docutils literal">myriad/src/maths</tt>).</p>
<p>Distances are expressed in meters, speeds in meters per second.</p>
<p>The simulated world has an origin (<tt class="docutils literal">{0.0,0.0}</tt>) and spreads in both dimensions. Cartesian coordinates are used.</p>
<p>By default the world is a torus, i.e. the coordinates wrap around. They range from the origin to <tt class="docutils literal">{XMax,YMax}</tt>.</p>
</div>
<div class="section" id="spatialised-elements">
<h3>Spatialised Elements</h3>
<p>A simulation element that is  <em>spatialized</em> has a position in the simulation world, and should be (directly or not) an instance of <tt class="docutils literal">class_SpatializedEntity</tt> or, more precisely here, a <tt class="docutils literal">class_TwoDimensionalSpatializedActor</tt>.</p>
<p>The constructors of each of these classes take, as first actual parameter, the PID of the environment. An upper bound of the speed of each instance may be specified (it allows to optimise the mode of operation of the environment).</p>
<p>This <tt class="docutils literal">class_TwoDimensionalSpatializedActor</tt> class defines an attribute <tt class="docutils literal">position</tt> whose type is <tt class="docutils literal">linear_2D:point()</tt> and a <tt class="docutils literal"><span class="pre">-spec</span> <span class="pre">getPosition(wooper_state(),pid())</span></tt> actor oneway which triggers back on the caller, at the next diasca, the <tt class="docutils literal"><span class="pre">-spec</span> <span class="pre">notifyPosition(wooper_state(),linear_2D:point(),pid())</span></tt> actor oneway.</p>
</div>
<div class="section" id="interaction-with-the-environment">
<h3>Interaction with the Environment</h3>
<p>In the general case, no instance is able to know the whole simulation world. An instance is only able to perceive a subset of it, through its perception.</p>
<p>Such a neighborhood can only be obtained thanks to a specific actor, the environment.</p>
<p>An instance can indeed call the actor oneway defined, here in <tt class="docutils literal">class_TwoDimensionalEnvironment</tt>, as <tt class="docutils literal"><span class="pre">-spec</span> <span class="pre">getEntitiesWithin(point(),radius(),pid())</span></tt>: it requests that the entities within a disc whose center and radius are specified are determined by the environment.</p>
<p>This center of perception must be by convention the current location of the perceiving instance, as:</p>
<ul class="simple">
<li>a given instance should only perceive its own neighborhood</li>
<li>the environment will take advantage of this call to update its knowledge of the location of the perceiver</li>
</ul>
<p></p>
</div>
</div>
</div>
<div class="section" id="sim-diasca-helper-tools">
<h1><a class="toc-backref" href="#id213">Sim-Diasca Helper Tools</a></h1>
<p id="helper-tools"><span id="tools"></span>These tools are not strictly necessary to the mode of operation of the engine, however they provide some features that are very useful in some contexts.</p>
<p><span class="raw-html"><center><img src="xkcd-the_general_problem.png" id="responsive-image-medium"></img></center></span>
</p>
<p>As a consequence, on a vanilla Sim-Diasca version, they start disabled (so that they induce no resource overhead), but their sources are in the main codebase, they are always built and readily available - as soon as the user chooses to activate them.</p>
<div class="section" id="performance-tracker">
<h2><a class="toc-backref" href="#id214">Performance Tracker</a></h2>
<p>The <em>Performance Tracker</em> is a fully optional mechanism that allows the user to monitor a simulation that was run, in order to profile it.</p>
<p>It aims to monitor and then generate reports giving detailed information about all kinds of technical measurements dealing with performances, notably in terms of resource consumption (CPU, RAM, network, Erlang process count, etc.).</p>
<div class="section" id="requirements-functional-coverage">
<h3>Requirements &amp; Functional Coverage</h3>
<p>The current version provides the following features:</p>
<ul class="simple">
<li>trace the following memory consumptions on the user node and on computing nodes along with the simulation duration or with the wall-clock time:<ul>
<li>the available memory (which is: free memory + buffers + cache)</li>
<li>the memory used by the other applications (i.e. all non-Erlang applications)</li>
<li>the memory allocated to the Erlang emulator (i.e. the memory currently used by the simulator), plus any other Erlang program being executed at the same time</li>
<li>the used swap</li>
</ul>
</li>
<li>trace the overall number of Erlang processes (on a per-node basis) during the simulation in real (wall-clock) time and/or in simulation time (tick)</li>
</ul>
<p>In the future, it will allow to trace also:</p>
<ul class="simple">
<li>overall number of instances of a given class; for example: how many classical or virtual probes, or <tt class="docutils literal">class_Foobar</tt> instances on each node</li>
<li>the wall-clock duration of each simulation tick, on each node</li>
</ul>
<p>The output of the performance tracker is:</p>
<ul class="simple">
<li>time series (<tt class="docutils literal">.dat</tt> files)</li>
<li>and/or the corresponding graphs (<tt class="docutils literal">.png</tt>)</li>
</ul>
<p>Its reports are available post-mortem (not live), among the simulation results.</p>
</div>
<div class="section" id="id97">
<h3>Implementation</h3>
<p>The performance tracker and its integration test are located in <tt class="docutils literal"><span class="pre">sim-diasca/src/core/src/data-management/monitoring/performance</span></tt>.</p>
<p>The performance tracker is integrated at the Sim-Diasca level (i.e. not only at the WOOPER-level), and relies on various services of the engine (ex: probe, deployment manager, result manager).</p>
<p>The performance tracker is implemented as an optional service, disabled by default (to avoid any unnecessary runtime overhead), which can be enabled on a per-need basis.</p>
<p>It defines following classical probes:</p>
<ul class="simple">
<li>a global probe is created in order to track the overall number of Erlang processes on each node: it includes as many curves as there are nodes (user node and computing nodes); each curve is named according to its corresponding node</li>
<li>a probe per node is also created in order to track the resource consumptions on each node</li>
</ul>
<p>In terms of architecture, currently the performance tracker is centralized (a singleton) and is created on the same node with the Depployment Manager in order to enable the performance information available in all circumstances, such as, simulation fail because of a timeout or a computing node crash.</p>
<p>In case of performance tracker enabled, the data for the probes is retrieved in a predefined interval during simulation, by default, this interval is defined as 100ms and it can be modified by sending a &quot;setTickerPeriod&quot; message with new interval to the performance tracker.</p>
<p>In the future and in particular for the scalability test when numerous computing nodes are engaged, there will be a performance monitor per node besides this centralized tracker, in order to reduce the exchanges over the network. Contrariwise, the distributed monitoring way can lead to lose some node performance information when a node is crashed during the simulation and relevant data saved on it.</p>
</div>
<div class="section" id="performance-tracker-activation-and-creation">
<h3>Performance Tracker Activation and Creation</h3>
<p>The activation of the performance tracker is to be requested from the simulation case, through its deployment settings: the <tt class="docutils literal">enable_performance_tracker</tt> field of the <tt class="docutils literal">DeploymentSettings</tt> record (defined in <tt class="docutils literal">class_DeploymentManager.hrl</tt>) must be set to true.</p>
<p>When the performance tracker is enabled, the user can customise it according to her needs, notably in order to set the wall-clock period, expressed in milliseconds, between two measures (performance tracker samples); see its <tt class="docutils literal">setTickerPeriod/2</tt> method.</p>
<p>To do so, the PID of the tracker must be obtained, thanks to the following static method:</p>
<pre class="code erlang literal-block">
<span class="nv">MyPerformanceTrackerPid</span> <span class="o">=</span> <span class="nn">class_PerformanceTracker</span><span class="p">:</span><span class="nf">get_tracker</span><span class="p">()</span>
</pre>
</div>
<div class="section" id="performance-tracker-report-example">
<h3>Performance Tracker Report Example</h3>
<div class="section" id="example-1-a-single-host-simulation">
<h4>Example 1: a single-host simulation</h4>
<p>These reports are generated based on the results of the performance tracker test (<tt class="docutils literal">class_Performance_Tracker_test.erl</tt>) with following test configuration:</p>
<ul class="simple">
<li>only one initial test actor (<tt class="docutils literal">class_PerformanceTracker_TestActor</tt>)</li>
<li>each test actor creates a new test actor every 4 simulation tick</li>
<li>the total simulation duration is 36 simulation ticks</li>
<li>the simulation runs on only one machine, that means: the user node and the computing node are on the same machine</li>
</ul>
<p></p>
<p>One can have a global view of the simulation, first in <em>wall-clock</em> time:</p>
<p><span class="raw-html"><center><img src="example1_process_tracker_in_wall_clock_time.png" id="responsive-image-full"></img></center></span>
</p>
<p>The same global view can also be shown in <em>simulation</em> time:</p>
<p><span class="raw-html"><center><img src="example1_process_tracker_on_simulation_time.png" id="responsive-image-full"></img></center></span>
</p>
<p>More detailed information can be collected, on a per node basis. Here first is the report specific to the <em>user</em> node, in wall-clock time, then the same report for a <em>computing</em> node:</p>
<p><span class="raw-html"><center><img src="example1_memory_tracker_on_user_node.png" id="responsive-image-full"></img></center></span>
</p>
<p><span class="raw-html"><center><img src="example1_memory_tracker_on_computing_node.png" id="responsive-image-full"></img></center></span>
</p>
</div>
<div class="section" id="example-2-a-simulation-distributed-over-4-nodes">
<h4>Example 2: a simulation distributed over 4 nodes</h4>
<p>These reports are generated based on the results of the performance tracker test (<tt class="docutils literal">class_Performance_Tracker_test.erl</tt>) with following test configuration:</p>
<ul class="simple">
<li>only one initial test actor (<tt class="docutils literal">class_PerformanceTracker_TestActor</tt>)</li>
<li>each test actor creates a new test actor every 4 simulation tick</li>
<li>the total simulation duration is 36 simulation ticks</li>
<li>the simulation runs on 4 machines, that means:  the user node and one computing node are on one machine, the three other computing nodes are on three different machines</li>
</ul>
<p></p>
<p>One can have a global view of the simulation, first in <em>wall-clock</em> time:</p>
<p><span class="raw-html"><center><img src="example_process_tracker_in_wall_clock_time.png" id="responsive-image-full"></img></center></span>
</p>
<p>The same global view can also be shown in <em>simulation</em> time:</p>
<p><span class="raw-html"><center><img src="example_process_tracker_on_simulation_time.png" id="responsive-image-full"></img></center></span>
</p>
<p>More detailed memory consumption information can be collected. Here first is the report specific to the <em>user</em> node, in wall-clock time, then the same report for  <em>computing</em> nodes:</p>
<p><span class="raw-html"><center><img src="example_memory_tracker_on_user_node.png" id="responsive-image-full"></img></center></span>
</p>
<p><span class="raw-html"><center><img src="example_memory_tracker_on_computing_node_1.png" id="responsive-image-full"></img></center></span>
</p>
</div>
</div>
</div>
<div class="section" id="post-processing-services">
<h2><a class="toc-backref" href="#id215">Post-Processing Services</a></h2>
<p>As hinted by their name, these services are not integrated to the engine, but are to be applied, if needed, to the results it produces.</p>
<div class="section" id="time-series-analyzer">
<h3>Time-Series Analyzer</h3>
<p>Time-series are typically produced by simulation probes (either basic or virtual), and are stored in <tt class="docutils literal">*.dat</tt> files, which gathers the values of a series of curves at different ticks.</p>
<p>Such files can be inputs to the Sim-Diasca analyzer tool for time series, which can then apply them various algorithms, some related to signal processings.</p>
<p>For a time-series file, identified processings of interest are:</p>
<ul class="simple">
<li>select a subset of curves in a time-series file</li>
<li>remove empty ones and/or constant ones</li>
<li>generate a basic <tt class="docutils literal">gnuplot</tt> command file corresponding to a <tt class="docutils literal">.dat</tt> file</li>
</ul>
<p>For a curve,  identified processings of interest are:</p>
<ul class="simple">
<li>find the extrema (minimum and maximum values), and when they occur (list of matching ticks)</li>
<li>compute the average value of the curve (which is not necessarily the average of the values, due to potentially non-consecutive ticks)</li>
<li>apply a convolution filter on the curve samples</li>
<li>compute the curve for the moving average (a specific case of convolution), which is a way of obtaining a smoother curve, making its interpretation easier by highlighting trends</li>
<li>perform a linear interpolation between samples</li>
<li>perform decimation, to reduce the number of samples</li>
<li>change scale (ex: switch to logarithmic, reshape to fit into a <tt class="docutils literal"><span class="pre">0..1</span></tt> interval, etc.)</li>
</ul>
<p><span class="raw-html"><center><img src="xkcd-log_scale.png" id="responsive-image-medium"></img></center></span>
</p>
</div>
</div>
<div class="section" id="plugin-infrastructure">
<h2><a class="toc-backref" href="#id216">Plugin Infrastructure</a></h2>
<p>Sim-Diasca offers a full <em>Plugin Management System</em>, which allows third-party code to interface with the engine in various ways.</p>
<div class="section" id="id98">
<h3>General Principles</h3>
<p>Each plugin is able to:</p>
<ul class="simple">
<li>specify requests for configuration changes (ex: like the number of sequencers on each computing node)</li>
<li>know runtime information, like the list of the computing nodes that have been actually elected by the engine</li>
<li>be notified of all main events (engine-related or even case-defined) regarding the simulation, which for example allows tools to monitor resources during only some phases of the simulation - typically when models are effectively evaluated (skipping deployment, preparation, initialisation phases, as well as the ones after the simulation)</li>
</ul>
</div>
<div class="section" id="more-in-depth-description">
<h3>More In-Depth Description</h3>
<p>A simulation case can specify a list of directories that will be scanned for plugins at start-up by the engine.</p>
<p>This is done thanks to the <tt class="docutils literal">plugin_directories</tt> field of the <tt class="docutils literal">deployment_settings</tt> record, which can be set to a list of directory paths (either absolute or relative to the directory where the case was launched). See <tt class="docutils literal">city_benchmarking_test.erl</tt> (in <tt class="docutils literal"><span class="pre">mock-simulators/city-example/src</span></tt>) for such an example case.</p>
<p>Each BEAM file found in any of these directories is expected to comply with the interface described in the <tt class="docutils literal">sim_diasca_plugin</tt> behaviour <a class="footnote-reference" href="#id100" id="id99">[37]</a> ).</p>
<table class="docutils footnote" frame="void" id="id100" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id99">[37]</a></td><td>This is a post-R15B, Dialyzer-friendly, behaviour. It is defined in <tt class="docutils literal"><span class="pre">sim-diasca/src/core/src/plugins/sim_diasca_plugin.erl</span></tt>.</td></tr>
</tbody>
</table>
<p>This boils down to implementing a callback for all simulation events:</p>
<ul class="simple">
<li><tt class="docutils literal">on_simulator_start</tt>: when the simulator is started (or almost, as basic services, including the trace one, are already up)</li>
<li><tt class="docutils literal">on_deployment_start</tt>: when the deployment phase starts</li>
<li><tt class="docutils literal">on_deployment_stop</tt>: when the deployment phase stops</li>
<li><tt class="docutils literal">on_technical_settings_available</tt>: when the simulation technical settings are available, notably once the deployment phase is over</li>
<li><tt class="docutils literal">on_case_initialisation_start</tt>: when the simulation case starts the creation of the initial state of the simulation</li>
<li><tt class="docutils literal">on_case_initialisation_stop</tt>: when the simulation case finished the creation of the initial state of the simulation</li>
<li><tt class="docutils literal">on_simulation_start</tt>: when the simulation is started (first tick, first diasca)</li>
<li><tt class="docutils literal">on_simulation_bootstrap_start</tt>: when the simulation is just started and must evaluate the first diasca of all initial actors</li>
<li><tt class="docutils literal">on_simulation_bootstrap_stop</tt>: when the evaluation of the first diasca of all initial actors is over</li>
<li><tt class="docutils literal">on_simulation_wallclock_milestone_met</tt>: when a wallclock milestone is met (i.e. when a given duration in real time elapsed)</li>
<li><tt class="docutils literal">on_simulation_tick_milestone_met</tt>: when a tick milestone is met (i.e. when a given number of ticks have been evaluated)</li>
<li><tt class="docutils literal">on_simulation_stop</tt>: when the simulation is stopped (an ending criterion was just met; only called on successful ending)</li>
<li><tt class="docutils literal">on_result_gathering_start</tt>: when the results start being gathered, after simulation termination</li>
<li><tt class="docutils literal">on_result_gathering_stop</tt>: when the results have been gathered</li>
<li><tt class="docutils literal">on_simulator_stop</tt>: when the simulator execution stopped under normal circumstances (i.e. not crashing)</li>
<li><tt class="docutils literal">on_case_specific_event</tt>: triggered iff a case decided to notify the plugins of a specific event</li>
</ul>
<p>Most callbacks just take one parameters, the current plugin state, and return one value, the new plugin state.</p>
<p>This allows stateful plugins to be easily implemented (instead of, for example, spawning a dedicated and registering it), the engine keeping track of their state between callbacks. Of course using that feature is optional and, for example, all callbacks can ignore the engine-specified state and only return the <tt class="docutils literal">undefined</tt> atom as new state.</p>
<p>Some callbacks are a little more complex:</p>
<ul class="simple">
<li><tt class="docutils literal">on_simulator_start/2</tt> is given also the current configuration changes (as possibly already updated by other plugins - the first of them receiving a blank <tt class="docutils literal">configuration_changes</tt> record), so that the currently executed plugin can update it</li>
<li><tt class="docutils literal">on_technical_settings_available/2</tt> is given also a <tt class="docutils literal">technical_settings/2</tt> record, describing the actual settings then enforced by the engine, notably on the basis of the previously consolidated plugin configuration requests</li>
<li><tt class="docutils literal">on_simulation_wallclock_milestone_met/2</tt> and <tt class="docutils literal">on_simulation_tick_milestone_met</tt> are respectively also given the current simulation timestamp (respectively in real and virtual time), whenever a milestone is met</li>
<li><tt class="docutils literal">on_case_specific_event/3</tt> is given the name of the corresponding case-specific event (as an atom) and its associated data; see <tt class="docutils literal">class_CityGenerator.erl</tt> for an example of use</li>
</ul>
</div>
<div class="section" id="implementation-notes">
<h3>Implementation Notes</h3>
<p>All services of the lower layers are available to plugins. As a result, they can rely upon the facilities of the Myriad layer, WOOPER classes may be used as plugins, and the distributed trace system can be used by the plugins as well.</p>
<p>The plugin service is mostly located in <tt class="docutils literal"><span class="pre">sim-diasca/src/core/src/plugins</span></tt>.</p>
<p>An example of a full, complete plugin is available in <tt class="docutils literal">plugins/tests/my_plugin_example.erl</tt>.</p>
<p>We might consider supporting even <em>distributed</em> plugins (with one instance of them, code and data, being deployed and run on each computing node), if such use case was found interesting.</p>
<p></p>
</div>
</div>
</div>
<div class="section" id="sim-diasca-modelling-guide">
<h1><a class="toc-backref" href="#id217">Sim-Diasca Modelling Guide</a></h1>
<div class="section" id="objective-context">
<h2><a class="toc-backref" href="#id218">Objective &amp; Context</a></h2>
<p>The goal here is to help bridging the gap between the modelling world and the simulation world: in this section we discuss what is the &quot;language&quot; that the simulation engine natively understands, so that a modelling team is able to prepare descriptions of models that can be almost readily implemented into actual (runnable) simulation models.</p>
</div>
<div class="section" id="basics-of-simulation-operation-mode">
<h2><a class="toc-backref" href="#id219">Basics Of Simulation Operation Mode</a></h2>
<div class="section" id="actors-models">
<h3>Actors &amp; Models</h3>
<div class="section" id="actor">
<h4>Actor</h4>
<p>A simulation actor is the basic building block of a simulation. It is an autonomous agent, usually corresponding to an element of the simulated system, which, during the course of the simulation, will be automatically and appropriately scheduled.</p>
<p>Being scheduled means being given the opportunity to act, either spontaneously and/or after having been triggered by another actor.</p>
<p>Each actor has a private state, which is made of a set of any number of attributes.</p>
<p>An attribute has a name and a value, which can be of any data type, usually made of an arbitrarily-complex combination of primitive types (integer, logical text constant <a class="footnote-reference" href="#id103" id="id101">[38]</a>, floating-point value, etc.) and structures (fixed-size array <a class="footnote-reference" href="#id104" id="id102">[39]</a>, list, tree, associative table, etc.).</p>
<table class="docutils footnote" frame="void" id="id103" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id101">[38]</a></td><td>Named <tt class="docutils literal">atom</tt> in Erlang.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id104" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id102">[39]</a></td><td>Named <tt class="docutils literal">tuple</tt> in most declarative languages, including Erlang.</td></tr>
</tbody>
</table>
<p>For an actor, acting corresponds mostly to:</p>
<ul class="simple">
<li>changing its private state (ex: changing the value of an attribute)</li>
<li>sending messages to other actors (ex: to notify them that some event occurred)</li>
<li>possibly, triggering side-effects (ex: sending a message to the distributed trace system)</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Please refer to the Sim-Diasca Developer Guide for more implementation-level information about actors.</p>
</div>
</div>
<div class="section" id="model">
<h4>Model</h4>
<p>A model corresponds to the description of a type of simulation actors, regarding state and behaviour.</p>
<p>Technically a model is actually a specific class, whose instances are the simulation actors that respect that model.</p>
</div>
<div class="section" id="expressivity">
<h4>Expressivity</h4>
<p><span class="raw-html"><center><img src="xkcd-candy_button_paper.png" id="responsive-image-intermediate"></img></center></span>
</p>
<p>Of course, Turing machines can be simulated, but more generally very few restrictions apply to models, which can be arbitrarily complex.</p>
<p>The most difficult issue to deal with comes probably from the latency (in virtual time) which is induced by the simulation mechanisms: an information (i.e. an actor message) sent at tick T cannot be processed by its recipient sooner than tick T+1.</p>
<p>This one-tick latency can be alleviated by increasing the simulation frequency. It will then just be a matter of choosing the preferred trade-off between latency and wall-clock simulation duration.</p>
</div>
</div>
<div class="section" id="time-stepped-simulation">
<h3>Time-Stepped Simulation</h3>
<p>Models and actors have to comply with the operating conventions of the Sim-Diasca simulations.</p>
<p>In that context, the main convention is that these simulations are <em>time-stepped</em>. This means that the simulation time is sliced into chunks of constant durations.</p>
<p>Therefore we can define at which frequency a simulation should run: a simulation scheduled at 50Hz will rely on a fundamental period of <tt class="docutils literal">1/50 = 20 ms</tt>, thus all simulation time-steps (also known as <em>ticks</em>) will correspond to 20 ms of virtual time.</p>
</div>
<div class="section" id="uncoupling-from-virtual-time">
<h3>Uncoupling From Virtual Time</h3>
<p>Actors are only aware of the passing of this simulation virtual time: the actual time that we, users, experience must not matter to them, otherwise the simulation would loose most of its expected properties.</p>
<p>For example, we do not want the same simulation to output different results depending on the processing power that happens to be available for it.</p>
<p>Thus, for an actor, whether the computing of a given virtual 20ms time-step actually lasts for 1 ms or for two minutes of our time shall be irrelevant; each of these 20 ms time-steps will last in our time exactly as long as needed to compute it appropriately, and the processing of two successive time-steps might require vastly different actual durations, in user time.</p>
</div>
<div class="section" id="formalisation">
<h3>Formalisation</h3>
<p>Modelling allows to bridge the gap between our knowledge of the system and its implementation in the context of a simulation. Generally, increasingly detailed models are specified: first as full text, then with more formal languages.</p>
<p>One can certainly use flowcharts:</p>
<p><span class="raw-html"><center><img src="xkcd-flow_charts.png" id="responsive-image-intermediate"></img></center></span>
</p>
<p>But one may preferably rely on a few UML diagrams, including:</p>
<ul class="simple">
<li>use case diagram</li>
<li>activity diagram</li>
<li>class diagram</li>
<li>sequence diagram</li>
</ul>
<p>Other interesting diagrams might be:</p>
<ul class="simple">
<li>communication diagram</li>
<li>state machine diagram</li>
</ul>
<p>This is one of the most delicate steps, as often the domain experts are not able to write by their own their corresponding models: they generally make use of domain-specific languages, which are tailored for their needs but quite often are, simulation-wise, not standard.</p>
<p>So a translation step to the simulation language must generally take place, and usually domain experts cannot perform that work <a class="footnote-reference" href="#id106" id="id105">[40]</a>.</p>
<p>The best practice we recommend is to adopt a unified language to specify all models first, and to practise pair-work (one domain expert sitting on the side of a computer scientist/model developer) to ensure that the translation is correct. Indeed, mistakes can easily be made:</p>
<p><span class="raw-html"><center><img src="xkcd-circumference_formula.png" id="responsive-image-small"></img></center></span>
</p>
<table class="docutils footnote" frame="void" id="id106" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id105">[40]</a></td><td>These restrictions surely apply to, say, lower-level C++-based simulation engines which demand that models are written that way; and, more generally, models whose behaviour is intrinsically to be described algorithmically need anyway a programming language to be specified. However some of these languages are more suitable than others. To take a real-life example, for the CLEVER project, 5 days of Erlang training, 5 days of basic Sim-Diasca training and 3 days of advanced Sim-Diasca training have been sufficient so that a team with no prior knowledge about these topics was able to write not only models but even a whole specialisation layer of Sim-Diasca for the simulation of metering systems.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="actor-messages">
<h3>Actor Messages</h3>
<p>Actors can communicate only thanks to the passing of specific messages, named <em>actor messages</em>.</p>
<p>During one tick, any actor can send any number of actor messages to any number of actors.</p>
<p>When an actor A sends during tick <tt class="docutils literal">N</tt> an actor message to actor B, B will process it only during the next tick, <tt class="docutils literal">N+1</tt> <a class="footnote-reference" href="#id108" id="id107">[41]</a>.</p>
<table class="docutils footnote" frame="void" id="id108" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id107">[41]</a></td><td>This 1-tick latency is induced by the time-stepped nature of the simulation. This is a constraint indeed, but it can be alleviated (for example by anticipating exchanges and/or choosing a higher fundamental frequency for the simulation) and it is at the root of all the useful properties these simulations can rely on.</td></tr>
</tbody>
</table>
<p>A corollary is then that if A requests an information from B during tick <tt class="docutils literal">N</tt>, A will process that information during tick <tt class="docutils literal">N+2</tt>.</p>
<p>Moreover during a tick an actor may receive multiple messages from multiple actors. No assumption should be made on their processing order within that tick, as the simulation algorithm will have reordered them to ensure the respect of the simulation properties (ex: reproducibility or ergodicity).</p>
</div>
<div class="section" id="actor-life-cycle">
<h3>Actor Life-Cycle</h3>
<div class="section" id="actor-creation">
<h4>Actor Creation</h4>
<p>An actor must be either created:</p>
<ul class="simple">
<li>by the simulation scenario, before the simulation is started</li>
<li>by another (already synchronised) actor</li>
</ul>
<p>In the latter case, if actor A requires the creation of an actor B during tick <tt class="docutils literal">T</tt> diasca <tt class="docutils literal">D</tt> (hence at <tt class="docutils literal">{T,D}</tt>), then B will be actually created at tick <tt class="docutils literal">{T,D+1}</tt>. On the next diasca (<tt class="docutils literal">{T,D+2}</tt>) B will be scheduled for the first time (thanks to a call to its <tt class="docutils literal">onFirstDiasca/2</tt> actor oneway), while A will be notified of this creation (and of the PID of B).</p>
<p>Usually some specific actors, not directly corresponding to an element of the target system, are defined to create other actors.</p>
<p>For example a deployment policy for an information system can be such an actor, that will create devices according to a given statistical law, in the course of the simulation.</p>
<p>The simulation scenario itself can be modelled as one of these creating actors.</p>
<p>The actual creation of an actor in the course of the simulation is made of a few steps:</p>
<ul class="simple">
<li>at <tt class="docutils literal">{T,D}</tt> the creating actor issues a creation request <a class="footnote-reference" href="#id110" id="id109">[42]</a> to the load balancer</li>
<li>at <tt class="docutils literal">{T,D+1}</tt>:<ul>
<li>the load balancer processes that request, and creates synchronously the corresponding instance on the computing node it deems the most appropriate</li>
<li>during its construction the instance retrieves the overall scheduling settings from the time management agent it is in contact with, and as a consequence notifies it of how it intends to be scheduled; as the created actor is not synchronised yet to the simulation, its initial construction stage has to respect some restrictions; notably the actor is not able yet to interact with other actors or to consume stochastic variables yet</li>
<li>the load balancer sends back to the creating actor an actor message carrying the PID of the created instance, whose basic construction is finished (its constructor ended), but which is not ready to enter the simulation yet</li>
</ul>
</li>
<li>at <tt class="docutils literal">{T,D+2}</tt>:<ul>
<li>the creating actor processes the notification of the created instance, which includes its PID</li>
<li>the created actor is notified that the simulation has started for it (it is necessary as it could have been created before the simulation was started) and is scheduled for the first time; it is up to its model to determine whether this actor is ready to develop its behaviour immediately, as it may not have achieved its full initialisation yet (ex: it may be waiting for other actors to be themselves ready, and/or it might need to set some stochastic values to complete its initialisation, etc.)</li>
<li>as soon as the created actor deems it is itself ready (maybe from its first scheduled tick, maybe on later ticks), automatically any related actions will be triggered, and any actors waiting for that actor will be notified that it is ready now; then on the next tick the actor will be free to develop its normal behaviour; by default during its first scheduled tick an actor will not wait for any other actor, and therefore will call directly its (possibly overridden) <tt class="docutils literal">onReady</tt> method; it will then be ready to develop its actual behaviour only on next tick (<tt class="docutils literal">N+3</tt>)</li>
</ul>
</li>
</ul>
<table class="docutils footnote" frame="void" id="id110" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id109">[42]</a></td><td>To preserve the simulation properties, the load balancer is itself a simulation actor and therefore the creation request is an actor message.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="actor-deletion">
<h4>Actor Deletion</h4>
<p>An actor can decide to be removed from the simulation, usually before being deleted.</p>
<p>The removal process from the time manager will then be automatically conducted, but it is the responsibility of the the removed actor to ensure that no other actor will try to interact with it any more.</p>
<p>Usually the underlying logic ensures that it will be so, or the actor to remove notifies relevant actors of its ongoing removal.</p>
</div>
</div>
<div class="section" id="scheduling-sequence">
<h3>Scheduling Sequence</h3>
<p>At each fundamental simulation tick, each actor may or may not be triggered by the time manager.</p>
<p>If an actor message was sent to it during the last tick, then the actor will automatically process that message, regardless of its scheduling policy.</p>
<p>Then, the time manager determines whether the scheduling policy of this actor implies that it should develop its spontaneous behaviour during this tick.</p>
<p>If yes, the actor will be notified of the current tick and be requested to act according to its planned behaviour.</p>
<p>If no, the actor will not be specifically contacted?</p>
</div>
<div class="section" id="stochastic-variables">
<h3>Stochastic Variables</h3>
<p>An actor may rely on any number of stochastic variables, each of which following any <a class="reference external" href="http://en.wikipedia.org/wiki/Probability_density_function">probability density function</a>.</p>
<p>Sim-Diasca provides three of the most usual stochastic laws: uniform, Gaussian and exponential. User-specified laws can be added quite easily.</p>
<p>Once synchronised, an actor can draw any number of stochastic variables for any law during one tick, immediately (i.e. with a zero-tick latency).</p>
<p></p>
</div>
</div>
<div class="section" id="main-choices-in-terms-of-actor-modelling">
<h2><a class="toc-backref" href="#id220">Main Choices In Terms Of Actor Modelling</a></h2>
<div class="section" id="fundamental-frequency">
<h3>Fundamental Frequency</h3>
<p>As discussed previously, the root time manager in charge of a simulation will maintain its virtual time based on the fundamental overall frequency the simulation user specified: this frequency (ex: 50 Hz) directly dictates the duration in virtual time between two successive engine ticks (ex: 20 ms).</p>
<p>Therefore once this root time manager will have determined that all the actors to be scheduled this tick (the ones having to process actor message(s) and/or having to develop their behaviour on that tick) have reported that they have finished taking that current tick into account, it will then just increment the simulation tick, since the corresponding virtual 20 ms will have elapsed, and then declare that a new tick just has just begun.</p>
<p>Relying on a fundamental simulation frequency does not imply however that each and every simulation actor will have to be scheduled according to that exact overall frequency, i.e. at each tick. Each model is able to pick a scheduling policy that match best its needs.</p>
<p>Once all models have been established, the overall frequency of the simulation can be determined: it should be chosen at least equal to the highest frequency of the models involved.</p>
</div>
<div class="section" id="policies-in-terms-of-actor-scheduling">
<h3>Policies in Terms of Actor Scheduling</h3>
<p>Generally the fundamental frequency will have been chosen so that the most reactive actors can be scheduled at the exact pace they require, but usually there will be also many other actors whose behaviour does not need to be evaluated as frequently.</p>
<p>Therefore, to ease the implementation of models and to preserve performances, the Sim-Diasca simulation engine allows models to request a scheduling more flexible than &quot;every actor is triggered at each simulation tick&quot;.</p>
<p>Scheduling-wise, the three most common types of actors are:</p>
<ul class="simple">
<li><em>periodical actors</em>: an actor requesting a scheduling period of N would be triggered by the time manager one time step every N elapsed; therefore an actor could run, in virtual time, at a frequency of 10 Hz even if the fundamental frequency of the simulation was set for example to 50Hz</li>
<li><em>step-by-step actors</em>: when such actors finish a time step, they may specify the next tick at which they should be triggered again (<em>look-ahead</em>), unless they receive an actor message in-between, in which case they may withdraw their already planned activation and set a new one, earlier or later</li>
<li><em>purely passive actors</em>: these actors have no spontaneous behaviour, they are triggered only when they receive a message from another actor during the previous tick</li>
</ul>
<p>These scheduling policies - and many others - can be implemented with Sim-Diasca thanks to the definition of future actions: each actor, during its triggered and spontaneous behaviours, is able to specify, if needed, a future tick at which it should be scheduled for a spontaneous behaviour.</p>
<p>Thus periodical actors will just define at the end of their spontaneous behaviour one future action which is to take place a fixed duration (in simulation time) after the current tick, step-by-step actors will define arbitrary future actions, and passive actors will never define any specific future action.</p>
</div>
<div class="section" id="frequency-independent-timings">
<h3>Frequency-Independent Timings</h3>
<p>In the context of a model, durations (in virtual time) are encouraged to be defined explicitly, absolutely, rather than directly as a given number of simulation ticks, so that models remain as much as possible independent from the actual frequency a simulation is running at.</p>
<p>For example, when a simulated device starts a new task and thus has to determine when a priori it will have finished the corresponding work and be available again, its model may evaluate the corresponding duration to &quot;1400 ms&quot; (in virtual time) rather than directly to an hard-coded &quot;28 fundamental ticks&quot;.</p>
<p>Then only (i.e. at run-time), that duration, depending on the actual settings of the current simulation, will be converted to the appropriate number of ticks, so that a change in the simulation fundamental frequency will not impact models.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Using such absolute durations is not always straightforward, as being based on a fundamental frequency leads to a quantisation of durations: if for example a simulated device is scheduled by the voltage of the main supply (say, 50Hz), and if the simulation does not run at a multiple of 50Hz, then either the model will have to ignore the errors resulting from the approximated scheduling, or be designed - if possible - to accommodate to an arbitrary scheduling frequency, in spite of the issues this implies (like the accumulation of rounding or sampling errors).</p>
</div>
</div>
</div>
<div class="section" id="modelling-process">
<h2><a class="toc-backref" href="#id221">Modelling Process</a></h2>
<p>Here are the questions that should be addressed simulation-wise, when writing a model.</p>
<div class="section" id="nature-of-the-model">
<h3>Nature Of The Model</h3>
<p>Should all concepts to be ultimately simulated be represented by models of their own? Sometimes using a simple data structure owned by another actor is the most appropriate approach.</p>
<p>If a concept:</p>
<ul class="simple">
<li>is used in multiple different contexts</li>
<li>and/or is used by multiple actors</li>
<li>and/or has a complex state and/or behaviour</li>
<li>and/or is not tightly coupled to any model</li>
</ul>
<p>then most probably this concept should be mapped to a specific model, i.e. a dedicated class inheriting from <tt class="docutils literal">class_Actor</tt>.</p>
</div>
<div class="section" id="model-temporality-and-reactivity">
<h3>Model Temporality And Reactivity</h3>
<p>Supposing we determined that the model was to be implemented as a class, we must then establish whether this model is able to perform spontaneous actions.</p>
<p>If yes (i.e. its instances are able to trigger actions not directly related to the receiving of a message received from other actors), then this is an active actor that will have a spontaneous behaviour, possibly periodical or erratic (step-by-step), etc.</p>
<p>The model is then able to specify with a total freedom its spontaneous scheduling, using notably <tt class="docutils literal">addSpontaneousTick/2</tt>, <tt class="docutils literal">addSpontaneousTicks/2</tt>, <tt class="docutils literal">withdrawnSpontaneousTick/2</tt> and <tt class="docutils literal">withdrawnSpontaneousTicks/2</tt>, from its <tt class="docutils literal">actSpontaneous/1</tt> oneway or any of ithe actor oneways it defined.</p>
<p>Please refer to the <tt class="docutils literal"><span class="pre">Sim-Diasca</span> Developer Guide</tt> for further details.</p>
</div>
<div class="section" id="state-and-behaviour-of-the-model">
<h3>State And Behaviour Of The Model</h3>
<p>These are very model-specific, but general rules still apply.</p>
<p>Processing an actor message and acting spontaneously both boil down to writing an appropriate method, which may send actor messages and/or return any updated state and/or trigger the removal of that actor.</p>
<div class="section" id="triggered-behaviour-receiving-of-an-actor-message">
<h4>Triggered Behaviour: Receiving of an Actor Message</h4>
<p>For example if an actor A needs to set the color of an actor B, then it may send to it an actor message specifying <tt class="docutils literal">{setColor,red}</tt>. Then, B will process it at the next diasca: its <tt class="docutils literal">setColor</tt> method (actor oneway) will be automatically called and, based on the transmitted parameter, B will be able to update its state, for example by setting its <tt class="docutils literal">color</tt> attribute to <tt class="docutils literal">red</tt>.</p>
<p>Should B receive an actor message requesting an answer (ex: <tt class="docutils literal">getColor</tt>), it would do so by sending back another actor message to A, like <tt class="docutils literal">{notifyColor,red}</tt>.</p>
</div>
<div class="section" id="spontaneous-behaviour">
<h4>Spontaneous Behaviour</h4>
<p>It is simply implemented by the calling of the <tt class="docutils literal">actSpontaneous</tt> oneway method of that actor.</p>
<p>See also the <em>Sim-Diasca Modeller Guide</em> for a more in-depth discussion about modelling and implementation, based on a light yet complete example.</p>
<p></p>
</div>
</div>
</div>
</div>
<div class="section" id="validating-the-resulting-simulators">
<span id="validated"></span><span id="validation"></span><h1><a class="toc-backref" href="#id222">Validating The Resulting Simulators</a></h1>
<p>Adding to Sim-Diasca (the simulation engine) a set of models and at least one simulation case results into building a new simulator.</p>
<p>This simulator may or may not be accurate, and this must be established first.</p>
<p>Indeed, drawing bad conclusions from false assumptions or improper reasoning is surprisingly easy:</p>
<p><span class="raw-html"><center><img src="xkcd-dimensional_analysis.png" id="responsive-image-reduced"></img></center></span>
</p>
<p>Being able to trust this new simulator is of course of the utmost importance.</p>
<p>Therefore, before using it to learn new facts, one must validate it adequately.</p>
<p>Validation can be done thanks to multiple non-exclusive approaches, mostly based on the produced results:</p>
<ul class="simple">
<li>having field experts review virtual experiments about known situations</li>
<li>computing coarse orders of magnitude with other approaches (ex: spreadsheet-based estimations not involving time aspects)</li>
<li>checking the results against an actual (in real-life) test bed, provided that early prototypes are available</li>
<li>comparing a representative set of outputs to the one produced by a reference simulator (ex: validating the telecom aspects of a business simulation against an industrial-grade telecom-specific simulator)</li>
</ul>
<p></p>
</div>
<div class="section" id="sim-diasca-cheat-sheet">
<h1><a class="toc-backref" href="#id223">Sim-Diasca Cheat Sheet</a></h1>
<div class="admonition warning">
<p class="first admonition-title">Warning</p>
<p class="last">This section would deserve some update.</p>
</div>
<p>Note: unless specified otherwise, mentioned tests are to be found in the <tt class="docutils literal"><span class="pre">sim-diasca/src/core/src/scheduling/tests</span></tt> directory.</p>
<div class="section" id="which-sim-diasca-version-should-be-used">
<h2><a class="toc-backref" href="#id224">Which Sim-Diasca Version Should Be Used?</a></h2>
<p>Previously there were two versions, one local, one distributed. Now that they have been merged into a single base, one should simply pick the latest stable version. That's it!</p>
<p>To check which version you are using, simply run from the root directory:</p>
<pre class="code bash literal-block">
$ make info-version
This is Sim-Diasca version x.y.z.
</pre>
<p>Alternatively, look at the <tt class="docutils literal">SIM_DIASCA_VERSION</tt> variable in <tt class="docutils literal"><span class="pre">sim-diasca/GNUmakevars.inc</span></tt>.</p>
<p>As upgrading the Sim-Diasca version is fairly straightforward, we recommend to stick to the latest stable one, which simplifies considerably any support.</p>
<p>Finally, the lower layers (namely Erlang itself, <tt class="docutils literal">Myriad</tt>, <tt class="docutils literal">WOOPER</tt> and <tt class="docutils literal">Traces</tt>) have of course their own version as well, and the same holds for the upper layers, i.e. the actual simulations making use of Sim-Diasca (from the toy examples in <tt class="docutils literal"><span class="pre">mock-simulators</span></tt> to any user-provided one).</p>
<p>Anyway, as a given version of Sim-Diasca is delivered with all its strictly mandatory prerequisites except Erlang, no particular checking of their version is necessary, as they collectively form a consistent bundle.</p>
</div>
<div class="section" id="how-can-we-run-a-simulation">
<h2><a class="toc-backref" href="#id225">How Can We Run a Simulation?</a></h2>
<p>A simulation can be run either from a <em>test</em> file, whose name is suffixed with <tt class="docutils literal">_test.erl</tt> (ex: stored in a <tt class="docutils literal">my_foobar_test.erl</tt>) or from a <em>case</em> file, whose name is suffixed with <tt class="docutils literal">_case.erl</tt> (ex: stored in a <tt class="docutils literal">my_baz_case.erl</tt>).</p>
<p>No runtime difference is made between these two (they are technically exactly handled the same), the purpose of this distinction being solely to help the user separating the more punctual testing from full-blown simulation cases.</p>
<p>So, with both tests and cases:</p>
<ul class="simple">
<li>the corresponding simulation shall be run by executing a make target bearing the same name, suffixed by <tt class="docutils literal">_run</tt>; respectively as <tt class="docutils literal">make my_foobar_run</tt> and <tt class="docutils literal">make my_baz_run</tt> for the two examples above</li>
<li>all files and directories generated by the simulation (notably traces and results) will be created in the current directory; typically the user changes to the directory where the corresponding test or case file is stored, and run it from there</li>
<li>by default, simulations will be run in interactively, i.e. with graphical windows popping up (ex: to browse traces, results, etc.); to prevent that and remain in a purely textual, command-line, batch execution, one can add the <tt class="docutils literal"><span class="pre">CMD_LINE_OPT=&quot;--batch&quot;</span></tt> option to the make command; as it involves some typing, it may be convenient to define a shorthand for that, typically by putting in ones's <tt class="docutils literal"><span class="pre">~/.bashrc</span></tt> a line like: <tt class="docutils literal">export <span class="pre">BATCH='CMD_LINE_OPT=&quot;--batch&quot;'</span></tt></li>
</ul>
<p>As a full, concrete example of running a <em>test</em> simulation interactively:</p>
<pre class="code bash literal-block">
$ <span class="nb">cd</span> mock-simulators/soda-test/src
$ ls soda_stochastic_integration_test.erl
soda_stochastic_integration_test.erl
$ make soda_stochastic_integration_run
Running unitary <span class="nb">test</span> soda_stochastic_integration_run <span class="o">(</span>third form<span class="o">)</span> from soda_stochastic_integration_test
<span class="o">[</span>...<span class="o">]</span>
End of <span class="nb">test</span> soda_stochastic_integration_test
<span class="o">(</span><span class="nb">test</span> finished, interpreter halted<span class="o">)</span>
</pre>
<p>To run a simulation <em>case</em>, here in batch mode:</p>
<pre class="code bash literal-block">
$ <span class="nb">cd</span> mock-simulators/soda-test/src
$ ls soda_platform_integration_case.erl
soda_platform_integration_case.erl
$ make soda_platform_integration_run <span class="nv">CMD_LINE_OPT</span><span class="o">=</span><span class="s2">&quot;--batch&quot;</span>
Running simulation <span class="k">case</span> soda_platform_integration_case
<span class="o">[</span>...<span class="o">]</span>
End of <span class="k">case</span> soda_platform_integration_case
<span class="o">(</span><span class="k">case</span> finished, interpreter halted<span class="o">)</span>
</pre>
<p>Of course, with the aforementioned shell shorthand, the last case could also be run as:</p>
<pre class="code bash literal-block">
$ make soda_platform_integration_run <span class="nv">$BATCH</span>
</pre>
</div>
<div class="section" id="how-can-i-select-whether-a-simulation-run-shall-be-purely-local-or-distributed">
<h2><a class="toc-backref" href="#id226">How Can I Select Whether A Simulation Run Shall be Purely Local, or Distributed?</a></h2>
<p>Each simulation case is able to define how it is to be deployed or executed, simply by setting accordingly the <tt class="docutils literal">computing_hosts</tt> field in its <tt class="docutils literal">deployment_settings</tt> record (whose full definition and associated comments can be found in <tt class="docutils literal">class_DeploymentManager.hrl</tt>).</p>
<p>Most test cases rely on default settings, which operate this way:</p>
<ol class="arabic simple">
<li>if a host file - named by default <tt class="docutils literal"><span class="pre">sim-diasca-host-candidates.txt</span></tt> - is found in the current directory (the one from which a test case <tt class="docutils literal">X</tt> is run, thanks to a <tt class="docutils literal">make X_run</tt> for example), then the engine will read it and try to use the hosts listed there; the (ETF) syntax is simple and described in the <tt class="docutils literal"><span class="pre">sim-diasca-host-candidates-sample.txt</span></tt> example file, to be found in the <tt class="docutils literal"><span class="pre">sim-diasca/conf</span></tt> directory (it is also described <a class="reference external" href="http://myriad.esperide.org/#etf">here</a>)</li>
<li>if this host file is not found, the simulation will run only locally</li>
</ol>
<p>The <tt class="docutils literal">computing_hosts</tt> field can also directly list the hosts involved, but we do not recommend doing so, as in general a simulation case should not be specific to any deployment context (hence our defaults).</p>
<p>The <tt class="docutils literal">deployment_settings</tt> record allows to specify more advanced options (ex: whether the simulation should stop on error if at least one of the listed hosts could not be used, up to which duration a deployment may last, whether the user host shall be used for computations, etc.), see its definition mentioned above for further information.</p>
</div>
<div class="section" id="how-many-erlang-nodes-are-involved-in-a-simulation">
<h2><a class="toc-backref" href="#id227">How Many Erlang Nodes Are Involved in a Simulation?</a></h2>
<p>By default (unless specified otherwise, see above), only the local host is involved, yet there are two VMs running then: the one of the user node, and the one of a (local) computing node.</p>
<p>In the general case, distributed simulations running on <tt class="docutils literal">N</tt> hosts will involve by default <tt class="docutils literal">N+1</tt> nodes: one user node (on the user host) and <tt class="docutils literal">N</tt> computing nodes (including one on the user host).</p>
<p>See the <tt class="docutils literal">computing_hosts</tt> field in the <tt class="docutils literal">deployment_settings</tt> record (defined in <tt class="docutils literal">class_DeploymentManager.hrl</tt>) for further options.</p>
</div>
<div class="section" id="what-constraints-shall-be-observed-in-order-to-run-in-a-distributed-manner-ex-on-a-cluster">
<span id="distributed-cheat-sheet"></span><h2><a class="toc-backref" href="#id228">What Constraints shall be Observed in order to run in a Distributed Manner (ex: on a cluster)?</a></h2>
<p>Let's suppose that you benefit from a set of hosts, either ad hoc or allocated on a cluster by a job manager such as <a class="reference external" href="https://en.wikipedia.org/wiki/Slurm_Workload_Manager">Slurm</a>.</p>
<p>These hosts are expected to run GNU/Linux, to be rather homogeneous in terms of processing power and configuration, and to be interlinked thanks to a suitable IPv4 <a class="footnote-reference" href="#id115" id="id113">[43]</a> communication network providing at least DNS services, and possibly ping (ICMP) ones <a class="footnote-reference" href="#id116" id="id114">[44]</a>.</p>
<table class="docutils footnote" frame="void" id="id115" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id113">[43]</a></td><td>If the network is by default using IPv6, generally a setting allows to present it to applications as an IPv4 network.</td></tr>
</tbody>
</table>
<table class="docutils footnote" frame="void" id="id116" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id114">[44]</a></td><td>If no ping service is available, then, in the <tt class="docutils literal">deployment_settings</tt> record of your simulation case, set <tt class="docutils literal">ping_available=false</tt>, and the simulation will try directly to SSH-connect to hosts (possibly inducing longer timeouts).</td></tr>
</tbody>
</table>
<p>When specifying these hosts (ex: in a host file of the <tt class="docutils literal">computing_hosts</tt> field of the deployment record, or directly in the simulation case), their DNS name (more precisely, their FQDN <a class="footnote-reference" href="#id118" id="id117">[45]</a>) shall be retained (not, for example, their IP address).</p>
<table class="docutils footnote" frame="void" id="id118" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id117">[45]</a></td><td><em>Fully-Qualified Domain Name</em>, e.g. <tt class="docutils literal">hurricane.foobar.org</tt> rather than just <tt class="docutils literal">hurricane</tt>, knowing that from a FQDN a (domain-less) hostname can be derived, whereas this cannot be done the other way round. Sim-Diasca will start first with no distribution, then will attempt first to make use, in Erlang node parlance, of <em>short</em> names before, depending on the local DNS configuration, attempting to switch to <em>long</em> names instead.</td></tr>
</tbody>
</table>
<p>Moreover, for the simulation user, a SSH password-less authentication must be possible at least from the user host to each of the computing hosts, so that the former can spawn an Erlang VM on the latter.</p>
<p>Indeed, all hosts, be them the user one or a computing one, must be able to run their own Erlang virtual machine; as a result the Erlang environment must have been installed, typically thanks to our <tt class="docutils literal"><span class="pre">myriad/conf/install-erlang.sh</span></tt> script.</p>
<p>Quite often HPC clusters implement a distributed filesystem (ex: mounted in <tt class="docutils literal">/scratch</tt>, thanks to NFS, Lustre or any similar solution), in which case a single Erlang installation can be done once for all, each computing node creating its own VM from it.</p>
<p>If no such distributed filesystem exists, the Erlang environment must be deployed/installed on each computing host, by any relevant means.</p>
<p>These target Erlang installations must be readily available from the default <tt class="docutils literal">PATH</tt> that is obtained from a SSH connection to a computing host: from the user host, <tt class="docutils literal">ssh A_COMPUTING_NODE erl</tt> should successfully run an Erlang VM <a class="footnote-reference" href="#id120" id="id119">[46]</a>.</p>
<table class="docutils footnote" frame="void" id="id120" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id119">[46]</a></td><td>If in this case a custom, locally-installed Erlang version (ex: located in <tt class="docutils literal"><span class="pre">~/Software/Erlang/Erlang-current-install</span></tt>) is not found whereas it was added in the <tt class="docutils literal">PATH</tt> of the user's <tt class="docutils literal"><span class="pre">~/.bashrc</span></tt>, consider that many default batch configurations ignore this file for non-login shells (&quot;<em>If not running interactively, don't do anything</em>&quot;); a workaround is to update one's <tt class="docutils literal">PATH</tt> at the beginning of one's <tt class="docutils literal"><span class="pre">~/.bashrc</span></tt> rather than at its end, before it bails out with a <tt class="docutils literal">return</tt>.</td></tr>
</tbody>
</table>
<p>As for Sim-Diasca, its own Ceylan prerequisites (namely <a class="reference external" href="http://myriad.esperide.org/">Myriad</a>, <a class="reference external" href="http://wooper.esperide.org/">WOOPER</a> and <a class="reference external" href="http://traces.esperide.org/">Traces</a>), the engine itself and the user-defined simulation elements (simulation case, models, data, etc.), the whole will be automatically deployed from the user host to the computing ones, according to the specified simulation settings.</p>
<p>One should thus ensure that these settings are complete, and that any third-party software used (ex: in models, in probes, etc.; including any language binding) is available on all computing hosts.</p>
<p>Finally, we advise having a look to the help scripts defined in <tt class="docutils literal"><span class="pre">sim-diasca/conf/clusters</span></tt>, which are meant to ease the management of Sim-Diasca jobs run on Slurm-based HPC clusters.</p>
</div>
<div class="section" id="what-are-the-most-common-gotchas-encountered-with-distributed-simulations">
<span id="distributed-gotchas"></span><h2><a class="toc-backref" href="#id229">What are the Most Common Gotchas encountered with Distributed Simulations?</a></h2>
<p>As soon as an application is distributed, a rather wide range of additional problems may appear.</p>
<p>Here are a list of checks that might be of help:</p>
<ul class="simple">
<li>is this simulation (possibly set to a lesser scale) running well on a single host?</li>
<li>has the full simulation been recompiled from scratch with success, using a recent version of Erlang?</li>
<li>is this version of Erlang uniform across all hosts involved in the simulation? (it is usually not strictly necessary, but is convenient to rule out some possible incompatibilities)</li>
<li>are ping (ICMP) messages supported by the hosts and network at hand? If no, set the <tt class="docutils literal">ping_available</tt> field of the <tt class="docutils literal">deployment_settings</tt> record to <tt class="docutils literal">false</tt></li>
<li>does spawning a Erlang VM on a computing host non-interactively through SSH from the user host succeed? Ex: from the user host, <tt class="docutils literal">ssh A_COMPUTING_HOST erl</tt></li>
<li>does it spawn a VM with the same, expected Erlang version? (ex: <tt class="docutils literal">Eshell V10.2</tt>)</li>
<li>can this VM be run with either short or long names, and does it report the expected FQDN in its prompt? Ex: <tt class="docutils literal">ssh COMPUTING_HOST_FQDN erl <span class="pre">-name</span> foo</tt> reporting <tt class="docutils literal">(foo&#64;COMPUTING_HOST_FQDN)1&gt;</tt></li>
<li>are all hosts specified indeed by their FQDN? (rather than by a riskier mere hostname or, worse, by their IP address - which is not permitted)</li>
<li>on any host or network device, have fancier firewall rules been defined? (ex: <tt class="docutils literal">iptables <span class="pre">-L</span></tt> might give clues)</li>
<li>on a cluster, have the right hosts been allocated by the job manager, and is the user host one of them? (rather than for example being a front-end host - which surely should not be attempted)</li>
</ul>
<p>Should the problem remain, one may log interactively and perform operations manually to check whether the engine has a chance of succeeding when doing the same.</p>
</div>
<div class="section" id="what-is-the-first-tick-offset-of-a-simulation">
<h2><a class="toc-backref" href="#id230">What is the First Tick Offset of a Simulation?</a></h2>
<p>Tick offset #0.</p>
</div>
<div class="section" id="what-is-the-first-diasca-of-a-given-tick-t">
<h2><a class="toc-backref" href="#id231">What is the First Diasca of a given Tick T?</a></h2>
<p>Diasca #0! Hence the corresponding simulation timestamp is <tt class="docutils literal">{T,0}</tt>.</p>
</div>
<div class="section" id="how-a-simulation-starts">
<h2><a class="toc-backref" href="#id232">How a Simulation Starts?</a></h2>
<p>The root time manager is to be requested to start from the simulation case being run, typically by executing its <tt class="docutils literal"><span class="pre">start/{1,2,3}</span></tt> or <tt class="docutils literal"><span class="pre">startFor/{2,3}</span></tt> oneways.</p>
<p>For that, the PID of the deployment manager shall be obtained first, thanks a call to one of the <tt class="docutils literal"><span class="pre">sim_diasca/{1,2,3}</span></tt> functions; for example:</p>
<pre class="code erlang literal-block">
<span class="nv">DeploymentManagerPid</span> <span class="o">=</span> <span class="nn">sim_diasca</span><span class="p">:</span><span class="nf">init</span><span class="p">(</span><span class="nv">SimulationSettings</span><span class="p">,</span> <span class="nv">DeploymentSettings</span><span class="p">)</span>
</pre>
<p>Then the PID of the root time manager can be requested from it:</p>
<pre class="code erlang literal-block">
<span class="nv">DeploymentManagerPid</span> <span class="o">!</span> <span class="p">{</span><span class="n">getRootTimeManager</span><span class="p">,</span> <span class="p">[],</span> <span class="n">self</span><span class="p">()},</span>
<span class="nv">RootTimeManagerPid</span> <span class="o">=</span> <span class="n">test_receive</span><span class="p">()</span>
</pre>
<p>The actual start can be then triggered thanks to:</p>
<pre class="code erlang literal-block">
<span class="nv">RootTimeManagerPid</span> <span class="o">!</span> <span class="p">{</span><span class="n">start</span><span class="p">,</span> <span class="p">[</span><span class="n">self</span><span class="p">()]}</span>
</pre>
<p>This will evaluate the simulation from its first timestamp, <tt class="docutils literal">{0,0}</tt>:</p>
<ul class="simple">
<li>the <tt class="docutils literal">simulationStarted/3</tt> request of all time managers will be triggered by the root one, resulting in the request being triggered (by transparent chunks) in turn to all initial actors so that they can be synchronised (i.e. so that they are notified of various information, mostly time-related); at this point they are still passive, have no agenda declared and are not fully initialized (their own initialization logic is to be triggered only when entering for good the simulation, at their fist diasca)</li>
<li>then the root time manager auto-triggers its <tt class="docutils literal">beginTimeManagerTick/2</tt> oneway</li>
<li>then <tt class="docutils literal">{0,0}</tt> is scheduled, and the load balancer (created, like the time managers, by the deployment manager) is triggered (by design no other actor can possibly in that case), for its first and only spontaneous scheduling, during which it will trigger in turn, over the first diascas (to avoid a potentially too large initial spike), the <tt class="docutils literal">onFirstDiasca/2</tt> actor oneway of all initial actors (that it had spawned)</li>
</ul>
<p>As actors can schedule themselves only once fully ready (thus from their <tt class="docutils literal">onFirstDiasca/2</tt> actor oneway onward), by design the load balancer is the sole actor to be scheduled at <tt class="docutils literal">{0,0}</tt> (thus spontaneously), leading all other actors to be triggered for their first diasca only at <tt class="docutils literal">{0,1}</tt>, and possible next diascas, should initial actors be numerous.</p>
<p>From that point they can start sending (and thus receiving) actor messages (while still at tick offset #0), or they can request a spontaneous activation at the next tick (hence at <tt class="docutils literal">{1,0}</tt>), see <tt class="docutils literal">class_Actor:scheduleNextSpontaneousTick/1</tt> for that.</p>
<p>In summary, from an actor's viewpoint, in all cases:</p>
<ul class="simple">
<li>it is constructed first (no inter-actor message of any kind to be sent from there)</li>
<li>(it is synchronised to the simulation with its time manager - this step is fully transparent to the model developer)</li>
<li>its <tt class="docutils literal">onFirstDiasca/2</tt> actor oneway is triggered once entering the simulation; it is up to this oneway to send actor messages and/or declare at least one spontaneous tick (otherwise this actor will remain purely passive)</li>
</ul>
<p>For more information about simulation cases, one may look at a complete example thereof, such as <tt class="docutils literal">soda_deterministic_integration_test.erl</tt>, located in <tt class="docutils literal"><span class="pre">mock-simulators/soda-test/test</span></tt>.</p>
</div>
<div class="section" id="how-actors-are-to-be-created">
<h2><a class="toc-backref" href="#id233">How Actors Are To Be Created?</a></h2>
<p>Actors are to be created either before the simulation starts (they are then called <em>initial actors</em>) or in the course of the simulation (they are then <em>simulation-time actors</em>, or <em>runtime</em> actors).</p>
<p>In all cases, their creation must be managed through the simulation engine, not directly by the user (for example, making a direct use of <tt class="docutils literal">erlang:spawn*</tt> or any WOOPER <tt class="docutils literal">new</tt> variation is <em>not</em> allowed), as otherwise even essential simulation properties could not be preserved.</p>
<p><strong>Initial</strong> actors are to be created:</p>
<ul class="simple">
<li>either <em>programmatically</em>, directly from the simulation case, or from any code running (synchronously, to avoid a potential race condition) prior to the starting the simulation (ex: in the constructor of a scenario which would be created from the simulation case); see the <tt class="docutils literal"><span class="pre">class_Actor:create_initial_actor/{2,3}</span></tt> and <tt class="docutils literal"><span class="pre">class_Actor:create_initial_placed_actor/{3,4}</span></tt> static methods for individual creations (in the latter case with a placement hint), and the static methods <tt class="docutils literal"><span class="pre">class_Actor:create_initial_actors/{1,2}</span></tt> for the creation of a set of actors</li>
<li>or <em>from data</em>, i.e. from a stream of construction parameters; these information are typically read from an initialization file, see the <tt class="docutils literal">initialisation_files</tt> field of the <tt class="docutils literal">simulation_settings</tt> record</li>
</ul>
<p>In both cases, an initial actor is able to create directly from its constructor any number of other (initial) actors.</p>
<p><strong>Simulation-time</strong> actors are solely to be created directly from other actors that are already running - not from their constructors <a class="footnote-reference" href="#id124" id="id123">[47]</a>; hence simulation-time actors shall be created no sooner than in the <tt class="docutils literal">onFirstDiasca/2</tt> oneway of the creating actor; creation tags may be specified in order to help the creating actor between simultaneous creations; please refer to the <tt class="docutils literal"><span class="pre">class_Actor:create_actor/{3,4}</span></tt> and <tt class="docutils literal"><span class="pre">class_Actor:create_placed_actor/{4,5}</span></tt> helper functions for that</p>
<table class="docutils footnote" frame="void" id="id124" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id123">[47]</a></td><td>As a just-created <em>and</em> creating actor is not yet synchronized to the simulation, hence unable to interact with the load balancer through actor messages for that.</td></tr>
</tbody>
</table>
<p>In all cases, an actor can be either automatically created by the engine on a computing node chosen according to its <em>default heuristic</em> (agnostic placement), or the target node can be selected according to a <em>placement hint</em>, specified at the actor creation.</p>
<p>In the latter case, the engine will then do its best to place all actors being created with the same placement hint on the same computing node, to further optimise the evaluation of tightly coupled actors.</p>
<div class="section" id="initial-actors">
<h3>Initial Actors</h3>
<p>Initial actors are to be created directly from the simulation case, and their creation must be synchronous, otherwise there could be a race condition between the moment they are all up and ready and the moment at which the simulation starts.</p>
<p>There must be at least one initial actor, as otherwise the simulation will stop as soon as started, since it will detect that no event at all can possibly happen anymore.</p>
<div class="section" id="with-agnostic-actor-placement">
<h4>With Agnostic Actor Placement</h4>
<p>The actual creation is in this case done thanks to the <tt class="docutils literal">class_Actor:create_initial_actor/2</tt> static method, whose API is identical in the centralised and distributed branches.</p>
<p>For example, if wanting to create an initial soda vending machine (<tt class="docutils literal">class_SodaVendingMachine</tt>), whose constructor takes two parameters (its name and its initial stock of cans), then one has simply to use, before the simulation is started:</p>
<pre class="code erlang literal-block">
<span class="p">...</span>
<span class="nv">VendingMachinePid</span> <span class="o">=</span> <span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_initial_actor</span><span class="p">(</span>
  <span class="n">class_SodaVendingMachine</span><span class="p">,</span> <span class="p">[</span> <span class="p">_</span><span class="nv">Name</span><span class="o">=</span><span class="s">&quot;My machine&quot;</span><span class="p">,</span> <span class="p">_</span><span class="nv">CanCount</span><span class="o">=</span><span class="mi">15</span> <span class="p">]</span> <span class="p">),</span>
<span class="p">...</span>
<span class="c">% Now simulation can be started.</span>
</pre>
<p>An additional static method, <tt class="docutils literal">class_Actor:create_initial_actor/3</tt>, is available, the third parameter being the PID of an already-retrieved load balancer. This allows, when creating a large number of initial actors, to retrieve the load balancer once for all, instead of looking it up again and again, at each <tt class="docutils literal">class_Actor:create_initial_actor/2</tt> call.</p>
<p>For example:</p>
<pre class="code erlang literal-block">
<span class="p">...</span>
<span class="nv">LoadBalancerPid</span> <span class="o">=</span> <span class="nn">class_LoadBalancer</span><span class="p">:</span><span class="nf">get_balancer</span><span class="p">(),</span>
<span class="p">...</span>

<span class="nv">FirstVendingMachinePid</span> <span class="o">=</span> <span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_initial_actor</span><span class="p">(</span>
      <span class="n">class_SodaVendingMachine</span><span class="p">,</span> <span class="p">[</span> <span class="p">_</span><span class="nv">Name</span><span class="o">=</span><span class="s">&quot;My first machine&quot;</span><span class="p">,</span>
         <span class="p">_</span><span class="nv">FirstCanCount</span><span class="o">=</span><span class="mi">15</span> <span class="p">],</span>
      <span class="nv">LoadBalancerPid</span> <span class="p">),</span>
<span class="p">...</span>
<span class="nv">SecondVendingMachinePid</span> <span class="o">=</span> <span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_initial_actor</span><span class="p">(</span>
      <span class="n">class_SodaVendingMachine</span><span class="p">,</span> <span class="p">[</span> <span class="s">&quot;My second machine&quot;</span><span class="p">,</span>
         <span class="p">_</span><span class="nv">SecondCanCount</span><span class="o">=</span><span class="mi">8</span> <span class="p">],</span>
      <span class="nv">LoadBalancerPid</span> <span class="p">),</span>
<span class="p">...</span>
<span class="c">% Now simulation can be started.</span>
</pre>
<p>Full examples can be found in:</p>
<ul class="simple">
<li><tt class="docutils literal">scheduling_one_initial_terminating_actor_test.erl</tt></li>
<li><tt class="docutils literal">scheduling_one_initial_non_terminating_actor_test.erl</tt></li>
</ul>
</div>
<div class="section" id="based-on-a-placement-hint">
<h4>Based On A Placement Hint</h4>
<p>The same kind of calls as previously can be used, with an additional parameter, which is the placement hint, which can be any Erlang term chosen by the developer.</p>
<p>In the following example, first and second vending machines should be placed on the same computing node (having the same hint), whereas the third vending machine may be placed on any node:</p>
<pre class="code erlang literal-block">
<span class="p">...</span>
<span class="nv">FirstVendingMachinePid</span> <span class="o">=</span> <span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_initial_placed_actor</span><span class="p">(</span>
   <span class="n">class_SodaVendingMachine</span><span class="p">,</span> <span class="p">[</span> <span class="s">&quot;My first machine&quot;</span><span class="p">,</span> <span class="p">_</span><span class="nv">CanCount</span><span class="o">=</span><span class="mi">15</span> <span class="p">]</span>
   <span class="n">my_placement_hint_a</span> <span class="p">),</span>
<span class="p">...</span>
<span class="c">% Using now the variation with an explicit load balancer:
% (only available in the distributed case)
</span><span class="nv">LoadBalancerPid</span> <span class="o">=</span> <span class="nn">class_LoadBalancer</span><span class="p">:</span><span class="nf">get_balancer</span><span class="p">(),</span>
<span class="p">...</span>

<span class="nv">SecondVendingMachinePid</span> <span class="o">=</span> <span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_initial_placed_actor</span><span class="p">(</span>
      <span class="n">class_SodaVendingMachine</span><span class="p">,</span> <span class="p">[</span> <span class="s">&quot;My second machine&quot;</span><span class="p">,</span>
        <span class="p">_</span><span class="nv">SecondCanCount</span><span class="o">=</span><span class="mi">0</span> <span class="p">],</span>
      <span class="nv">LoadBalancerPid</span><span class="p">,</span> <span class="n">my_placement_hint_a</span> <span class="p">),</span>
<span class="p">...</span>
<span class="nv">ThirdVendingMachinePid</span> <span class="o">=</span> <span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_initial_actor</span><span class="p">(</span>
      <span class="n">class_SodaVendingMachine</span><span class="p">,</span> <span class="p">[</span> <span class="s">&quot;My third machine&quot;</span><span class="p">,</span>
        <span class="p">_</span><span class="nv">ThirdCanCount</span><span class="o">=</span><span class="mi">8</span> <span class="p">],</span>
      <span class="nv">LoadBalancerPid</span><span class="p">,</span> <span class="n">my_placement_hint_b</span> <span class="p">),</span>
<span class="p">...</span>
<span class="c">% Now simulation can be started.</span>
</pre>
<p>In a centralised version, placement hints are simply ignored.</p>
<p>Full examples can be found in <tt class="docutils literal">scheduling_initial_placement_hint_test.erl</tt>.</p>
</div>
</div>
<div class="section" id="simulation-time-actors">
<h3>Simulation-Time Actors</h3>
<p>These actors are created in the course of the simulation.</p>
<p>Such actors can <em>only</em> be created by other (pre-existing) actors, otherwise the uncoupling of real time and simulated times would be jeopardised. Thus once the simulation is started it is the only way of introducing new actors.</p>
<p>As before, actors can be created with or without placement hints.</p>
<div class="section" id="id125">
<h4>With Agnostic Actor Placement</h4>
<p>An actor A needing to create another one (B) should use the <tt class="docutils literal">class_Actor:create_actor/3</tt> helper function.</p>
<p>For example:</p>
<pre class="code erlang literal-block">
<span class="p">...</span>
<span class="nv">CreatedState</span> <span class="o">=</span> <span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_actor</span><span class="p">(</span>
       <span class="p">_</span><span class="nv">CreatedClassname</span><span class="o">=</span><span class="n">class_PinkFlamingo</span><span class="p">,</span>
       <span class="p">[_</span><span class="nv">Name</span><span class="o">=</span><span class="s">&quot;Ringo&quot;</span><span class="p">,_</span><span class="nv">Age</span><span class="o">=</span><span class="mi">34</span><span class="p">],</span> <span class="nv">CurrentState</span> <span class="p">),</span>
<span class="p">...</span>
</pre>
<p>If actor A calls this function at a simulation timestamp {T,D}, then B will be created at the next diasca (hence at {T,D+1}) and A will be notified of it at {T,D+2}.</p>
<p>Indeed the load balancer will process the underlying actor creation message (which is an actor oneway) at {T,D+1} and will create immediately actor B, whose PID will be notified to A thanks to another actor oneway, <tt class="docutils literal">onActorCreated/5</tt>, sent on the same diasca. This message will then be processed by A at {T,D+2}, for example:</p>
<pre class="code erlang literal-block">
<span class="nf">onActorCreated</span><span class="p">(</span> <span class="nv">State</span><span class="p">,</span> <span class="nv">CreatedActorPid</span><span class="p">,</span>
               <span class="nv">ActorClassName</span><span class="o">=</span><span class="n">class_PinkFlamingo</span><span class="p">,</span>
               <span class="nv">ActorConstructionParameters</span><span class="o">=</span><span class="p">[</span> <span class="s">&quot;Ringo&quot;</span><span class="p">,</span> <span class="mi">34</span> <span class="p">],</span>
               <span class="nv">LoadBalancerPid</span> <span class="p">)</span> <span class="o">-&gt;</span>
<span class="c">% Of course this oneway is usually overridden, at least
% to record the PID of the created actor and/or to start
% interacting with it.</span>
</pre>
</div>
<div class="section" id="id126">
<h4>Based On A Placement Hint</h4>
<p>An actor A needing to create another one (B) while specifying a placement hint should simply use the <tt class="docutils literal">class_Actor:create_placed_actor/4</tt> helper function for that.</p>
<p>Then the creation will transparently be done according to the placement hint, and the <tt class="docutils literal">onActorCreated/5</tt> actor oneway will be triggered back on the side of the actor which requested this creation, exactly as in the case with no placement hint.</p>
</div>
</div>
</div>
<div class="section" id="how-constructors-of-actors-are-to-be-defined">
<h2><a class="toc-backref" href="#id234">How Constructors of Actors Are To Be Defined?</a></h2>
<p>Actor classes are to be defined like any WOOPER classes (of course they have to inherit, directly or not, from <tt class="docutils literal">class_Actor</tt>), except that their first construction parameter must be their actor settings.</p>
<p>These settings (which include the actor's AAI, for <em>Abstract Actor Identifier</em>) will be specified automatically by the engine, and should be seen as opaque information just to be transmitted as it is to the parent constructor(s).</p>
<p>All other parameters (if any) are call <em>actual parameters</em>.</p>
<p>For example, a <tt class="docutils literal">Foo</tt> class may define a constructor as:</p>
<pre class="code erlang literal-block">
<span class="p">-</span><span class="ni">spec</span> <span class="n">construct</span><span class="p">(</span><span class="nn">wooper</span><span class="p">:</span><span class="nf">state</span><span class="p">(),</span><span class="n">actor_settings</span><span class="p">(),</span><span class="nv">T1</span><span class="p">(),</span> <span class="nv">T2</span><span class="p">())</span> <span class="o">-&gt;</span>
           <span class="nn">wooper</span><span class="p">:</span><span class="nf">state</span><span class="p">().</span>
<span class="nf">construct</span><span class="p">(</span><span class="nv">State</span><span class="p">,</span><span class="nv">ActorSettings</span><span class="p">,</span><span class="nv">FirstParameter</span><span class="p">,</span><span class="nv">SecondParameter</span><span class="p">)</span> <span class="o">-&gt;</span>
   <span class="p">[...]</span>
</pre>
<p>Or course, should this class take no specific actual construction parameter, we would have had:</p>
<pre class="code erlang literal-block">
<span class="p">-</span><span class="ni">spec</span> <span class="n">construct</span><span class="p">(</span><span class="nn">wooper</span><span class="p">:</span><span class="nf">state</span><span class="p">(),</span><span class="n">actor_settings</span><span class="p">())</span> <span class="o">-&gt;</span> <span class="nn">wooper</span><span class="p">:</span><span class="nf">state</span><span class="p">().</span>
<span class="nf">construct</span><span class="p">(</span><span class="nv">State</span><span class="p">,</span><span class="nv">ActorSettings</span><span class="p">)</span> <span class="o">-&gt;</span>
   <span class="p">[...]</span>
</pre>
<p>The creation of an instance will require all actual parameters to be specified by the caller (since the actor settings will be determined and assigned by the simulation engine itself).</p>
<p>For example:</p>
<pre class="code erlang literal-block">
<span class="p">...</span>
<span class="nv">MyFooPid</span> <span class="o">=</span> <span class="nn">class_Actor</span><span class="p">:</span><span class="nf">create_initial_actor</span><span class="p">(</span> <span class="n">class_Foo</span><span class="p">,</span>
   <span class="p">[</span> <span class="nv">MyFirstParameter</span><span class="p">,</span> <span class="nv">MySecondParameter</span><span class="p">]</span> <span class="p">),</span>
<span class="c">% Actor settings will be automatically added at creation-time
% by the engine.</span>
</pre>
<p>For a complete example, see <tt class="docutils literal">class_TestActor.erl</tt>.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">No message of any sort shall be sent by an actor to another one from its constructoir; see <a class="reference internal" href="#common-pitfalls">Common Pitfalls</a> for more information.</p>
</div>
</div>
<div class="section" id="how-actors-can-define-their-spontaneous-behaviour">
<h2><a class="toc-backref" href="#id235">How Actors Can Define Their Spontaneous Behaviour?</a></h2>
<p>They just have to override the default implementation of the <tt class="docutils literal">class_Actor:actSpontaneous/1</tt> oneway.</p>
<p>The simplest of all spontaneous behaviour is to do nothing at all:</p>
<pre class="code erlang literal-block">
<span class="nf">actSpontaneous</span><span class="p">(</span><span class="nv">State</span><span class="p">)</span> <span class="o">-&gt;</span>
   <span class="nv">State</span><span class="p">.</span>
</pre>
<p>For a complete example, see <tt class="docutils literal">class_TestActor.erl</tt>.</p>
</div>
<div class="section" id="how-actors-are-to-interact">
<h2><a class="toc-backref" href="#id236">How Actors Are To Interact?</a></h2>
<p>Actors must <em>only</em> interact based on <tt class="docutils literal">actor messages</tt> (ex: using directly Erlang messages or WOOPER ones is <em>not</em> allowed), as otherwise even essential simulation properties could not be preserved.</p>
<p>Thus the <tt class="docutils literal">class_Actor:send_actor_message/3</tt> helper function should be used for each and every inter-actor communication (see the function header for a detailed usage information).</p>
<p>As a consequence, only actor oneways are to be used, and if an actor A sends an actor message to an actor B at simulation timestamp <tt class="docutils literal">{T,D}</tt>, then B will process it at tick <tt class="docutils literal">{T,D+1}</tt>, i.e. at the next diasca (that will be automatically scheduled).</p>
<p>Requests, i.e. a message sent from an actor A to an actor B (the question), to be followed by a message being sent back from B to A (the answer), must be implemented based on a round-trip exchange of two actor oneways, one in each direction.</p>
<p>For example, if actor A wants to know the color of actor B, then:</p>
<ul class="simple">
<li>first at tick T, diasca D, actor A sends an actor message to B, ex: <tt class="docutils literal">SentState = class_Actor:send_actor_message( PidOfB, getColor, CurrentState ), ...</tt> (probably from its <tt class="docutils literal">actSpontaneous/1</tt> oneway)</li>
<li>then, at diasca D+1, the <tt class="docutils literal">getColor(State,SenderPid)</tt> oneway of actor B is triggered, in the body of which B should send, as an answer, a second actor message, back to A: <tt class="docutils literal">AnswerState = class_Actor:send_actor_message(SenderPid, {beNotifiedOfColor,red}, CurrentState)</tt>; here <tt class="docutils literal">SenderPid</tt> corresponds to the PID of A and we suppose that the specification requires the answer to be sent immediately by B (as opposed to a deferred answer that would have to be sent after a duration corresponding to some number of ticks)</li>
<li>then at diasca D+2 actor A processes this answer: its <tt class="docutils literal">beNotifiedOfColor( State, Color, SenderPid )</tt> oneway is called, and it can react appropriately; here <tt class="docutils literal">Color</tt> could be <tt class="docutils literal">red</tt>, and <tt class="docutils literal">SenderPid</tt> corresponds to the PID of B</li>
</ul>
<p>Finally, the only licit case involving the direct use of a WOOPER request (instead of an exchange of actor messages) in Sim-Diasca occurs before the simulation is started.</p>
<p>This is useful typically whenever the simulation case needs to interact with some initial actors <a class="footnote-reference" href="#id128" id="id127">[48]</a> or when two initial actors have to communicate, in both cases <em>before</em> the simulation is started.</p>
<table class="docutils footnote" frame="void" id="id128" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id127">[48]</a></td><td>For example requests can be used to set up the connectivity between initial actors, i.e. to specify which actor shall be aware of which, i.e. shall know its PID.</td></tr>
</tbody>
</table>
</div>
<div class="section" id="how-actor-oneways-shall-be-defined">
<h2><a class="toc-backref" href="#id237">How Actor Oneways Shall be Defined?</a></h2>
<p>An actor oneway being a special case of a WOOPER oneway, it behaves mostly the same (ex: it is to return a state, and no result shall be expected from it) but, for clarity, it is to rely on its own type specifications and method terminators.</p>
<p>In terms of <em>type specification</em>, an actor oneway shall use:</p>
<ul class="simple">
<li>either, if being a const actor oneway: <tt class="docutils literal">actor_oneway_return/0</tt></li>
<li>otherwise (non-const actor oneway): <tt class="docutils literal">const_actor_oneway_return/0</tt></li>
</ul>
<p>In terms of <em>implementation</em>, similarly, each of its clauses, shall use:</p>
<ul class="simple">
<li>either, if being a const clause: <tt class="docutils literal">actor:const_return/0</tt></li>
<li>otherwise (non-const clause): <tt class="docutils literal">actor:return_state/1</tt></li>
</ul>
<p>As an example:</p>
<pre class="code erlang literal-block">
<span class="c">% This actor oneway is not const, as not all its clauses are const:
</span><span class="p">-</span><span class="ni">spec</span> <span class="n">notifySomeEvent</span><span class="p">(</span><span class="nn">wooper</span><span class="p">:</span><span class="nf">state</span><span class="p">(),</span><span class="n">a_type</span><span class="p">(),</span><span class="n">other_type</span><span class="p">(),</span>
                      <span class="n">sending_actor_pid</span><span class="p">())</span> <span class="o">-&gt;</span> <span class="n">actor_oneway_return</span><span class="p">().</span>
<span class="c">% A non-const clause to handle fire-related events:
</span><span class="nf">notifySomeEvent</span><span class="p">(</span><span class="nv">State</span><span class="p">,_</span><span class="nv">FirstValue</span><span class="o">=</span><span class="n">fire_event</span><span class="p">,</span><span class="nv">SecondValue</span><span class="p">,_</span><span class="nv">SendingActorPid</span><span class="p">)</span> <span class="o">-&gt;</span>
    <span class="p">[...]</span>
    <span class="nn">actor</span><span class="p">:</span><span class="nf">return_state</span><span class="p">(</span><span class="nv">SomeFireState</span><span class="p">);</span>

<span class="c">% A const clause to handle other events (through side-effects only):
</span><span class="nf">notifySomeEvent</span><span class="p">(</span><span class="nv">State</span><span class="p">,_</span><span class="nv">FirstValue</span><span class="p">,_</span><span class="nv">SecondValue</span><span class="p">,_</span><span class="nv">SendingActorPid</span><span class="p">)</span> <span class="o">-&gt;</span>
    <span class="p">[...]</span>
    <span class="nn">actor</span><span class="p">:</span><span class="nf">const_return_state</span><span class="p">().</span>
</pre>
<p>Note that we also recommend to follow the conventions used above regarding the typing of the last parameter (<tt class="docutils literal">sending_actor_pid()</tt>) and the name of its (often muted) associated value (<tt class="docutils literal">SendingActorPid</tt>).</p>
</div>
<div class="section" id="how-to-handle-actors-needing-to-exchange-a-larger-volume-of-data">
<h2><a class="toc-backref" href="#id238">How to Handle Actors Needing to Exchange a Larger Volume of Data?</a></h2>
<p>First of all, such Erlang terms shall be made as compact as possible: data duplication shall be avoided, identifiers (such as atoms or integers) shall be used to designate elements rather than copying them, plain strings shall be replaced with binary ones, more compact compounding types (e.g. tuples instead of maps) shall be preferred, etc.</p>
<p>Is the data static and can be defined either at build-time or at runtime, when starting the simulator? Then Myriad's &quot;const&quot; facilities (e.g. <tt class="docutils literal">const_table</tt>, <tt class="docutils literal">const_bijective_table</tt>, <tt class="docutils literal">const_bijective_topics</tt>) may be of help; also, static or infrequently-changing data may be handled thanks to the Erlang <tt class="docutils literal">persistent_term</tt> module.</p>
<p>If the data is dynamic, yet is identical for many actors, <tt class="docutils literal">class_DataExchanger</tt> may then be of help.</p>
<p>Finally, having larger, dynamic, specific (per-actor) data to be exchanged is not necessarily a problem in a distributed context: they should just be co-allocated (that is: instantiated on the same Erlang node, and thus host) by specifying the same placement hint when creating them.</p>
<p>See also the next section for more specific communication solutions.</p>
</div>
<div class="section" id="how-to-handle-less-classical-communication-schemes">
<h2><a class="toc-backref" href="#id239">How to Handle Less Classical Communication Schemes?</a></h2>
<p>While oneway messages constitute a universal paradigm in order to communicate inside the simulation (hence between actors), in a case where one-to-many communication is to occur, relying on a standard actor or even a set thereof (ex: as a pool to even the load, or as for example a 3D environment split into a binary space partitioning scheme, with one actor per cell) may be suboptimal.</p>
<p>Should the same message have to be sent from one actor to many, one may have a look to <tt class="docutils literal">class_BroadcastingActor</tt>, a specialised actor designed for that use case.</p>
<p>Also, using the data-exchanger service (see <tt class="docutils literal">class_DataExchanger</tt>) may be of help, keeping in mind that this is a data-management service (not a specific kind of actor) that is updated between diascas.</p>
<p>As for communication that is “pure result” (produced by an actor, but not read by any of them), data may be sent immediately out of the simulation, either directly (as fire and forget), or with some flow control (should there be a risk that the simulation overwhelms the targeted data sink).</p>
</div>
<div class="section" id="how-actors-are-to-be-deleted">
<h2><a class="toc-backref" href="#id240">How Actors Are To Be Deleted?</a></h2>
<p>Actors are to be deleted either in the course of the simulation or after the simulation is over.</p>
<p>In all cases their deletion must be managed through the simulation engine, not directly by the user (ex: sending  WOOPER <tt class="docutils literal">delete</tt> messages is <em>not</em> allowed), as otherwise even essential simulation properties could not be preserved.</p>
<p>The recommended way of deleting an actor is to have it trigger its own deletion process. Indeed this requires at least that actor to notify all other actors that may interact with it that this should not happen anymore.</p>
<p>Once they are notified, this actor (possibly on the same tick at which it sent these notifications) should execute its <tt class="docutils literal"><span class="pre">declareTermination/{1,2}</span></tt> oneway (or the <tt class="docutils literal"><span class="pre">class_Actor:declare_termination/{1,2}</span></tt> helper function), for example from  <tt class="docutils literal">actSpontaneous/1</tt>:</p>
<pre class="code erlang literal-block">
<span class="p">...</span>
<span class="nv">TerminatingState</span> <span class="o">=</span> <span class="n">executeOneway</span><span class="p">(</span> <span class="nv">CurrentState</span><span class="p">,</span>  <span class="n">declareTermination</span><span class="p">),</span>
<span class="p">...</span>
</pre>
<p>See <tt class="docutils literal">class_TestActor.erl</tt> for an example of complex yet proper coordinated termination, when a terminating actor knows other actors and is known by other actors.</p>
<p>See also the <tt class="docutils literal"><span class="pre">Sim-Diasca</span> Developer Guide</tt>.</p>
</div>
<div class="section" id="how-requests-should-be-managed-from-a-simulation-case">
<h2><a class="toc-backref" href="#id241">How Requests Should Be Managed From A Simulation Case?</a></h2>
<p>As already explained, direct WOOPER calls should not be used to modify the state of the simulation once it has been started, as we have to let the simulation layer have full control over the exchanges, notably so that they can be reordered.</p>
<p>However requests can be used <em>before</em> the simulation is started.</p>
<p>For example we may want to know, from the simulation case, what the initial time will be, like in:</p>
<pre class="code erlang literal-block">
<span class="nv">TimeManagerPid</span> <span class="o">!</span> <span class="p">{</span><span class="n">getTextualTimings</span><span class="p">,[],</span><span class="n">self</span><span class="p">()},</span>
<span class="k">receive</span>

   <span class="p">{</span><span class="n">wooper_result</span><span class="p">,</span><span class="nv">TimingString</span><span class="p">}</span> <span class="k">when</span> <span class="nb">is_list</span><span class="p">(</span><span class="nv">TimingString</span><span class="p">)</span> <span class="o">-&gt;</span>
       <span class="o">?</span><span class="n">test_info_fmt</span><span class="p">(</span><span class="s">&quot;Initial time is </span><span class="si">~s</span><span class="s">.&quot;</span><span class="p">,[</span><span class="nv">TimingString</span><span class="p">])</span>

<span class="k">end</span><span class="p">,</span>
<span class="p">...</span>
</pre>
<p>The <tt class="docutils literal">is_list/1</tt> guard would be mandatory here, as other messages may spontaneously be sent to the simulation case <a class="footnote-reference" href="#id130" id="id129">[49]</a>.</p>
<table class="docutils footnote" frame="void" id="id130" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id129">[49]</a></td><td>Typically the trace supervisor will send <tt class="docutils literal">{wooper_result,monitor_ok}</tt> messages to the simulation case whenever the user closes the window of the trace supervision tool, which can happen at any time: without the guard, we could then have  <tt class="docutils literal">TimingString</tt> be unfortunately bound to <tt class="docutils literal">monitor_ok</tt>, instead of the expected timing string returned by the <tt class="docutils literal">getTextualTimings</tt> request.</td></tr>
</tbody>
</table>
<p>However, specifying, at each request call issued from the simulation case, a proper guard is tedious and error-prone, so a dedicated, safe function is provided for that by the engine, <tt class="docutils literal">test_receive/0</tt>; thus the previous example should be written that way instead:</p>
<pre class="code erlang literal-block">
<span class="nv">TimeManagerPid</span> <span class="o">!</span> <span class="p">{</span><span class="n">getTextualTimings</span><span class="p">,[],</span><span class="n">self</span><span class="p">()},</span>
<span class="nv">TimingString</span> <span class="o">=</span> <span class="n">test_receive</span><span class="p">(),</span>
<span class="o">?</span><span class="n">test_info_fmt</span><span class="p">(</span><span class="s">&quot;Received time: </span><span class="si">~s</span><span class="s">.&quot;</span><span class="p">,[</span><span class="nv">TimingString</span><span class="p">]),</span>
<span class="p">...</span>
</pre>
<p>This <tt class="docutils literal">test_receive/0</tt> function performs a (blocking) selective receive, retrieving any WOOPER result which is <em>not</em> emanating directly from the operation of the engine itself. That way, developers of simulation cases can reliably retrieve the values returned by the requests they send, with no fear of interference.</p>
</div>
<div class="section" id="how-should-i-run-larger-simulations">
<h2><a class="toc-backref" href="#id242">How Should I run larger simulations?</a></h2>
<p>Larger simulations are more difficult to run, notably because they are generally distributed and because they tend to exhaust various resources.</p>
<div class="section" id="testing-in-a-simple-case">
<h3>Testing in a Simple Case</h3>
<p>A good first step is to ensure that, in the target hardware and software setting, the intended simulation is already able to run in a small scale from begin to end, first on a single host then, if targeted, on an increasing number of hosts (see the <a class="reference internal" href="#distributed-gotchas">distributed gotchas</a> for that).</p>
<p>Ensure that only the safest choices are made (e.g. have a properly-configured DNS, fix permissions, rely on a normal user - not root, etc.). Investigate any network-related issue with <a class="reference external" href="https://olivier-boudeville.github.io/Ceylan-Myriad/#testing-troubleshooting">such checkings</a>.</p>
</div>
<div class="section" id="enabling-the-production-execution-target">
<h3>Enabling the <tt class="docutils literal">production</tt> Execution Target</h3>
<p>If, for a given simulation, more than a few nodes are needed, then various preventive measures shall be taken in order to be ready to go to further scales (typically disabling most <a class="reference internal" href="#simulation-traces">simulation traces</a>, extending key time-outs, etc.).</p>
<p>For that the <tt class="docutils literal">EXECUTION_TARGET</tt> compile-time overall flag has been defined. Its default value is <tt class="docutils literal">development</tt> (simulations will not be really scalable, but a good troubleshooting support will be provided), but if you set it to <tt class="docutils literal">production</tt>, then all settings for larger simulations will be applied.</p>
<p>It is a compile-time option, hence it must be applied when building Sim-Diasca and the layers above; thus one may run, from the root:</p>
<pre class="code bash literal-block">
$ make clean all <span class="nv">EXECUTION_TARGET</span><span class="o">=</span>production
</pre>
<p>to prepare for any demanding run.</p>
<p>One may instead set <tt class="docutils literal">EXECUTION_TARGET=production</tt> once for all, typically in <tt class="docutils literal">myriad/GNUmakevars.inc</tt>, however most users prefer to go back and forth between the execution target settings (as traces, shorter time-outs etc. are very useful for developing and troubleshooting), using the command-line to switch.</p>
<p>It is even possible to compile everything in production mode, touch the source files that one wants to be still talkative (<tt class="docutils literal">touch some_module.erl</tt>) and run just <tt class="docutils literal">make all</tt> for the root: all touched module (and only them) will be then recompiled with the default execution target, by default the <tt class="docutils literal">development</tt> one.</p>
</div>
<div class="section" id="circumventing-any-system-limit">
<h3>Circumventing any System Limit</h3>
<p>Many GNU/Linux operating systems enforce various limits onto the resources that one application may use (RAM, file descriptors, cores, etc.).</p>
<p>Notably, UNIX processes that are considered using &quot;too much&quot; RAM might be killed by the operating system far before exhausting this memory.</p>
<p>The <tt class="docutils literal">ulimit</tt> command and the configuration of the Linux kernel capabilities may be of interest then.</p>
<p>Containerization / OS-level virtualization (e.g. Docker, Singularity) may also have an impact.</p>
</div>
<div class="section" id="increasing-the-maximum-number-of-erlang-processes">
<h3>Increasing the Maximum Number of Erlang Processes</h3>
<p>The Erlang default limit is only 32768 processes, but Sim-Diasca relies on the <tt class="docutils literal"><span class="pre">myriad/src/scripts/launch-erl.sh</span></tt> script to launch its user VM, and this script enforces a larger limit (of a few thousands; refer to its <tt class="docutils literal">max_process_count</tt> variable).</p>
<p>One may set the <tt class="docutils literal">MAX_PROCESS_COUNT</tt> make variable (defined in <tt class="docutils literal">myriad/GNUmakevars.inc</tt>) to set that process limit to any value of interest.</p>
</div>
<div class="section" id="selecting-whether-any-file-based-creation-of-initial-actors-shall-be-concurrent">
<h3>Selecting Whether any File-based Creation of Initial Actors shall be Concurrent</h3>
<p>Currently, by default the <tt class="docutils literal">simdiasca_allow_reproducible_nested_initial_creations</tt> token is defined (see the <tt class="docutils literal">SIM_DIASCA_SETTINGS_FLAGS</tt> make variable in <tt class="docutils literal"><span class="pre">sim-diasca/GNUmakevars.inc</span></tt>), and thus the creation of the initial actors from an initialisation file is done by a single process.</p>
<p>This allows the nested creations (creating an initial actor from the constructor of another one) to be fully reproducible, including regarding the allocation of the AAI of these actors.</p>
<p>However, if not relying on such nested creations, or if totally-reproducible initial AAIs are not necessary, then it may useful to <em>not</em> define that token in one's settings; a pool of actor creators will then be spawned (one per core of the user host), resulting in a considerable speed-up of the initialisation of larger file-based simulations.</p>
</div>
<div class="section" id="monitoring-resources">
<h3>Monitoring Resources</h3>
<p>Any tool to track resource usage (at least CPU, RAM, swap) on the target host(s), at the level of the operating system will certainly be of use.</p>
<p>Regarding Erlang itself (notably its VM), the <tt class="docutils literal">observer</tt> application provides also invaluable runtime information.</p>
</div>
<div class="section" id="monitoring-traces-and-logs">
<h3>Monitoring Traces and Logs</h3>
<p>The Sim-Diasca traces are an invaluable means of tracking the course of a given simulation; error-like severities will always be enabled (even in production mode).</p>
<p>In case of a runtime problem, one should investigate also the main log files of the operating system (typically thanks to <tt class="docutils literal">journalctl</tt>), as many events can happen (OOM - <em>Out of Memory</em>, the Sim-Diasca main process being killed process due to some limit being reached, a container enforcing some constraint, etc.).</p>
<p></p>
</div>
</div>
</div>
<div class="section" id="sim-diasca-troubleshooting">
<h1><a class="toc-backref" href="#id243">Sim-Diasca Troubleshooting</a></h1>
<div class="section" id="first-of-all-did-you-read-the-manuals">
<h2><a class="toc-backref" href="#id244">First Of All: Did You Read The Manuals?</a></h2>
<p><span class="raw-html"><center><img src="xkcd-rtfm.png" id="responsive-image-reduced"></img></center></span>
</p>
<p>Besides this document, a Sim-Diasca user should definitively read the <em>Sim-Diasca Developer Guide</em>, which is freely available as well. We are not providing <tt class="docutils literal">man</tt> pages yet.</p>
</div>
<div class="section" id="troubleshooting-principles">
<h2><a class="toc-backref" href="#id245">Troubleshooting Principles</a></h2>
<p>First at all, everything is done so that:</p>
<ul class="simple">
<li>the simulation crashes as soon as a problem occurs (in the engine, in the models and/or in the simulation case), so that there is not silent error</li>
<li>in debug mode, many additional runtime checkings are performed (ex: with regard to actor scheduling, termination, etc.)</li>
</ul>
<p>As a consequence, models in development will crash early and often, and the diagnosis should be quite easy to obtain, thanks to the detailed crash information being given.</p>
<p>Each actor having its own sequential stream of instructions, sharing no data, relying only on its state variable and not having any pointer, exchanging only messages according to well-defined procedures should help a lot the debugging.</p>
<p>So, unlike other approaches like this one:</p>
<p><span class="raw-html"><center><img src="xkcd-compiler_complaint.png" id="responsive-image-large"></img></center></span>
</p>
<p>this is a normal and easy process for the model developer to iterate simulation runs again and again (<em>let is crash</em> belongs to the Erlang principles), until having complete and correct models.</p>
<p>Of course, the fact that a model does not crash does not necessarily imply it respects its intended behaviour: it is of course part of the work of the model developer to check their implementation against their specification.</p>
</div>
<div class="section" id="most-common-issues">
<h2><a class="toc-backref" href="#id246">Most Common Issues</a></h2>
<p>The most common errors encountered that are not self-explanatory (please have a careful look at the console outputs and, should it be not sufficient, read thoroughly the simulation traces) while using Sim-Diasca are explained and solved here.</p>
<p>They are roughly sorted by chronological order of potential appearance.</p>
<p><span class="raw-html"><center><img src="xkcd-computer_problems.png" id="responsive-image-medium"></img></center></span>
</p>
<div class="section" id="issue-1-undefined-parse-transform-myriad-parse-transform">
<h3><strong>Issue #1</strong>: <tt class="docutils literal">undefined parse transform 'myriad_parse_transform'</tt></h3>
<p>When a build recipe fails that way, this usually means that one attempted to compile elements of a layer depending on the <tt class="docutils literal">Myriad</tt> layer whereas this latter layer is itself not already compiled. One should preferably run <tt class="docutils literal">make</tt> from the root, to ensure that the full code-base is rebuilt (layers will then be compiled in a relevant order).</p>
<p>Why is it so? Because a parse-transform (Erlang code modifying how Erlang code is compiled) defined in the <tt class="docutils literal">Myriad</tt> layer is necessary to compile most of the BEAM files of all layers, hence it must be available prior to any of these builds.</p>
</div>
<div class="section" id="issue-2-protocol-register-error">
<h3><strong>Issue #2</strong>: <tt class="docutils literal">Protocol: register error</tt></h3>
<p>If running a simulation and being notified of a strange error like:</p>
<pre class="code erlang literal-block">
<span class="p">{</span><span class="n">error_logger</span><span class="p">,{{</span><span class="mi">2008</span><span class="p">,</span><span class="mi">11</span><span class="p">,</span><span class="mi">25</span><span class="p">},{</span><span class="mi">15</span><span class="p">,</span><span class="mi">25</span><span class="p">,</span><span class="mi">6</span><span class="p">}},</span> <span class="s">&quot;Protocol: </span><span class="si">~p</span><span class="s">: register
error: </span><span class="si">~p~n</span><span class="s">&quot;</span><span class="p">,</span> <span class="p">[</span><span class="s">&quot;inet_tcp&quot;</span><span class="p">,{{</span><span class="n">badmatch</span><span class="p">,{</span><span class="n">error</span><span class="p">,</span><span class="n">duplicate_name</span><span class="p">}},</span>
<span class="p">[{</span><span class="n">inet_tcp_dist</span><span class="p">,</span><span class="n">listen</span><span class="p">,</span><span class="mi">1</span><span class="p">},{</span><span class="n">net_kernel</span><span class="p">,</span><span class="n">start_protos</span><span class="p">,</span><span class="mi">4</span><span class="p">},</span>
<span class="p">{</span><span class="n">net_kernel</span><span class="p">,</span><span class="n">start_protos</span><span class="p">,</span><span class="mi">3</span><span class="p">},{</span><span class="n">net_kernel</span><span class="p">,</span><span class="n">init_node</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span>
<span class="p">{</span><span class="n">net_kernel</span><span class="p">,</span><span class="n">init</span><span class="p">,</span><span class="mi">1</span><span class="p">},{</span><span class="n">gen_server</span><span class="p">,</span><span class="n">init_it</span><span class="p">,</span><span class="mi">6</span><span class="p">},</span> <span class="p">{</span><span class="n">proc_lib</span><span class="p">,</span><span class="n">init_p</span><span class="p">,</span><span class="mi">5</span><span class="p">}]}]}</span>
<span class="p">[...]</span>
</pre>
<p>then it is the symptom that a similarly-named Erlang virtual machine is already running on the same host. Either it is an idle forgotten simulation still opened on another terminal <a class="footnote-reference" href="#id132" id="id131">[50]</a> (in that case shutting down the corresponding virtual machine will correct the situation), or the user really wants to have two instances of the same simulation run simultaneously. In that case, the two virtual machines should be named differently, knowing that, with the default Sim-Diasca Make rules, the launched virtual machines are named according to the case that is run. For example, to run the simulation case defined in <tt class="docutils literal">simulationAndScenario_test.erl</tt> from the host <tt class="docutils literal">myhost.foobar.org</tt>, one may just issue <tt class="docutils literal">make simulationAndScenario_run</tt>. The corresponding Erlang virtual machine will be then named <tt class="docutils literal">simulationAndScenario_run&#64;myhost.foobar.org</tt>.</p>
<table class="docutils footnote" frame="void" id="id132" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id131">[50]</a></td><td><p class="first">This can happen if for example you issued <tt class="docutils literal"><span class="pre">CTRL-Z</span></tt> then put that task in the background (<tt class="docutils literal">bg</tt>) and forgot that it was still running.</p>
<p class="last">Note that Sim-Diasca includes various mechanisms to ensure that no two runs can silently interfere by mistake (ex: using UUID-based cookies, uniquely named directories according to case, user and a generated identifier, etc.).</p>
</td></tr>
</tbody>
</table>
</div>
<div class="section" id="issue-3-can-t-set-long-node-name-please-check-your-configuration">
<h3><strong>Issue #3</strong>: <tt class="docutils literal">Can't set long node name! Please check your configuration</tt></h3>
<p>Such a problem may be reproduced simply by running on a given host:</p>
<pre class="code bash literal-block">
$ erl -name my_test
</pre>
<p>Instead of running the expected VM, like in:</p>
<pre class="code erlang literal-block">
<span class="nv">Erlang</span><span class="o">/</span><span class="nv">OTP</span> <span class="mi">21</span> <span class="p">[</span><span class="n">erts</span><span class="o">-</span><span class="mi">10</span><span class="p">.</span><span class="mi">3</span><span class="p">]</span> <span class="p">[</span><span class="n">source</span><span class="p">]</span> <span class="p">[</span><span class="mi">64</span><span class="o">-</span><span class="n">bit</span><span class="p">]</span> <span class="p">[...]</span>

<span class="nv">Eshell</span> <span class="nv">V10</span><span class="p">.</span><span class="mi">3</span>  <span class="p">(</span><span class="n">abort</span> <span class="n">with</span> <span class="err">^</span><span class="nv">G</span><span class="p">)</span>
<span class="p">(</span><span class="n">my_test</span><span class="p">&#64;</span><span class="n">hurricane</span><span class="p">.</span><span class="n">foobar</span><span class="p">.</span><span class="n">org</span><span class="p">)</span><span class="mi">1</span><span class="o">&gt;</span>
</pre>
<p>the VM launcher may report that no long node naming can be used.</p>
<p>This may happen whenever the network configuration of the local host is not consistent, at least from the point of view of the Erlang virtual machine. More specifically, it can happen if in the <tt class="docutils literal">/etc/hosts</tt> file the first name to appear for the local host is not the expected proper FQDN (<em>Fully-Qualified Domain Name</em>) and/or when the domain is not correctly specified.</p>
<p>For example, supposing that in <tt class="docutils literal">/etc/resolv.conf</tt> a domain is specified as <tt class="docutils literal">domain localdomain</tt> and that the local hostname is <tt class="docutils literal">foo</tt>, then a line in <tt class="docutils literal">/etc/hosts</tt> like:</p>
<pre class="code bash literal-block">
<span class="m">127</span>.0.0.1 localhost.localdomain localhost foo.bar.org foo
</pre>
<p>should be corrected into:</p>
<pre class="code bash literal-block">
<span class="m">127</span>.0.0.1 foo.bar.org foo localhost.localdomain localhost
</pre>
<p>Typically, one of the simplest <tt class="docutils literal">/etc/hosts</tt> could be in this context:</p>
<pre class="code bash literal-block">
<span class="m">127</span>.0.0.1 localhost.localdomain localhost
::1       localhost
<span class="m">127</span>.0.1.1 foo.localdomain foo
</pre>
<p>Ping your local host, use <tt class="docutils literal">hostname</tt>, <tt class="docutils literal">hostname <span class="pre">-f</span></tt> and/or <tt class="docutils literal">hostnamectl</tt> to check that the name resolution is correctly set. See also the related note about <tt class="docutils literal">Domain configuration</tt> in the <tt class="docutils literal"><span class="pre">Sim-Diasca</span> Installation Guide</tt>.</p>
<p>If you have for example a laptop making use of DHCP servers that assign over time different host/domain names and you find it impractical, you may reintroduce a stable naming (to be used at least by Sim-Diasca) by adding at the end of your <tt class="docutils literal">/etc/hosts</tt> a line like:</p>
<pre class="code bash literal-block">
<span class="m">127</span>.0.2.1 a_host_name.a_domain_name a_host_name
</pre>
<p>(where <tt class="docutils literal">a_host_name</tt> and <tt class="docutils literal">a_domain_name</tt> can be any network names of your choice)</p>
<p>Then, in <tt class="docutils literal">myriad/GNUmakevars.inc</tt>, the FQDN information shall be set statically, accordingly by editing the corresponding section with:</p>
<pre class="code bash literal-block">
FQDN :<span class="o">=</span> a_host_name.a_domain_name
</pre>
<p>(before <tt class="docutils literal">ifdef FQDN <span class="pre">[...]</span></tt>)</p>
</div>
<div class="section" id="issue-4-the-deployment-of-a-sim-diasca-module-apparently-failed">
<h3><strong>Issue #4</strong>: The Deployment of a Sim-Diasca Module apparently failed</h3>
<p>The corresponding symptom is an exception being thrown during deployment and including:</p>
<pre class="code erlang literal-block">
<span class="p">{</span><span class="n">module_deployment_failed</span><span class="p">,</span><span class="nv">SOME_MODULE</span><span class="p">,...</span>
</pre>
<p>This may happen when running distributed simulations whereas hostname resolution is somehow failing.</p>
<p>For example, we encountered sometimes faulty network configurations (ex: w.r.t. to a stale domain name) where a host contacted as <tt class="docutils literal">foo.bar.org</tt> was responding as <tt class="docutils literal">foo.other.org</tt>, and thus was never reported as available.</p>
<p>In other cases, a computing host was designated (either in a host file or directly in the simulation case) not, as expected, by its name (preferably FQDN) but, incorrectly, by its IP address (which is disallowed, see the <tt class="docutils literal">computing_hosts</tt> field of the <tt class="docutils literal">deployment_settings</tt> record).</p>
</div>
<div class="section" id="issue-5-execution-seems-to-be-blocked-right-after-having-been-triggered">
<h3><strong>Issue #5</strong>: Execution seems to be blocked right after having been triggered.</h3>
<p>This may happen (albeit now on very rare cases; or, possibly, never anymore) if using a virtualized environment (ex: VMWare or VirtualBox). Indeed there used to be, with some unspecified configurations, a general problem related to timers and message receiving, and apparently Sim-Diasca was not the culprit here (as unrelated applications were affected similarly). Erlang was maybe not guilty either, as possibly related issues were reported on the VMWare side.</p>
<p>Anyway, because of these problems and of the incurred performance penalty, <em>the use of virtualized environments should be avoided</em> here; at least one should develop and test one's simulation on a real hardware before considering running it in a virtualized form.</p>
<p>Another cause of a launched computing node not being found and resulting in a time-out might be an inconsistent name resolution (see issue #3).</p>
<p>For example, beware of specifying in <tt class="docutils literal">/etc/resolv.conf</tt> a wrong domain in the <tt class="docutils literal">domain</tt> entry (ex: <tt class="docutils literal">bar.org</tt> instead of <tt class="docutils literal">foo.org</tt>) . Otherwise your user node may try to reach <tt class="docutils literal">A_COMPUTING_NODE_NAME&#64;HOST.foo.org</tt> whereas this one will believe its own name actually is <tt class="docutils literal">A_COMPUTING_NODE_NAME&#64;HOST.bar.org</tt> and thus will not respond - leading to Sim-Diasca freezing at start-up before automatically timing-out. If in doubt and having the relevant permissions, one may comment-out the <tt class="docutils literal">domain</tt> information, at least for a first troubleshooting.</p>
</div>
<div class="section" id="issue-6-at-least-one-computing-node-times-out-because-it-did-not-receive-on-time-from-the-user-node-the-deployment-archive">
<h3><strong>Issue #6</strong>: At least one computing node times-out because it did not receive on time (from the user node) the deployment archive.</h3>
<p>The default deployment time-out is supposedly sufficient for most configuration settings.</p>
<p>If for example relying on very slow hard-disks and/or having defined extra simulation data to deploy whose size exceeds a few dozens megabytes, then maybe indeed you may need to increase your deployment time-out, at least for this simulation case.</p>
<p>For that, see the <tt class="docutils literal">maximum_allowed_deployment_duration</tt> field of the <tt class="docutils literal">deployment_settings</tt> record (defined in <tt class="docutils literal">class_DeploymentManager.hrl</tt>, in the <tt class="docutils literal"><span class="pre">sim-diasca/src/core/src/deployment</span></tt> directory).</p>
<p>Such larger simulation archives may also result from user-level errors. A typical mistake was to run the Erlang installation script <tt class="docutils literal"><span class="pre">install-erlang.sh</span></tt> directly from its location (in <tt class="docutils literal">myriad/conf</tt>): then the full build tree of Erlang/OTP could still reside in this latter directory. In this case, the deployment manager, when scanning the <tt class="docutils literal">Myriad</tt> package, would also detect the BEAM files of Erlang/OTP and include them in the simulation archive. Note that a specific checking has been since then introduced so that the specific case of a local build of the Erlang/OTP runtime should be correctly detected, but this issue may arise for other codebases as well.</p>
<p>Of course including such duplicated BEAMs (as they shall be already available on the computing hosts) is not desirable at all, and results in larger simulation packages bound to trigger a deployment time-out.</p>
<p>So: just remove then, from the overall Sim-Diasca codebase, all build trees that do not belong there!</p>
</div>
<div class="section" id="issue-7-at-start-up-the-rebuild-of-the-simulator-codebase-fails-although-the-code-is-correct">
<h3><strong>Issue #7</strong>: At start-up, the rebuild of the simulator codebase fails, although the code is correct.</h3>
<p>This may happen if at least one source file (ex: <tt class="docutils literal">myFile.erl</tt>) is being edited without having been saved yet: some editors then create a temporary file like <tt class="docutils literal">~myFile.erl</tt> or <tt class="docutils literal">.#myFile.erl</tt> in the same directory. The make system will try to rebuild that file, but the compilation will fail necessarily, as this filename will not match the module name. A proper error message should have been sent in the simulation traces.</p>
</div>
<div class="section" id="issue-8-a-noconnection-error-is-triggered-in-the-course-of-the-execution">
<h3><strong>Issue #8</strong>: A <tt class="docutils literal">noconnection</tt> error is triggered in the course of the execution.</h3>
<p>This usually means that at least one of the involved computing nodes unexpectedly crashed. The most likely reason is that its host was exceedingly loaded. This happens typically in the course of the creation of the initial actors: a too large simulation may then result on the exhaustion of the RAM (and, possibly, swap) of at least one computing host, crashing the whole simulation.</p>
<p>Solution: opt for a less demanding simulation and/or use more hosts, ensuring they have roughly the same level of free resources (knowing that the load balancer tends to even the resource demands across the available hosts).</p>
</div>
<div class="section" id="issue-9-apparently-my-newer-code-does-not-seem-to-be-taken-into-account">
<h3><strong>Issue #9</strong>: Apparently my newer code does not seem to be taken into account!</h3>
<p>More precisely, some changes to the source code have been made, yet the newer executions seem to correspond to the code that existed before the change rather than to the updated one. Or, more generally, the executed code does not seem to correspond to the specified one.</p>
<p>This could happen when multiple BEAM versions of the same module can be found from the deployment root. For example, from some subdirectory in the sources, one may have issued <tt class="docutils literal">cp <span class="pre">-r</span> foo_directory <span class="pre">foo_directory-hidden</span></tt>, to save temporarily its content while experimenting in-place in <tt class="docutils literal">foo_directory</tt>.</p>
<p>The problem is that the deployment manager will scan for all BEAMs from the deployment root, and include them in the deployment archive. As a result, on each computing node, any BEAM found in <tt class="docutils literal"><span class="pre">foo_directory-hidden</span></tt> will be deployed as well and, depending on the code path, <tt class="docutils literal"><span class="pre">foo_directory-hidden/a_module.beam</span></tt> may be found before <tt class="docutils literal">foo_directory/a_module.beam</tt> (unfortunately this tends to be often the case). As a consequence, the previous version of the code (the hidden one) would be wrongly executed.</p>
<p>The solution is to avoid to perform back-ups directly in the source tree (ex: use <tt class="docutils literal">git stash</tt>) or, at the very least, to copy them once all BEAMs have been removed, to avoid that they silently collide.</p>
<p>Another possible cause of not seeing a change when running Sim-Diasca (at least, not the first time it is then run) is to modify a source file without recompiling it afterwards: Sim-Diasca, during its deployment, will then recompile the whole (thus updating any BEAM file that requires it), yet the previous version of the BEAM may have already been loaded by the user node (and possibly sent over the network to other nodes). These changes would be visible only from the second run, not the first one. To avoid that, one should recompile a module when having modified it - anyway after a change we have to check that the module still compiles, isn't it?</p>
</div>
<div class="section" id="issue-10-my-simulation-seems-to-be-finished-however-it-does-not-return-to-the-shell-and-it-is-still-eating-a-lot-of-resources-for-quite-long-what-s-happening">
<h3><strong>Issue #10</strong>: My simulation seems to be finished, however it does not return to the shell, and it is still eating a lot of resources for quite long. What's happening?</h3>
<p>It may happen whenever a simulation is executed for a long time and/or with numerous actors, whereas the intensity of trace sendings has not been lowered: although all trace modes write down a trace directly as soon as possible once received, and none, except the PDF mode, incurs long processings at shutdown, nevertheless all trace modes can significantly delay this shutdown phase.</p>
<p>The reason is that the trace aggregation process (see <tt class="docutils literal">class_TraceAggregator</tt>) could not cope with the speed at which traces are sent by the various emitters, including actors. Thus traces accumulate in the aggregator mailbox, and time is needed for them to be formatted and flushed on disk. Sending too many traces regarding the aggregator speed should be avoided, as accumulating messages in the mailbox may result in a huge RAM consumption, delayed shutdown, and risk that a simulation crash happens whereas the corresponding traces are not written yet.</p>
</div>
<div class="section" id="issue-11-at-runtime-an-exception-like-unexpected-ack-from-apid-pidlist-atick-actorpid-is-thrown">
<h3><strong>Issue #11</strong>: At runtime, an exception like <tt class="docutils literal">{unexpected_ack_from,APid,PidList,ATick,ActorPid}</tt> is thrown.</h3>
<p>Although it looks as if the engine was faulty, the cause must lie in the code of the class corresponding to the instance <tt class="docutils literal">ActorPid</tt> refers to: most probably that an updated state was not taken into account into one of its methods, from where an actor message was sent (directly or not, like in the case of the creation of another actor) to the process corresponding to <tt class="docutils literal">APid</tt>.</p>
<p>Indeed an actor message must have been sent, returning an updated state tracking that sending, whereas a previous state, unaware of that sending, was instead returned to WOOPER by that method. Thus when that actor received the acknowledgement corresponding to the actor message it sent, it does not correspond to any recorded sending, leading to the <tt class="docutils literal">unexpected_ack_from</tt> exception to be triggered.</p>
</div>
<div class="section" id="issue-12-simulation-runs-but-is-slow">
<h3><strong>Issue #12</strong>: Simulation runs, but is slow.</h3>
<p>This is a difficult issue to tackle generically. Some slowness are more acceptable than others:</p>
<p><span class="raw-html"><center><img src="xkcd-long_light.png" id="responsive-image-medium"></img></center></span>
</p>
<p>Most efficient solutions to increase speed are:</p>
<ul class="simple">
<li>increase your computing resources (more nodes, more powerful, better network, etc.); check that you are never hitting the swap and, more generally, try to ensure that computing nodes stay well below a high load (performances in that case degrade swiftly)</li>
<li>make (a better) use of advanced scheduling (models seldom require all the same evaluation frequency)</li>
<li>selectively tune your models (ex: use <tt class="docutils literal">etop</tt> and the traces to spot the most-demanding ones)</li>
<li>switch to more &quot;exotic&quot; solutions, like native compilation or the use of <a class="reference external" href="http://erlang.org/doc/tutorial/nif.html">NIFs</a> (i.e. <em>Native Implemented Functions</em>)</li>
<li>ultimately, if at all possible, reduce your problem size</li>
<li>improve your algorithms (ex: choose better data-structures):</li>
</ul>
<p><span class="raw-html"><center><img src="xkcd-algorithms.png" id="responsive-image-medium"></img></center></span>
</p>
</div>
<div class="section" id="issue-13-simulation-seems-to-freeze-or-to-be-surprisingly-slow-or-more-generally-does-not-behave-as-expected-and-i-do-not-want-to-stick-io-format-calls-everywhere-to-understand-what-is-happening">
<h3><strong>Issue #13</strong>: Simulation seems to freeze, or to be surprisingly slow, or more generally does not behave as expected, and I do not want to stick <tt class="docutils literal">io:format</tt> calls everywhere to understand what is happening.</h3>
<p>If not using the simulation traces either to figure out what is happening, then a good approach could be to connect to the busiest computing nodes (use simply <tt class="docutils literal">top</tt> on each host) to determine what they are doing; to do so, track in the console the line which reminds the user of the names of the computing nodes and of the simulation cookie, like in:</p>
<pre class="code erlang literal-block">
<span class="nv">To</span> <span class="n">connect</span> <span class="n">to</span> <span class="n">computing</span> <span class="nb">nodes</span> <span class="p">[</span>
 <span class="n">'Scheduling_scalability_test-boudevil&#64;server1'</span><span class="p">,</span>
 <span class="n">'Scheduling_scalability_test-boudevil&#64;server2'</span><span class="p">,</span>
 <span class="n">'Scheduling_scalability_test-boudevil&#64;server3'</span><span class="p">],</span> <span class="n">use</span> <span class="n">cookie</span>
 <span class="n">'1f793a6ba507-d389-2e11-5bd1-2f759320'</span><span class="p">.</span>
</pre>
<p>Then run a new node, connect to the computing node and run <tt class="docutils literal">etop</tt> to inspect it, like in (maybe exporting <tt class="docutils literal">DISPLAY</tt> and/or increasing the net tick time can help):</p>
<pre class="code bash literal-block">
erl -epmd_port <span class="m">4506</span> -setcookie <span class="s1">'1f793a6ba507-d389-2e11-5bd1-2f759320'</span> -sname inspector
<span class="o">(</span>inspector&#64;tesla<span class="o">)</span><span class="m">1</span>&gt; net_adm:ping<span class="o">(</span>
<span class="s1">'Scheduling_scalability_test-boudevil&#64;server2'</span><span class="o">)</span>.
 pong
</pre>
<p>Then hit CTRL-G and enter:</p>
<pre class="code erlang literal-block">
<span class="p">-</span><span class="err">-&gt; </span><span class="ni">r</span> <span class="n">'Scheduling_scalability_test-boudevil&#64;server2'</span>
<span class="p">-</span><span class="err">-&gt; </span><span class="ni">j</span>
   <span class="mi">1</span>  <span class="p">{</span><span class="n">shell</span><span class="p">,</span><span class="n">start</span><span class="p">,[</span><span class="n">init</span><span class="p">]}</span>
   <span class="mi">2</span><span class="o">*</span> <span class="p">{</span><span class="n">'Scheduling_scalability_test-boudevil&#64;server2'</span><span class="p">,</span><span class="n">shell</span><span class="p">,</span><span class="n">start</span><span class="p">,[]}</span>
<span class="p">-</span><span class="err">-&gt; </span><span class="ni">c</span> <span class="mi">2</span>
     <span class="p">(</span><span class="nv">Scheduling_scalability_test</span><span class="o">-</span><span class="n">boudevil</span><span class="p">&#64;</span><span class="n">server2</span><span class="p">)</span><span class="mi">1</span><span class="o">&gt;</span> <span class="nn">etop</span><span class="p">:</span><span class="nf">start</span><span class="p">().</span>
</pre>
<p>(note that the ping is not necessary, just issuing <tt class="docutils literal">r <span class="pre">'Scheduling_scalability_test-boudevil&#64;server2'</span></tt> then <tt class="docutils literal">c</tt> would suffice)</p>
<p>Then you are able to see something like:</p>
<p><span class="raw-html"><center><img src="etop.png" id="responsive-image-large"></img></center></span>
</p>
<p>You can also run <tt class="docutils literal">observer</tt> instead:</p>
<pre class="code erlang literal-block">
<span class="p">(</span><span class="nv">Scheduling_scalability_test</span><span class="o">-</span><span class="n">boudevil</span><span class="p">&#64;</span><span class="n">server2</span><span class="p">)</span><span class="mi">1</span><span class="o">&gt;</span> <span class="nn">observer</span><span class="p">:</span><span class="nf">start</span><span class="p">().</span>
</pre>
<p>And then we have:</p>
<p><span class="raw-html"><center><img src="observer.png" id="responsive-image-intermediate"></img></center></span>
</p>
</div>
<div class="section" id="issue-14-simulation-runs-but-result-generation-fails">
<h3><strong>Issue #14</strong>: Simulation runs, but result generation fails.</h3>
<p>If the error message mentions <tt class="docutils literal">unknown or ambiguous terminal type</tt>, this means that <tt class="docutils literal">gnuplot</tt> (used by probes to generate graphical outputs) is (surprisingly enough) <em>not</em> able to generate PNG files. Either rebuild it accordingly, or select a gnuplot package in your distribution whose PNG support has been enabled beforehand.</p>
</div>
<div class="section" id="issue-15-at-start-up-no-available-computing-node-is-found-each-candidate-node-being-apparently-successfully-launched-but-not-responding">
<h3><strong>Issue #15</strong>: At start-up, no available computing node is found, each candidate node being apparently successfully launched, but not responding.</h3>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Unlikely to happen anymore (a cleaner script is used by default now).</p>
</div>
<p>This may happen if a previous simulation crashed and thus could not reach its clean-up phase: then pending Erlang nodes, spawned by the previous run, may linger for up to 10 minutes before their automatic shutdown, should the node cleaner script have been unable to remove them, for any reason (which must be <em>very</em> uncommon).</p>
<p>Indeed their node name will be correct, so no attempt to launch them will be made, but the automatic authentication system of the engine, based on security cookies generated from a unique UUID, will prevent the connection to these preexisting nodes. They will thus be deemed unavailable and the simulation will stop, short of being able to rely on any computing node. The solution is then either to remove these pending nodes manually (one effective yet rough means of doing so being <tt class="docutils literal">killall <span class="pre">-9</span> ssh beam beam.smp</tt>, to be run on all computing nodes) or to set the <tt class="docutils literal">perform_initial_node_cleanup</tt> field in the <tt class="docutils literal">deployment_settings</tt> record to true (see <tt class="docutils literal">class_DeploymentManager.hrl</tt>) and recompile, in which case any lingering node would be removed when colliding with a newer run; as this latter setting is now the default, this issue should not happen frequently anymore, or at all.</p>
</div>
<div class="section" id="issue-16-simulation-runs-and-fails-with-no-specific-error-message-in-the-traces">
<h3><strong>Issue #16</strong>: Simulation runs and fails with no specific error message in the traces.</h3>
<p>Of course this never happens usually, as it is precisely what we want to avoid.</p>
<p>Such a behaviour may sum up to a message like:</p>
<pre class="code literal-block">
--- diasca {2200,2} still in progress at 2021/1/12 10:29:21 ---
</pre>
<p>being issued, then:</p>
<pre class="code literal-block">
&lt;----------------
[emergency] The 'Sim-Diasca-XXX-YYY-128694-computing-node&#64;foobar.org'
node disconnected, performing an emergency shutdown.
----------------&gt;

&lt;----------------
[emergency] EXIT message received for &lt;11029.94.0&gt;, whose exit
reason was: noconnection, terminating now.
----------------&gt;
</pre>
<p>The only case when such a behaviour was reported happened when a model developer created by mistake an infinite recursion <a class="footnote-reference" href="#id134" id="id133">[51]</a>; the induced RAM consumption resulted in instantly having the VM killed by the operating system.</p>
<table class="docutils footnote" frame="void" id="id134" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id133">[51]</a></td><td>Precisely: from a given actor oneway A, instead of calling the version of its mother class with <tt class="docutils literal">wooper:executeOnewayAs/4</tt>, <tt class="docutils literal">wooper:executeOneway/3</tt> was used, leading to A calling itself indefinitely and exploding the stack.</td></tr>
</tbody>
</table>
<p>So chances are that this corresponds to a user implementation error.</p>
</div>
<div class="section" id="issue-17-now-unlikely-to-happen-as-run-erl-not-used-by-default-anymore-a-simulation-case-is-launched-yet-it-freezes-just-after-the-line-telling-the-trace-aggregator-has-been-created-and-stays-unresponsive-until-ctrl-c-is-entered">
<h3><strong>Issue #17</strong> [now unlikely to happen, as <tt class="docutils literal">run_erl</tt> not used by default anymore]: A simulation case is launched, yet it freezes just after the line telling the trace aggregator has been created, and stays unresponsive until CTRL-C is entered.</h3>
<p>This typically happens after a first failed launch: a virtual machine bearing the same name is already running on the background, thus preventing another one to be launched. The solution may be as simple as a brutal, yet efficient, <tt class="docutils literal">killall <span class="pre">-9</span> beam.smp</tt>.</p>
<p>This issue used to occur more frequently when the default launching mode was set to rely on <tt class="docutils literal">run_erl</tt> (rather than a direct start from the command-line). No more <tt class="docutils literal"><span class="pre">{error_logger,T,&quot;Protocol:</span> ~tp: the name X&#64;Ya seems to be in use by another Erlang <span class="pre">node&quot;,[&quot;inet_tcp&quot;]}</span></tt> was reported by the VM (as discussed in issue #1) yet, strangely enough, the issue discussed here could happen during the mass running of tests (ex: when executing <tt class="docutils literal">make test</tt> from the root). <tt class="docutils literal">run_erl</tt> was suspected here.</p>
</div>
<div class="section" id="issue-18-simulation-is-not-reproducible">
<h3><strong>Issue #18</strong> Simulation is not reproducible.</h3>
<p>One may run, in reproducible mode, a simulation twice, and unfortunately realize that results happen to differ.</p>
<p>Whether or not the technical setting changed (ex: local run versus a distributed one), it is abnormal and surely disturbing - moreover it tends to be among the issues that are the most difficult to investigate.</p>
<p>Of course the engine might be the culprit, yet, for the moment at least, every time that reproducibility was lost, the cause was found to lie in the simulation itself, not in the engine.</p>
<p>The actual culprit could be the simulation case (ex: see <a class="reference internal" href="#randomness-pitfalls">Randomness Pitfalls</a>) or the models. For example the implementor must remind that simulations are executed so that they are reproducible, while PIDs are expected to change from one run to another (a bit like pointers). Hence no operation, except equality testing, shall be performed on them. For reliable, stable actor identifiers, one must use AAIs instead.</p>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p>We encountered once a bug at this level, where an actor collected a list of other actors (possibly containing duplicates) and needed to select only one of them (of course in a reproducible manner) by applying some criterion.</p>
<p class="last">This operation should have been done on their AAI (even if it implied a conversion back and forth their PID), but it had been done on their PID instead. <tt class="docutils literal">list_utils:uniquify/1</tt> was used to remove first the duplicates; the order of the resulting list was not specified, yet of course it could only be deterministically reordered.</p>
</div>
<p>However this function happens to internally sort the elements of that list; as a consequence, removing duplicates from a list of non-reproducible PIDs resulted in a non-reproducible ordering, and the whole simulation started to behave differently from a run to the next...</p>
<p>To considerably increase the chances of spotting that different outcomes stem from a simulation (without even looking at the results), now the total number of diascas elapsed and of instance schedulings is displayed on the console. As soon as at least one of them differ from a run to another, the simulation is known to introduce non-reproducible elements, and must be fixed.</p>
</div>
<div class="section" id="issue-19-problem-when-rebuilding-the-documentation">
<h3><strong>Issue #19</strong> Problem when rebuilding the documentation.</h3>
<p>In some cases the generated documentation encountered problems, typically the table of contents of the technical manual was empty.</p>
<p>This may come from some tools that insert Unicode characters (typically <tt class="docutils literal">U+FEFF</tt>) that are invisible in most editors (ex: <tt class="docutils literal">emacs</tt>) yet that are not supported by the documentation generators (based on docutils and the RST syntax).</p>
<p>A solution is to check the output of the documentation tools (ex: <tt class="docutils literal">rubber</tt>) or to use editors like <tt class="docutils literal">nedit</tt>, which displays these characters that shall be removed.</p>
</div>
</div>
<div class="section" id="common-misconceptions">
<h2><a class="toc-backref" href="#id247">Common Misconceptions</a></h2>
<p><span class="raw-html"><center><img src="xkcd-misconceptions.png" id="responsive-image-small"></img></center></span>
</p>
<p>Here is the list of most common misconceptions that we spotted:</p>
<div class="section" id="traces-are-part-of-simulation-results">
<h3>Traces are part of simulation results</h3>
<p>This is not what we promote: we see the distributed traces as a way of monitoring technically a simulation run. Results are typically probe reports. Moreover, for actual large-scale runs, we generally prefer to disable traces.</p>
</div>
<div class="section" id="the-performance-tracker-is-the-one-responsible-for-the-progress-information-output-on-the-terminal">
<h3>The Performance Tracker is the one responsible for the progress information output on the terminal</h3>
<p>No, the culprit is the <a class="reference internal" href="#console-tracker">console tracker</a>, which is a live lightweight Sim-Diasca built-in, whereas the <a class="reference internal" href="#performance-tracker">performance tracker</a> is an unrelated, optional, more complex post-mortem feature.</p>
</div>
<div class="section" id="thanks-to-parallelism-i-will-have-all-my-cores-100-busy">
<h3>Thanks to parallelism, I will have all my cores 100% busy</h3>
<p>Unfortunately, the simulations of complex systems are in the general case <em>not</em> <a class="reference external" href="https://en.wikipedia.org/wiki/Embarrassingly_parallel">embarrassingly parallel</a>, as their various components (actors) are bound to interact (there lies the main interest of these simulations); model instances have therefore to synchronise, and it certainly comes at a cost. If having many lightweight, intensely-interacting models, the engine may spend a large part of its time just enforcing the proper scheduling and communication of the corresponding instances.</p>
<p>Such a synchronisation is a &quot;hard&quot; problem that all the concurrent, discrete-time simulations experience; to the best of our knowledge, in terms of algorithms no silver bullet exists (one just has to pick one's poison). Sim-Diasca is based on trade-offs that we deem relevant for most cases. Depending on the problem to simulate at hand, other approaches may perform better (or worse).</p>
</div>
<div class="section" id="harnessing-a-larger-set-of-resources-thanks-to-distribution-will-boost-the-simulation-performances">
<h3>Harnessing a larger set of resources thanks to distribution will boost the simulation performances</h3>
<p>In the sense of:</p>
<ul class="simple">
<li>completing a given simulation sooner, the opposite is very likely: many simulations of complex systems are very sensitive to latency, and of course synchronising over a network is bound to be a lot slower than doing so inside a single local RAM; so a significant overhead shall be expected as soon as more than one computing host is used</li>
<li>running simulations that could not even run on a single host, certainly</li>
</ul>
<p>In terms of <a class="reference external" href="https://en.wikipedia.org/wiki/Speedup">speedup</a>, in link with this question and the previous ones, <a class="reference external" href="https://en.wikipedia.org/wiki/Amdahl%27s_law">Amdahl's law</a> gives an upper bound to one's expectations in the cases where the problem size is fixed.</p>
<p></p>
</div>
</div>
</div>
<div class="section" id="sim-diasca-support">
<h1><a class="toc-backref" href="#id248">Sim-Diasca Support</a></h1>
<p>It is not required to apply any meaningless procedure or know any code word to get some support:</p>
<p><span class="raw-html"><center><img src="xkcd-tech_support.png"></img></center></span>
</p>
<p>No need either for a specific support registration form:</p>
<p><span class="raw-html"><center><img src="xkcd-a_new_captcha_approach.png"></img></center></span>
</p>
<p>Just be sure to have read beforehand the <a class="reference internal" href="#sim-diasca-troubleshooting">Sim-Diasca Troubleshooting</a> section.</p>
<p>Of course, if ever changes were made to the Sim-Diasca codebase, testing also against a vanilla (pristine) release may help discriminating among the many possible causes:</p>
<p><span class="raw-html"><center><img src="xkcd-appliance_repair.png"></img></center></span>
</p>
<p>If the issue remains, then probably that some support could help.</p>
<p>However, surely that, rather than reporting &quot;this does not work!&quot;, we would prefer a more detailed bug report, mentioning at least:</p>
<ul class="simple">
<li>your version of Sim-Diasca and of other tools (including Erlang)</li>
<li>your platform (hardware and software)</li>
<li>the detailed error message (preferably including stack trace, context and prior outputs, even if it is long)</li>
<li>the trace output, i.e. the full trace file (ex: <tt class="docutils literal">my_case_test.traces</tt>), which is a very valuable source of troubleshooting information</li>
</ul>
<p>The simplest approach is to double-check your problem and then contact directly the Si-Diasca maintainer, Olivier Boudeville, preferably by email (using the address at the top of this document for that).</p>
<p>Support will be done on a best-effort basis (no commercial support available).</p>
</div>
<div class="section" id="sim-diasca-changes">
<h1><a class="toc-backref" href="#id249">Sim-Diasca Changes</a></h1>
<p>The detailed changes over versions are not included in this manual anymore, as they used to spread over too many pages, for little interest.</p>
<p>Please refer directly to the <tt class="docutils literal"><span class="pre">Sim-Diasca-changes-english.rst</span></tt> file instead.</p>
<p></p>
</div>
<div class="section" id="sim-diasca-future-enhancements">
<span id="enhancements"></span><h1><a class="toc-backref" href="#id250">Sim-Diasca Future Enhancements</a></h1>
<p><span class="raw-html"><center><img src="xkcd-researcher_translation.png"></img></center></span>
</p>
<div class="section" id="general-requirements">
<h2><a class="toc-backref" href="#id251">General Requirements</a></h2>
<p>These requirements are lacking or are only poorly supported with the Sim-Diasca 1.x version series, and are fulfilled with the Sim-Diasca 2.x version series.</p>
<div class="section" id="id135">
<h3>Actor Creation</h3>
<p>An actor can be created either from a simulation launcher (ex: a test case), most often before the simulation started, or by another actor, usually in the course of simulation.</p>
<p>In both cases, these creations should lead to a totally reproducible simulation, moreover with no regard for the technical context (like the sets of computers being used).</p>
<p>To do so, an intermediate agent is used, the load balancer, which is a simulation actor and therefore can rely on the mechanisms for reproducibility.</p>
<p>Therefore the only simulation agent that will effectively create (spawn) a new simulation actor will be the load balancer.</p>
</div>
<div class="section" id="id136">
<h3>Load Balancing</h3>
<p>The load balancer, which is a singleton, will create actors remotely, on one of the available nodes, based on its balancing policy.</p>
<p>A priori the load balancer does not strictly need to create actors synchronously (as it will serialize their AAI assignment), but it needs anyway to return to the caller a notification that the created actors are ready, so that the caller can continue its operations without race conditions (ex: for a creating actor, it means finishing its own tick). Otherwise one could not be sure for example that the created actor managed to properly subscribe to its time manager during the same tick.</p>
<p>As actors may have to be created either before or in the course of a simulation, there are two ways of telling the load balancer to spawn them:</p>
<ul class="simple">
<li>before the simulation started, the scenario or test case will call its <tt class="docutils literal">bootstrap_actor</tt> request (not a oneway so that the caller can know for sure that the creation is over and, for example, can start the simulation from a proper and reproducible initial situation)</li>
<li>in the course of the simulation: then the creator will be one of the current actor, and the creation will be based on an actor message sent to the load balancer, <tt class="docutils literal">spawn_actor</tt></li>
</ul>
<p>Some more advanced load-balancing policies are interesting to provide, for example: the more instances interact, the closer they should be placed, the ideal situation being to have them run on the same computing node; the mere possibility of providing a hint to the load-balancer helps already a lot.</p>
<p>Indeed, this is just a matter of passing to the load balancer the same extra parameter, any Erlang term (ex: an atom like <tt class="docutils literal">house_111452</tt>), to the load-balancer when creating all actors corresponding to a given home (here the #111452). If having N candidate computing nodes, in that case the load balancer would bypass its default placement policy and always choose the <tt class="docutils literal">N1 = hash(house_111452) rem N</tt> node (i.e. the hash value of the specified placement hint, modulo the number of nodes), ensuring all devices of that home - expected to be tightly linked - will be placed on the same node, <tt class="docutils literal">N1</tt>. This could lead to a rather uniform distribution across nodes, while minimising very effectively the network traffic.</p>
</div>
<div class="section" id="actor-identifiers">
<h3>Actor Identifiers</h3>
<p>As in all cases - reproducible or ergodic - messages will be reordered based on various information including the identity of the sender, the simulation engine must rely on actor identifiers which are themselves reproducible.</p>
<p>The Sim-Diasca 0.1.x versions relied for that on Erlang process identifiers (PID), which where indeed reproducible in the context of a given computing architecture, but which would offer no guarantee should, for example, the number of computers change. Therefore in this case a given actor could be identified by different Pid, which in turn would lead to different reorderings, and therefore different simulation outcomes.</p>
<p>With the Sim-Diasca 0.1.x versions, actors use abstract identifiers, not technical ones like the Pid. In the course of a simulation, there is a one-to-one relationship (a bijection) between an <em>Abstract Actor Identifier</em> (AAI) and a Pid. But the same simulation run twice will exhibit actors bearing the same AAI with presumably different Pid.</p>
<p>AAI are managed by the load balancer, which simply maintains a counter of actors as it creates them, and keeps track of their Pid to be able to answer to look-ups.</p>
<p>The AAI of an actor is assigned when it is created, directly as the first construction parameter.</p>
<p>To avoid listing such an additional constructor parameter that we would have preferred invisible, the load balancer could have sent a message instead, that the actor would have waited in its constructor. However it is more complex, requires to send more networked messages, and finally might maybe be hidden with an appropriate parse transform.</p>
<p>The two-way resolving between AAI and Pid should probably be taken in charge preferably by a dedicated agent.</p>
</div>
<div class="section" id="actor-start-up">
<h3>Actor Start-up</h3>
<p>The fundamental frequency of the simulation should be automatically specified to any created actor, so that it can adjust its timings or report an unability to comply with the simulation frequency.</p>
<p>After the start-up phase, each actor should know at least:</p>
<ul class="simple">
<li>the Pid of its time manager</li>
<li>the fundamental frequency of the simulation or, more precisely, the duration in simulation time of a elementary time step</li>
<li>its own random seeding for reproducibility and all</li>
<li>its Abstract Actor Identifier (AAI)</li>
<li>its scheduling policy</li>
</ul>
</div>
<div class="section" id="actor-scheduling">
<h3>Actor Scheduling</h3>
<p>Now the spontaneous and triggered behaviours of an actor do not have to happen at each tick: an actor can freely choose at which future simulation tick it should be scheduled next by the timer manager, whereas the actor messages sent to it will dictate when it will process them.</p>
<p>So an actor can behave spontaneously either as a periodical actor (being scheduled 1 tick every N), as a step-by-step actor (determining, while being scheduled, when it should be scheduled next), or as a purely passive actor (being only triggered by incoming actor messages, not having any spontaneous behaviour).</p>
<p>Actors will have also to be able to withdraw or change a previously selected tick. This can be useful when an actor receives an actor message between two spontaneous schedulings and based on that decides to change the planned one.</p>
<p>To do so, at the beginning of a tick when an actor is expected to develop some behaviour, it will be triggered by its time manager:</p>
<ul class="simple">
<li>either by a <tt class="docutils literal">spontaneous_top</tt> message, meaning this actor had planned to develop its spontaneous behaviour at this tick, and implicitly meaning that it has no actor message to process</li>
<li>or a <tt class="docutils literal">triggered_top</tt> message, meaning at least there is at least one pending actor message to be processed, and implicitly meaning that it has no spontaneous behaviour to develop at this tick</li>
<li>or a <tt class="docutils literal">twofold_top</tt> message, meaning there is at least one pending actor message to be processed <em>and</em> that this actor had planned to develop its spontaneous behaviour at this tick ; they will be managed in that order</li>
</ul>
<p>With each of these top messages, the current simulation tick will be passed by the time manager.</p>
<p>Once the actor will have managed the <tt class="docutils literal">top</tt> message it received, and once it will have successfully waited for the pending acknowledgement of any actor messages it sent this tick, it will notify its time manager its tick is finished by one of the following messages:</p>
<ul class="simple">
<li><tt class="docutils literal">{done,N}</tt> where N is a (strictly positive) number of ticks before this actor should be next scheduled for a spontaneous behaviour; for example, if during the tick 100 an actor returned <tt class="docutils literal">{done,2}</tt>, then it will be scheduled for its spontaneous behaviour only at tick 102, possibly jumping over tick 101 if it did not receive any actor message at tick 100 ; having each actor specify explicitly its next spontaneous tick is the most flexible possible policy ; for example periodical schedulings or purely passive ones are just special cases</li>
<li><tt class="docutils literal">{done,none}</tt> if this actor intends to remain purely passive (i.e. only triggered by message, with no spontaneous behaviour), at least until the first next receiving of an actor message</li>
<li><tt class="docutils literal">terminating</tt> if this actor plans its removal at the next tick ; it will then receive a <tt class="docutils literal">termination_top</tt> at the tick, and then nothing more</li>
</ul>
<p>Although an actor may send directly these messages, they can be automatically handled by <tt class="docutils literal">manage_end_of_tick</tt>, depending on the scheduling policy declared by the actor, in <tt class="docutils literal">passive</tt>, <tt class="docutils literal">{periodical,P}</tt> and <tt class="docutils literal">custom</tt>.</p>
<p>Each time manager will maintain an ordered list of the next ticks to schedule. If no event is planned in the simulated system for a period of virtual time, then the simulation will automatically jump directly over that period (i.e. no resource will be wasted examining idle ticks).</p>
<p>For reliability and testing purposes, the current tick of the actor can be appended to each of these messages, so that the time manager can check whether times are properly synchronised.</p>
<p>An actor can send at any time during its tick a <tt class="docutils literal">{withdraw_spontaneous,Tick}</tt> message telling its time manager it does not want any more to be scheduled for spontaneous behaviour on the specified (absolute) tick.</p>
</div>
<div class="section" id="inter-actor-communication">
<h3>Inter-Actor Communication</h3>
<p>When an actor A1 needs to communicate an information to an actor A2, A1 will send an actor message to A2.</p>
<p>This will actually involve the sending of three messages:</p>
<ol class="arabic simple">
<li>A1 sends the actual actor message to A2</li>
<li>upon reception, A2 sends:<ul>
<li>an acknowledgment message to A1, so that A1 can finish its tick</li>
<li>a <tt class="docutils literal">schedule_trigger</tt> message to its time manager, so that this manager schedules it back on the next tick in order for this message to be processed by A2</li>
</ul>
</li>
</ol>
<p>If A2 already knows that it will be triggered next tick <em>in order to process actor messages</em> (i.e. regardless on any spontaneous scheduling), it may choose not to notify again its time manager.</p>
<p>We could have imagined that, instead of A2, A1 could have contacted the time manager so that A2 is triggered on the next tick. However, in a distributed context, A1 and A2 may depend on different time managers, and we want to notify the one of A2, which handles A2, not the one, potentially different, of A1.</p>
<p>This is why it is the task of A2 to send adequately the <tt class="docutils literal">schedule_trigger</tt> message. Not only A2 knows which time manager to notify whereas A1 does not, but also it allows to use only one potentially non-local (networked) message instead of two.</p>
</div>
<div class="section" id="inter-time-manager-synchronisation">
<h3>Inter-Time Manager Synchronisation</h3>
<p>A time manager can have zero or one parent time manager (a time manager cannot be its own parent and no child manager should be set as a parent), any number of child time managers, and any number of actors to manage directly.</p>
<p>Therefore the time managers respect a hierarchical structure. As in each simulation any two time managers must be, directly or not, ancestor and heir (they must belong to the same graph), the structure is actually a tree, whose root corresponds to the time manager directly in touch with the user, and whose leaves are either time managers or, more probably, actors (an actor cannot be placed elsewhere than on a leaf).</p>
<p>When a tick is finished, all time managers, from bottom to top, reports the first next tick they have to schedule, and the next simulation tick will be the one that will happen sooner.</p>
<p>So each time manager will determine, based on its own actors (if any) and on its direct child time managers (if any), what is the next tick T it would schedule (the soonest of the reported next ticks), then sends to its parent time manager (if any) a <tt class="docutils literal">{next_tick,T}</tt> message.</p>
<p>Then when these messages reach the overall time manager (the root one, the only one having no parent time manager), the smaller tick of all is known, the consensus is found and sent down recursively in the scheduling tree of time managers with a <tt class="docutils literal">{begin_tick,T}</tt> message. Each time manager will in turn translate it with the proper <tt class="docutils literal">top</tt> messages for the actors they drive.</p>
</div>
<div class="section" id="granularity-of-synchronisation">
<h3>Granularity of Synchronisation</h3>
<p>The scheduling tree can be of any depth, and we could imagine having one time-manager per core, per processor, per computer, or per simulation.</p>
<p>The trade-off we currently prefer is to let the Erlang SMP interpreter spread as much as possible in a computing node, i.e. across processors and cores.</p>
<p>For example, with a computer relying on two processors with four cores each, we could have imagined 8 time managers (one per core), or 2 (one per processor), however just having one of them is possible and probably better, performance-wise. So we would have here one Erlang node making use of eight run queues. The optimal number of such queues might be further optimised.</p>
</div>
<div class="section" id="reproducibility-and-ergodicity">
<h3>Reproducibility and Ergodicity</h3>
<p>The simulation user can request the engine to work according to one of the following schemes:</p>
<ul class="simple">
<li><tt class="docutils literal">reproducible</tt>, with or without a user-specified random seed</li>
<li><tt class="docutils literal">ergodic</tt></li>
</ul>
<p>In reproducible mode, running twice the same simulation (same scenario, with possibly different computing contexts) should output exactly the same results.</p>
<p>In ergodic mode, each simulation execution will follow a specific possible trajectory of the system, knowing that statistically, over a large number of executions, the exploration of the possible states should be fair, i.e. all possible situations allowed by the models should be able to show up, and moreover they should occur with respect to their theoretical probabilities, as dictated by the models.</p>
<p>In practical, the reproducible mode without a user-specified random seed will just result in each actor reordering its messages according to their hash.</p>
<p>Thus the actor will be seeded (for any need in terms of generation of stochastic values they could have) but will not perform any additional message permutations <a class="footnote-reference" href="#id138" id="id137">[52]</a>. A default seed will then be used.</p>
<table class="docutils footnote" frame="void" id="id138" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id137">[52]</a></td><td>Therefore this mode should be slightly faster than the others.</td></tr>
</tbody>
</table>
<p>On the contrary, the other modes will rely on the actor-specific seed to perform an additional permutation of the messages.</p>
<p>More precisely, that seed will be the user-specified one if reproducible, or a seed automatically determined from current time if ergodic.</p>
<p>As the seed used in an ergodic context is recorded in the simulation traces, any ergodic execution can be later run again at will by the user, simply by specifying that seed in a new simulation execution, this time in reproducible mode.</p>
<p>As a consequence of these settings, in the context of a simulation the time managers, which are created by the load balancer, will:</p>
<ul class="simple">
<li>all be given a seed, and will generate a specific seed for each actor they manage</li>
<li>request their actors either to reorder their messages based on hash only, or with an additional permutation</li>
</ul>
</div>
<div class="section" id="reordering-of-actor-messages">
<h3>Reordering Of Actor Messages</h3>
<p>Depending on the simulator settings, the reordering of the actor messages received for a given tick will be performed either so that reproductivity is ensured (i.e. messages are sorted according to a constant arbitrary order, the default one or one depending on a user-defined seed), or so that &quot;ergodicity&quot; is ensured, i.e. so that all possible reordering of events (messages) have a uniform probability of showing up.</p>
<p>In all cases a basic constant arbitrary order is obtained, based on <tt class="docutils literal">keysort</tt>, which sorts the actor messages according to the natural order defined over Erlang terms <a class="footnote-reference" href="#id140" id="id139">[53]</a>.</p>
<table class="docutils footnote" frame="void" id="id140" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id139">[53]</a></td><td>Therefore this reordering does not involve computing the hash value of terms.</td></tr>
</tbody>
</table>
<p>Let's suppose for example that an actor has, for the current tick, the following message list, whose elements are triplets like <tt class="docutils literal">{SenderActorPid,SenderActorAai,ActorMessage}</tt>:</p>
<pre class="code erlang literal-block">
<span class="nv">L</span> <span class="o">=</span> <span class="p">[{</span><span class="n">pa</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
     <span class="p">{</span><span class="n">pb</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
     <span class="p">{</span><span class="n">pc</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
     <span class="p">{</span><span class="n">pd</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">},</span>
     <span class="p">{</span><span class="n">pe</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
     <span class="p">{</span><span class="n">pf</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
     <span class="p">{</span><span class="n">pg</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
     <span class="p">{</span><span class="n">ph</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
     <span class="p">{</span><span class="n">ph</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span>
     <span class="p">{</span><span class="n">pa</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">},</span>
     <span class="p">{</span><span class="n">pa</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">}]</span>
</pre>
<p>The constant arbitrary order is obtained thanks to <tt class="docutils literal">lists:keysort(3,lists:keysort(2,L))</tt> <a class="footnote-reference" href="#id142" id="id141">[54]</a>.</p>
<table class="docutils footnote" frame="void" id="id142" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id141">[54]</a></td><td>One can see that this ordering does not depend on the PID of the sending actors (which is the first element of the triplet), as, for a given simulation,  these technical identifiers may vary depending on the computing hosts involved, whereas we want a stable reproducible order, independent from any technical context.</td></tr>
</tbody>
</table>
<p>This means we sort first on the AAI (which is likely to be quite quick), like in:</p>
<pre class="code erlang literal-block">
<span class="nn">lists</span><span class="p">:</span><span class="nf">keysort</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="nv">L</span><span class="p">).</span>
<span class="p">[{</span><span class="n">pd</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pf</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pg</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pb</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pa</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pa</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pa</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pc</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">ph</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">ph</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pe</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">}]</span>
</pre>
<p>Once the entries are sorted in increasing AAI order (element #2), knowing that an actor may have sent multiple messages to that same actor, then we sort these entries based on their messages <a class="footnote-reference" href="#id144" id="id143">[55]</a> (element #3):</p>
<pre class="code erlang literal-block">
<span class="nn">lists</span><span class="p">:</span><span class="nf">keysort</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="nn">lists</span><span class="p">:</span><span class="nf">keysort</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="nv">L</span><span class="p">)).</span>
<span class="p">[{</span><span class="n">pa</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span>
 <span class="p">{</span><span class="n">ph</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">1</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pf</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pg</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pb</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pa</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pc</span><span class="p">,</span><span class="mi">6</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">ph</span><span class="p">,</span><span class="mi">7</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pe</span><span class="p">,</span><span class="mi">10</span><span class="p">,</span><span class="mi">5</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pd</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">7</span><span class="p">},</span>
 <span class="p">{</span><span class="n">pa</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">8</span><span class="p">}]</span>
</pre>
<table class="docutils footnote" frame="void" id="id144" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id143">[55]</a></td><td>Knowing that two different actors may send the same exact message to a given actor (ex: <tt class="docutils literal">{setColor,red}</tt>).</td></tr>
</tbody>
</table>
<p>So, at the end, the reordering ensured that messages are always sorted by increasing AAI and, when multiple messages share the same AAI (i.e. they were sent by the same actor), these messages are always sorted identically (i.e. according to an increasing message order).</p>
<p>At this point a basic reproducible order, totally independent from the technical context, is ensured.</p>
<p>Then, depending on whether reproducibility or ergodicity are targeted, further reorderings are performed over that constant base.</p>
<p>If the user selected reproducibility, the list of actor messages obtained from the basic reordering are then uniformly permuted, according to the simulation seed, which is either the default one or a user-defined one.</p>
<p>If the user selected ergodicity, a fair exploration of all possible simulation outcomes is obtained by operating exactly like for the reproducible case, except that the random seed is not user-specified, it is itself automatically drawn at random, based on user time.</p>
<p>Then each simulation will explore its own way one of the possible trajectories of the system, knowing that any of these trajectories is fully determined by the drawn ergodic seed.</p>
<p>As a consequence, whenever such an ergodic trajectory is deemed interesting, it can be replayed at will simply by feeding the simulator with the same seed, this time in the context of a reproducible execution based on that user-defined seed.</p>
</div>
<div class="section" id="simulation-deployment">
<h3>Simulation Deployment</h3>
<p>From the simulation scenario or from the test case, the load balancer must be created with the relevant simulation settings, including the list of candidate computing nodes.</p>
<p>The load balancer will then select the eligible computing nodes, which are the subset in the candidates nodes that can be connected:</p>
<ul class="simple">
<li>the corresponding host must be up and running</li>
<li>it must be available from the network (ping)</li>
<li>a properly configured and named Erlang VM either can be launched on that node (with a password-less SSH connection) or is already launched</li>
<li>a two-way connection must be established with it (ex: the security cookie must match)</li>
</ul>
</div>
<div class="section" id="performances">
<h3>Performances</h3>
<p>One major goal of the Sim-Diasca 2.x versions is to increase the performances in a distributed context.</p>
<p>However some less demanding simulations will still be run in a local (non-distributed) context. So another requirement is to ensure that the new distributed mode of operation does not result in a loss of performances in a local context.</p>
</div>
</div>
<div class="section" id="id145">
<h2><a class="toc-backref" href="#id252">Load Balancing</a></h2>
<p>As discussed previously, in a distributed context, it is always possible for the user to specify on which machine each actor should be created and run.</p>
<p>This rather tedious process can be managed automatically and more efficiently by a <tt class="docutils literal">load balancer</tt>, i.e. a module that determines by itself an appropriate location for each new actor, and creates this actor accordingly.</p>
<div class="section" id="example-of-use">
<h3>Example of Use</h3>
<p>An example of such interaction could be:</p>
<pre class="code erlang literal-block">
<span class="c">% Here instances are created on each calculator in turn:
</span><span class="nv">BalancerPid</span> <span class="o">=</span> <span class="nn">class_LoadBalancer</span><span class="p">:</span><span class="nf">new_link</span><span class="p">(</span> <span class="n">round_robin</span><span class="p">,</span>
    <span class="p">[</span> <span class="n">host_a</span><span class="p">,</span> <span class="n">host_b</span><span class="p">,</span> <span class="n">host_b</span> <span class="p">]</span> <span class="p">),</span>

<span class="c">% The load balancer creates on each calculator as many local time
% managers as there are available nodes.
</span>
<span class="c">% Replaces class_PLCNetwork:remote_new_link(MyHost,35,4,rural):
</span><span class="nv">BalancerPid</span> <span class="o">!</span> <span class="p">{</span><span class="n">instantiate_link</span><span class="p">,[</span><span class="n">class_PLCNetwork</span><span class="p">,[</span><span class="mi">35</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="n">rural</span><span class="p">]],</span><span class="n">self</span><span class="p">()},</span>

<span class="nv">PLCNetworkPid</span> <span class="o">=</span> <span class="k">receive</span>

    <span class="p">{</span><span class="n">wooper_result</span><span class="p">,{</span><span class="n">instantiated</span><span class="p">,</span><span class="nv">Pid</span><span class="p">,_</span><span class="nv">Computer</span><span class="p">}}</span> <span class="o">-&gt;</span>
        <span class="nv">Pid</span>

<span class="k">end</span><span class="p">,</span>
<span class="p">[..]</span>
</pre>
</div>
<div class="section" id="load-balancing-approaches">
<h3>Load Balancing Approaches</h3>
<p>Instead of an hardcoded placement, a load balancer can perform:</p>
<ul class="simple">
<li>either a <tt class="docutils literal">static</tt> balancing, i.e. actors will be created regardless of the actual machine loads, with <em>a priori</em> rules (ex: round-robin)</li>
<li>or a <tt class="docutils literal">dynamic</tt> one, i.e. thanks to heuristics the load balancer will try to dispatch the induced load as evenly as possible among the computing nodes, based on the measurement of their actual load over time</li>
</ul>
<p>In both cases, using a load balancer will lead in most cases to break the reproducibility of the association between a given actor instance and a Pid: a static balancing over a varying number of computing nodes or a dynamic balancing in all contexts will result in a given actor to bear different Pid from a simulation to another <a class="footnote-reference" href="#id147" id="id146">[56]</a>.</p>
<table class="docutils footnote" frame="void" id="id147" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id146">[56]</a></td><td>Not to mention a future possibility of actor migration.</td></tr>
</tbody>
</table>
<p>As explained below, this is not what we want, as we aim to uncouple totally the results of the simulations from the technical environments that support them.</p>
<p>On a side note, once the user code is able to rely on a load balancer, it will not depend on any particular type of load balancer, since all balancers will all be given creation requests and will all return the Pid of the corresponding created instances.</p>
<p>Therefore one can start with a very basic load balancer (like a round-robin based one), knowing that the integration of a more advanced ones (say, a dynamic one using advanced heuristics) should not imply any model to be modified.</p>
<p>Another interesting feature would be to have a load balancer which would take into account the tightness of the coupling between a set of actors. Then, the more actors would interact, the stronger the tendency to instantiate them on the same node would be.</p>
<p>If such a guessing about coupling intensity seems difficult to achieve for a load balancer, the simulation user could hint it, for example by designating a group by an atom and specifying that atom at each creation of one of its member. Then the load balancer would just have to try to place all actors bearing that atom on the same node, whatever it is.</p>
</div>
<div class="section" id="id148">
<h3>Actor Creation</h3>
<p>In the course of the simulation, an actor may need to create another actor <a class="footnote-reference" href="#id150" id="id149">[57]</a>. In this case it has to request the creation to the load balancer.</p>
<table class="docutils footnote" frame="void" id="id150" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id149">[57]</a></td><td>Otherwise an actor is <em>initial</em>, i.e. created by the simulation case before the simulation starts, see in this case the <tt class="docutils literal">class_LoadBalancer:createActor/3</tt> request.</td></tr>
</tbody>
</table>
<p>In the future, we could imagine following enhancements:</p>
<ul class="simple">
<li>the creating actor could be able to specify a <strong>placement hint</strong>, which could be any Erlang term (generally, an atom), to increase the probability that coupled actors are created on the same node; so, for example, an anthouse A, itself created with a placement hint <tt class="docutils literal"><span class="pre">anthouse-a</span></tt>, could specify the same hint whenever requesting the creation of an ant. Then the load balancer would compute the hash value of that hint and select always the same node based on that, provide this does not lead to a too unbalanced dispatching of actors onto nodes</li>
<li>the creating actor could be able to specify a <strong>request identifier</strong>, which would help it tracking which actors were created by the load balancer on its behalf; indeed, if an actor requests at the same tick the creation of an instance of two different classes, then by default, when it will be notified by the load balancer of these creations at the next tick, it will not be able to tell which returned PID corresponds to which instance, knowing that the load balancer had all its requests reordered</li>
</ul>
</div>
</div>
<div class="section" id="reproducible-actor-identifiers">
<h2><a class="toc-backref" href="#id253">Reproducible Actor Identifiers</a></h2>
<p>When running on reproducible mode, the arbitrary order enforced on concurrent messages received by a given actor at any given tick can be based on the actual message content, thanks to a hashing function, but in order to resolve the hash collisions we have to take into account the message sender as well.</p>
<p>Otherwise, when an actor A would be interacting with two instances B1 and B2 of a same class, B1 and B2 could quite possibly send the same message to A at the same tick (ex: <tt class="docutils literal">{setColor,red}</tt>). Then the content of the messages would be identical, their hash too, and the simulator would not be able to decide on their ordering.</p>
<p>Thus we need to rely on the sender information to perform a proper sorting of messages, but, unfortunately, if using a load balancer or if not using it but having to run on a changing computing infrastructure, Pid will not be suitable for that, short of being themselves reproducible.</p>
<p>Finally we need an actor identifier that is totally independent from the technical realm.</p>
<p>The solution will be implemented based on the load balancer.</p>
<p>To maintain a proper management of simulation time, all actors should be created:</p>
<ul class="simple">
<li>either directly from the simulation case <em>and</em> synchronously (to prevent race conditions at start-up), before the simulation is run (i.e. before the time manager makes the simulation clock progress)</li>
<li>or during the simulation itself, but in this case a new actor must be created by an actor already synchronised</li>
</ul>
<p>Otherwise the creation of new actors would not be synchronised with the simulation time (i.e. a given actor could be created, from a simulation to another, at different ticks) or if two actors were creating, each, another actor at the same tick, there would be a race condition.</p>
<p>When needing to rely on (unique) reproducible identifiers <a class="footnote-reference" href="#id152" id="id151">[58]</a>, to the best of our knowledge the only solution is to delegate the setting of identifiers to a centralised actor: no distributed algorithm can find a consensus on the new identifier to generate more easily than a counter-based centralised one.</p>
<table class="docutils footnote" frame="void" id="id152" rules="none">
<colgroup><col class="label" /><col /></colgroup>
<tbody valign="top">
<tr><td class="label"><a class="fn-backref" href="#id151">[58]</a></td><td>Actually we only need reproducible <em>orderings</em> of identifiers, but this weaker need could not be fulfilled with other solutions than actually reproducible identifiers (which is a stronger form).</td></tr>
</tbody>
</table>
</div>
<div class="section" id="code-deployment">
<h2><a class="toc-backref" href="#id254">Code Deployment</a></h2>
<p>When running a simulation on a set of computing nodes, on each of them the following software will be needed at runtime:</p>
<ul class="simple">
<li>an Erlang interpreter</li>
<li>a set of BEAM files corresponding to:<ul>
<li>the simulation engine (Sim-Diasca)</li>
<li>the simulation-specific models that run on top of it</li>
</ul>
</li>
</ul>
<p>The determining and gathering of these BEAM files is based in the buit-in installation procedure, with creates a proper, quite standard, installation base.</p>
<p>The Erlang interpreter <em>could</em> be deployed at runtime (a prebuilt version could be installed, at the expense of presumably light efforts), but it might be seen as a prerequisite, expected to be already available, instead.</p>
<p>In this case a few shell scripts could:</p>
<ul class="simple">
<li>login (with SSH password-less authentication) on each computing node</li>
<li>launch the <tt class="docutils literal">epmd</tt> daemon (<em>Erlang Port Mapper Daemon</em>) and an Erlang deployment client that would retrieve directly from a repository (possibly from the computer of the simulation user) all the relevant precompiled BEAM files</li>
</ul>
<p>Then the simulation could be created automatically on a user-defined set of nodes and run transparently on them.</p>
</div>
<div class="section" id="performance-tuning">
<h2><a class="toc-backref" href="#id255">Performance Tuning</a></h2>
<p>Many actions could - and will - be taken to further enhance the performances of Sim-Diasca, including:</p>
<ul class="simple">
<li>testing native compilation</li>
<li>integrating the &quot;zero-overhead&quot; WOOPER 2.0 version, based on parse transforms</li>
<li>using multiple 4GB VMs per host, to switch to a more compact 32-bit addressing; or making use of the &quot;half-word emulator&quot;</li>
<li>testing for concurrency errors, and tuning the application protocol to reduce overall latency</li>
<li>porting the simulation engine onto vastly concurrent resources (from IBM Bluegene/Q supercomputer to manycore cards like <a class="reference external" href="http://www.kalray.eu/">Kalray</a> or late <a class="reference external" href="https://en.wikipedia.org/wiki/Tilera/">Tilera</a>)</li>
</ul>
<p>We will ensure first that developing each of these enhancements is worth the time:</p>
<p><span class="raw-html"><center><img src="xkcd-is_it_worth_the_time.png"></img></center></span>
</p>
</div>
<div class="section" id="upstream-works">
<h2><a class="toc-backref" href="#id256">Upstream Works</a></h2>
<p>There is a number of more advanced topics that we hope to tackle in the next months and years.</p>
<p><span class="raw-html"><center><img src="xkcd-einstein.png"></img></center></span>
</p>
<p>Among them, there is:</p>
<ul class="simple">
<li>up to what point meta-programming can help further enhance the engine?</li>
<li>could there be a more high-level modelling language that could ease the work of domain experts (ex: UML-based graphical editors helping them to define models as if they were sequential) while still being automatically mappable to a massively concurrent simulation engine like Sim-Diasca?</li>
<li>could hybrid simulations (i.e. simulations that have elements both in discrete time and in continuous time) be supported by Sim-Diasca ? A first step would be to support the continuous-time paradigm alongside the discrete one, before trying to merge them; for example, energy-related systems may have to be simulated partly with differential equations that cannot be easily solved nor discretised, partly with more event-based behaviours, and of course both themes would likely need to be coupled for more integrated simulations</li>
</ul>
</div>
<div class="section" id="miscellaneous">
<h2><a class="toc-backref" href="#id257">Miscellaneous</a></h2>
<ul class="simple">
<li>improvement of random generator: use of the <tt class="docutils literal">crypto</tt> module or other good-quality random source (ex: Linux entropy pool) and a pseudo-random number generator (ex: a Fast Mersenne Twister)</li>
<li>use an enhanced version of WOOPER tailored for speed and low memory footprint (based on parse transforms)</li>
<li>deploy distributed nodes and agents fully in parallel, with a per-host or per-node manager, rather than sequentially</li>
<li>switch to the use of several 32-bit VMs per host, to further increase the scalability</li>
<li>support IPv6 settings (currently: IPv4-only); should not be too complex</li>
</ul>
<p></p>
</div>
</div>
<div class="section" id="sim-diasca-hints">
<h1><a class="toc-backref" href="#id258">Sim-Diasca Hints</a></h1>
<p>Some general hints are detailed here.</p>
<p><span class="raw-html"><center><img src="xkcd-wisdom_of_the_ancients.png"></img></center></span>
</p>
<div class="section" id="common-pitfalls">
<h2><a class="toc-backref" href="#id259">Common Pitfalls</a></h2>
<ul class="simple">
<li>the <tt class="docutils literal">class_Actor:onFirstDiasca/2</tt> actor oneway of all initial actors is to be called when the simulation starts, so that they can finish their initialisation; this does not imply that all initial actors will process the corresponding actor message exactly at diasca 1 (knowing that the load balancer was the only actor to be scheduled spontaneously, at diasca 0, and is the sender of these messages): in order to smooth the load (should there be a large number of initial actors), these calls to <tt class="docutils literal">onFirstDiasca/2</tt> will be dispatched over the first few diascas; as always, models shall be written based on the causality induced by message exchanges - not based on diascas being counted</li>
<li>when an actor instance is created from another one, it should be created <em>synchronously</em>, through the load balancer; the creator should wait for the creation to be notified, otherwise for example the created instance <em>could</em> subscribe on the next tick instead of on the current one</li>
<li><strong>no message shall be sent, directly or not, from the constructor of an actor</strong>; worst could be a <tt class="docutils literal">oneway</tt> one (it is asynchronous, hence prone to race conditions); <tt class="docutils literal">requests</tt>, despite their synchronous nature, shall not be used either, as no creation order among the initial actors shall be assumed (there is no guarantee that the targeted actor is already responsive - which may block the sender; ex: if the sending actor is read in batch from an initialisation file, while the targeted actor will be created in a later batch); even <tt class="docutils literal">actor messages</tt> shall not be used, as initial actors are not synchronised before the simulation start; as a result:</li>
</ul>
<div class="admonition note">
<p class="first admonition-title">Note</p>
<p class="last">Only actor messages shall be exchanged, and the first place for it to happen in the life cycle of an actor in its <tt class="docutils literal">class_Actor:onFirstDiasca/2</tt> actor oneway. As a bonus, it is also the guarantee that an actor will behave the same whether it is an initial one or it is created in the course of the simulation.</p>
</div>
<ul class="simple">
<li>communication between actors should <em>only</em> rely on the exchange of actor messages (no basic WOOPER method invocation or direct Erlang message sending allowed)</li>
<li>no actor message shall be sent from a destructor, as the deleted actor may not be still (or at all) synchronised to the simulation (ex: if not having acted spontaneously nor having received an actor message in the current tick offset); such a deletion can indeed be triggered from a non-actor context (ex: at simulation teardown, by a time manager), which would potentially result in a synchronisation error being detected (an actor message being sent in the past of the target actor); so the deletion of an actor shall be ultimately decided by itself, any actor-based operation to be performed then shall be done beforehand (either from <tt class="docutils literal">actSpontaneous/1</tt> or an actor oneway), before entering the destructor (see <tt class="docutils literal"><span class="pre">class_Actor:declareTermination/{1,2}</span></tt> instead)</li>
<li>to reduce the number of messages exchanged over the network and more generally to increase speed, trace sending is asynchronous (i.e. non-blocking). Thus if ever a simulation happens to send way too many traces (actors too verbose), then:</li>
<li>the trace aggregator will most probably lag behind, i.e. the traces being monitored in the course of the simulation will not correspond to the current state of the execution, but to a prior simulation state; and, should a crash occur, the corresponding traces may never be processed and thus be permanently lost</li>
<li>in worst talkative cases, the mailbox of the trace aggregator will lead to a huge memory footprint, possibly resulting in a crash in the course of the simulation (ex: with a message like <tt class="docutils literal">eheap_alloc: Cannot allocate XXX bytes of memory (of type &quot;old_heap&quot;)</tt>)</li>
<li>the simulation can be finished whereas the simulation case itself is still lingering (not terminating), waiting for the aggregator to process and store all remaining traces (it can last, in worst cases, for hours!)</li>
<li>when writing a simulation case (ex: a test case like <tt class="docutils literal">foo_test.erl</tt>), one must know that if the traces and their supervision are activated then, as soon as the user closes the supervision tool (ex: LogMX or the PDF viewer), a <tt class="docutils literal">{wooper_result,monitor_ok}</tt> message is sent back to the test, so that it is able to finish and shut down the Erlang node; however it means that any receive clause placed in the case (ex: between the calls of the <tt class="docutils literal">test_start/test_stop</tt> macros) must be written with special care, lest it catches this trace supervision message; for example if the supervision tool is close before a receive like <tt class="docutils literal">BarPid ! <span class="pre">{getBaz,[],self()},</span> receive {wooper_result,MyBaz} <span class="pre">-&gt;</span> ... end</tt> is executed, then <tt class="docutils literal">MyBaz</tt> will be actually <tt class="docutils literal">monitor_ok</tt> instead of the expected return value; the proper way of managing that is thus to add, to all receive clauses in the case, a proper guard, like: <tt class="docutils literal">when MyBaz /= monitor_ok</tt>; alternatively, if no other specific guard was needed in a receive clause, then it can be replaced by <tt class="docutils literal">MyBaz = test_receive()</tt> instead (defined in <tt class="docutils literal">traces_for_tests.hrl</tt>), as it enforces that the received result is not <tt class="docutils literal">monitor_ok</tt></li>
<li>if a specialized actor class <tt class="docutils literal">class_Foobar</tt> overrides the <tt class="docutils literal">simulationStarted/3</tt> method, a special care must be taken when writing its constructor (<tt class="docutils literal">class_Foobar:construct</tt>). Indeed the call to the overridden <tt class="docutils literal">simulationStarted/3</tt> method may happen directly from this constructor, through the call to the constructor of the (direct or not) mother class <tt class="docutils literal">class_Actor</tt>, should the corresponding actor be created whereas the simulation is already started (non-initial actor); as a result, one must ensure that any attribute modified in <tt class="docutils literal">class_Foobar:simulationStarted/3</tt> (ex: <tt class="docutils literal">baz</tt> set to <tt class="docutils literal">true</tt>) is not overwritten later in the class-specific part of <tt class="docutils literal">class_Foobar:construct</tt>, in what could be incorrectly considered as the initial setting of this attribute (ex: <tt class="docutils literal">baz</tt> set to <tt class="docutils literal">undefined</tt>). See <tt class="docutils literal">class_TestActor</tt> for an actual example of the dealing with that constraint</li>
</ul>
</div>
<div class="section" id="good-practices">
<h2><a class="toc-backref" href="#id260">Good Practices</a></h2>
<ul class="simple">
<li>all Erlang good practises should be followed</li>
<li>all WOOPER good practises should be followed</li>
<li>always think to the life-cycle of the actor instances you create: when are they to be created? By whom? When they shall be deleted?</li>
<li>in a simulation, either an actor is created before the simulation start, or by another actor; quite soon everything is driven by a model (ex: the deployment policy of devices in a simulated system should be an actor of its own)</li>
<li>each model should better be documented into a wiki page of its own</li>
<li>when designing complex-enough inter-actor protocols, diagrams such as the next one may help:</li>
</ul>
<p><span class="raw-html"><center><img src="actor-message-example-diagram.png"></img></center></span>
</p>
</div>
<div class="section" id="lesser-known-features">
<h2><a class="toc-backref" href="#id261">Lesser-Known Features</a></h2>
<p><span class="raw-html"><center><img src="xkcd-nine.png"></img></center></span>
</p>
<p>One should be aware that:</p>
<ul class="simple">
<li>even if the most usual mode of operation for SimDiasca-based simulators is the <em>batch</em> mode, the engine can also work in <strong>interactive</strong> mode as well (see the <tt class="docutils literal">simulation_interactivity_mode</tt> field of the <tt class="docutils literal">simulation_settings</tt> record in <tt class="docutils literal">class_TimeManager.hrl</tt>), where the simulation is kept on par with the wallclock time (rather than running as fast as possible); note to be confused with the <tt class="docutils literal"><span class="pre">--batch</span></tt> command-line option (see <tt class="docutils literal"><span class="pre">CMD_LINE_OPT=&quot;--batch&quot;</span></tt>), which means that no graphical output is wanted (just textual ones on the console then)</li>
<li>by default, the engine works in reproducible mode, based on a constant random seed, leading to always the same simulation trajectory for a simulation case; the engine can also work on (reproducible) <strong>ergodic</strong> mode (refer to the <tt class="docutils literal">evaluation_mode</tt> field in the same record as the previous hint), in which it changes the random seed at each simulation run, so that all the various possible trajectories can be explored, instead of just an arbitrary one</li>
<li>by default, probes write their results onto raw files; a database-based back-end is available as well, see the <strong>Data-Logger</strong> module for that (refer to <tt class="docutils literal">class_DataLogger.erl</tt> for that)</li>
<li>the engine includes a performance tracker, a service that can be enabled to track the behaviour of a simulation over both wall-clock and virtual time, and also its detailed resource consumption (see the <tt class="docutils literal">class_PerformanceTracker.erl</tt> for that); of course complementary insights can come from the operating system and from the Erlang VM itself</li>
<li>most users do not modify the code of engine itself, they mostly update repeatedly their simulation; therefore, in order to speed up the launching of a simulation (especially when being in the process of implementing it), since the 2.3.8 version of Sim-Diasca, the <tt class="docutils literal">rebuild_on_deployment_package_generation</tt> field of <tt class="docutils literal">deployment_settings</tt> record (in <tt class="docutils literal">class_DeploymentManager.hrl</tt>) is now set by default to <tt class="docutils literal">false</tt>; even with a SSD disk, a significant speed up can be noticed</li>
</ul>
</div>
<div class="section" id="other-useful-information">
<h2><a class="toc-backref" href="#id262">Other Useful Information</a></h2>
<ul class="simple">
<li>a WOOPER-aware <tt class="docutils literal">Nedit</tt> Erlang configuration file is available (see <tt class="docutils literal">myriad/conf/nedit.rc</tt>)</li>
<li>all Sim-Diasca Erlang source files (<tt class="docutils literal"><span class="pre">.hrl/.erl</span></tt>) should start with the appropriate LGPL header defined in <tt class="docutils literal"><span class="pre">sim-diasca/doc/licence/licence-header-erlang.txt</span></tt></li>
<li>the used Erlang environment should better be built thanks to a shell script we provide, <tt class="docutils literal"><span class="pre">myriad/conf/install-erlang.sh</span></tt>, to streamline this process; use for example <tt class="docutils literal"><span class="pre">myriad/conf/install-erlang.sh</span> <span class="pre">--cutting-edge</span> <span class="pre">--doc-install</span></tt>; add the <tt class="docutils literal"><span class="pre">--generate-plt</span></tt> option if intending to make any actual development in the future</li>
<li>in the cases where LogMX cannot be used to monitor the simulation traces, a fall-back system can be chosen instead: traces can be output as a human-readable text file which can be read by any text viewer; to do so, one just has to edit the <tt class="docutils literal"><span class="pre">sim-diasca/src/core/src/test_constructs.hrl</span></tt> file, in which <tt class="docutils literal"><span class="pre">-define(TraceType,log_mx_traces).</span></tt> should be replaced by <tt class="docutils literal"><span class="pre">-define(TraceType,text_traces).</span></tt></li>
<li>Sim-Diasca is able to run on multiple computing hosts, possibly with different user names; these hosts, and per-host user names as well, can be specified thanks to the <tt class="docutils literal">computing_hosts</tt> field of the <tt class="docutils literal">deployment_settings</tt> record (see <tt class="docutils literal">class_DeploymentManager.hrl</tt>)</li>
<li>where is the temporary data for the simulation stored on computing hosts? The default value of the <tt class="docutils literal">temporary_directory</tt> field of the <tt class="docutils literal">deployment_settings</tt> record is <tt class="docutils literal">/tmp</tt>; hence temporary data for a simulation case named <tt class="docutils literal">Foo</tt> run by a user <tt class="docutils literal">norris</tt> would be stored, on each host, in, for example, <tt class="docutils literal"><span class="pre">/tmp/sim-diasca-Foo-norris/2013-6-5-at-10h-38m-17s-1de19ec70ed5</span></tt> (the suffix is made of a wall-clock timestamp and a rather unique simulation ID); on simulation success, this directory will be automatically removed</li>
<li>how is this temporary data organised? In the general case, there are three top-level directories:</li>
<li><tt class="docutils literal"><span class="pre">deployed-elements</span></tt>, which contains the simulation archive (typically <tt class="docutils literal"><span class="pre">Sim-Diasca-deployment-archive.sdar</span></tt>) and the extracted trees thereof (typically with the main simulator layers, like <tt class="docutils literal">myriad</tt>, <tt class="docutils literal">wooper</tt>, <tt class="docutils literal">traces</tt>, etc.)</li>
<li><tt class="docutils literal">outputs</tt>, where simulation probes write their files (<tt class="docutils literal">*.dat</tt> for data, <tt class="docutils literal">*.p</tt> for the corresponding commands); as for technical probes (ex: for the performance tracker), they are directly written in the final result directory, as they must remain available in all cases (even if the simulation crashed)</li>
<li><tt class="docutils literal"><span class="pre">resilience-snapshots</span></tt>, where the persistance files for each secured node are stored, based on the tick and diasca of the serialisation and the node on which it was done (ex: <tt class="docutils literal"><span class="pre">serialisation-5719-0-from-cluster-node-147.foobar.org</span></tt>)</li>
<li>what are the constraints applying to the name of an attribute? Such a name must be an atom, and all names starting with <tt class="docutils literal">wooper_</tt>, <tt class="docutils literal">traces_</tt> or <tt class="docutils literal">sim_diasca_</tt> are reserved, and thus shall not be used</li>
</ul>
</div>
<div class="section" id="tips-and-tricks">
<h2><a class="toc-backref" href="#id263">Tips And Tricks</a></h2>
<ul class="simple">
<li>when running a simulation across multiple hosts, different versions of the Erlang runtime may coexist; if these releases are too distant in time to be compatible, the problem will be detected by Sim-Diasca and the incompatible versions will be reported; in this case one generally needs to install, out of the system tree, a newer version of the runtime to replace the oldest versions (use for that our <tt class="docutils literal"><span class="pre">install-erlang.sh</span></tt> script; more generally speaking, all Erlang runtimes <em>should</em> stick to the latest stable version, to benefit from the latest improvements); however, for these environments overridden by the user to be found by Sim-Diasca, they must become the default ones for that user; adding a line like <tt class="docutils literal"><span class="pre">PATH=~/my-install/bin:$PATH</span></tt> in one's shell settings (ex: <tt class="docutils literal"><span class="pre">~/.bashrc</span></tt>) is necessary but not always sufficient, as remote SSH login may not lead to that file being sourced; one should just check that on the target hosts the expected version Erlang version is used (ex: <tt class="docutils literal">ssh USER&#64;HOST erl</tt> allows to check the version); typically, with the <tt class="docutils literal">bash</tt> shell, the <tt class="docutils literal">.bash_profile</tt> file should contain something like: <tt class="docutils literal">if [ <span class="pre">-f</span> <span class="pre">~/.bashrc</span> ]; then . <span class="pre">~/.bashrc;</span> fi</tt></li>
<li>when adding a source file to the Sim-Diasca engine, use the <tt class="docutils literal"><span class="pre">add-header-to-files.sh</span></tt> script with an appropriate header, for example:</li>
</ul>
<pre class="code bash literal-block">
$ add-header-to-files.sh ../licence-header-erlang.txt MyNewFile.erl
</pre>
<ul class="simple">
<li>one may define in one's shell settings (ex: <tt class="docutils literal"><span class="pre">~/.bashrc</span></tt>) a variable that disables the automatic launch of the various windows (ex: LogMX interface, result browser, etc.), like in:</li>
</ul>
<pre class="code bash literal-block">
<span class="nb">export</span> <span class="nv">BATCH</span><span class="o">=</span><span class="s2">&quot;CMD_LINE_OPT='--batch'&quot;</span>
</pre>
<p>then running a test as <tt class="docutils literal">make my_test_run $BATCH</tt> will prevent any Sim-Diasca related window to pop up; this is quicker and more convenient when first debugging a new model: we generally have to focus first on runtime errors on the console. Then, only when these first mistakes are corrected, we can take advantage of the simulation traces and other information (with the usual <tt class="docutils literal">make my_test_run</tt>)</p>
<ul class="simple">
<li>one may also define in one's shell settings (ex: <tt class="docutils literal"><span class="pre">~/.bashrc</span></tt>) an alias that points to the current check-out (clone) and branch one's is using: otherwise an absent-minded developer could operate directly in the trunk or in a wrong branch; for example one can use: <tt class="docutils literal">alias <span class="pre">tosim='cd</span> $HOME/A_PATH</tt> (with GIT reusing lastly used branch is less a problem)</li>
<li>simulation traces can be inspected without LogMX, see the <a class="reference internal" href="#simulation-traces">Simulation Traces</a> section</li>
<li>sometimes, in error messages, we can see weird lists like:</li>
</ul>
<pre class="code erlang literal-block">
<span class="p">[</span><span class="mi">84</span><span class="p">,</span><span class="mi">104</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span><span class="mi">115</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span><span class="mi">115</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">97</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">115</span><span class="p">,</span><span class="mi">116</span><span class="p">,</span><span class="mi">114</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span><span class="mi">110</span><span class="p">,</span><span class="mi">103</span><span class="p">,</span><span class="mi">46</span><span class="p">]</span>
</pre>
<p>They are actually strings, that can be properly displayed by pasting them in an interpreter:</p>
<pre class="code erlang literal-block">
<span class="mi">1</span><span class="o">&gt;</span> <span class="p">[</span><span class="mi">84</span><span class="p">,</span><span class="mi">104</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span><span class="mi">115</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span><span class="mi">115</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">97</span><span class="p">,</span><span class="mi">32</span><span class="p">,</span><span class="mi">115</span><span class="p">,</span><span class="mi">116</span><span class="p">,</span><span class="mi">114</span><span class="p">,</span><span class="mi">105</span><span class="p">,</span><span class="mi">110</span><span class="p">,</span><span class="mi">103</span><span class="p">,</span><span class="mi">46</span><span class="p">].</span>
   <span class="s">&quot;This is a string.&quot;</span>
</pre>
<ul class="simple">
<li>knowing that the simulation engine relies on reproducible AAI, no special effort is made so that PID are themselves reproducible; moreover, notably in a distributed context, reproducibility of PID <em>cannot</em> be ensured at all (ex: two actors may create another actor each during the same tick); however, to investigate the mode of operation of the engine, it is convenient, as least for the first few simulation phases, to try to reduce the PID variability from a run to another, so that the same agent (ex: the load balancer) always bears the same PID; the simultaneous launching of the LogMX interface tends to make the first PID change a lot (ex: <tt class="docutils literal">&lt;x.52.0&gt;</tt>, then <tt class="docutils literal">&lt;x.58.0&gt;</tt>, then``&lt;x.56.0&gt;``, etc.); to reduce this trend, one should preferably run the simulation in batch mode: PID will then be a lot less changing; for example: <tt class="docutils literal">make my_case_run <span class="pre">CMD_LINE_OPT=&quot;--batch&quot;</span></tt></li>
<li>sometimes one may want to connect to the running Erlang VM, in order to determine what is happening there; to do so, one should note the pipe this VM is attached to (for that one should refer to the console output: one of the very first lines is akin to <tt class="docutils literal">Attaching to <span class="pre">/tmp/launch-erl-4938</span> (^D to exit)</tt>; then executing from another terminal <tt class="docutils literal">to_erl <span class="pre">-F</span> <span class="pre">/tmp/launch-erl-4938</span></tt> allows to connect to the VM</li>
<li>in case of a failure during a simulation, some Erlang nodes may linger on various computing hosts and be on the way of the next run; to ensure each new run cleans up any lingering node before launching a simulation, one may set the <tt class="docutils literal">perform_initial_node_cleanup</tt> field in the <tt class="docutils literal">deployment_settings</tt> record to true (see <tt class="docutils literal">class_DeploymentManager.hrl</tt>). Then another step will be added to the simulation start (which thus will take a bit longer), but no new run will have to reject a computing host because of an already existing node running with the target name but a different cookie; in all cases, a simulation cannot use such nodes by mistake, thanks to the unique cookie it generates at each launch</li>
<li>one may use the <tt class="docutils literal"><span class="pre">myriad/src/fix-all-sources.sh</span></tt> script periodically (from fully check-ined sources) to clean-up sources and remove unbreakable spaces</li>
<li>in some cases, mostly related to probe storage or post-processing, for example if wanting to create a large number of basic probes using immediate (non-deferred) writes (which is the default), you may be hindered by the maximum number of open file descriptors, which is usually set to 1024, thereby limiting the number of basic probes to, roughly, a thousand per computing node; refer to <a class="reference internal" href="#probe-troubleshooting">Probe Troubleshooting</a> for the various solutions to consider</li>
<li>on clusters, notably with PBS-based clusters, output log files (standard and error, ex: <tt class="docutils literal"><span class="pre">Sim-Diasca.o1983473</span></tt> and <tt class="docutils literal"><span class="pre">Sim-Diasca.e1983473</span></tt>) will be available <em>only</em> once the simulation is terminated (on error or on success); however, for most computations, notably the ones with high maximum durations, knowing whether the simulation is making relevant progress, or just wasting resources due to any issue, is surely convenient, as it allows either to monitor the corresponding task or to kill it a lot earlier, freeing the corresponding resources; to access this information, one has to connect to the node from which the simulation was actually run from by the job manager; this involves getting the job identifier (ex: thanks to <tt class="docutils literal">qstat <span class="pre">-u</span> $USER</tt>), determining the first allocated node (ex: <tt class="docutils literal">qstat <span class="pre">-f</span> 1983473.cla11pno | grep exec_host</tt>), connecting to it (directly with <tt class="docutils literal">ssh</tt> rather than with <tt class="docutils literal">qsub <span class="pre">-I</span></tt>) and look at <tt class="docutils literal"><span class="pre">/var/spool/torque/spool/${job_id}.OU</span></tt>, ex: <tt class="docutils literal">/var/spool/torque/spool/1983473.cla11pno.OU</tt></li>
</ul>
<p></p>
</div>
</div>
<div class="section" id="sim-diasca-bibliography">
<h1><a class="toc-backref" href="#id264">Sim-Diasca Bibliography</a></h1>
<p>In terms of multi-agent systems and distributed simulations, we spotted the following publications:</p>
<ul class="simple">
<li><a class="reference external" href="http://research.microsoft.com/users/lamport/pubs/time-clocks.pdf">Time, Clocks, and the Ordering of Events in a Distributed System</a>, by Leslie Lamport</li>
<li><a class="reference external" href="http://www.usingcsp.com/cspbook.pdf">Communicating Sequential Processes (CSP)</a>, by C.A.R. Hoare</li>
<li><a class="reference external" href="http://citeseer.ist.psu.edu/carlson95sim.html">Sim94, A concurrent simulator for plan-driven troops</a> (1995), by Bjorn Carlson</li>
</ul>
<ul class="simple">
<li><a class="reference external" href="http://citeseer.ist.psu.edu/706010.html">An Evaluation of Conservative Protocols for Bulk-Synchronous Parallel Discrete-Event Simulation</a>, by  Mauricio Marin</li>
</ul>
<p>Some books are relevant as well:</p>
<ul class="simple">
<li><em>Parallel and Distributed Simulation Systems</em>, author: Richard M. Fujimoto, publisher: Wiley-Interscience, ISBN: <tt class="docutils literal"><span class="pre">978-0471183839</span></tt></li>
<li><em>Modélisation et simulation à base d'agents</em>, authors: Jean-Pierre Treuil, Alexis Drogoul and Jean-Daniel Zucker, editor: Dunod, ISBN: <tt class="docutils literal"><span class="pre">978-2-10-050216-5</span></tt></li>
<li><em>Modélisation et simulation d'écosystèmes, des modèles déterministes aux simulations à événements discrets</em>, authors: Patrick Coquillard and David R.C. Hill, editor: Masson, ISBN: <tt class="docutils literal"><span class="pre">2-225-85363-0</span></tt></li>
<li><em>Modélisation stochastique et simulation</em>, authors: Bernard Bercu and Djalil Chafaï, editor: Dunod, ISBN: <tt class="docutils literal"><span class="pre">978-2-10-051379-6</span></tt></li>
</ul>
<p></p>
</div>
<div class="section" id="sim-diasca-credits">
<span id="credits"></span><h1><a class="toc-backref" href="#id265">Sim-Diasca Credits</a></h1>
<p>Special thanks to <strong>Randall Munroe</strong> who is the author of all the comic strips that enliven this documentation, and who kindly allowed their use in this material.</p>
<p>See his <a class="reference external" href="http://xkcd.com/">XKCD</a> website for all information, including for all his delightful other strips.</p>
<p></p>
</div>
<div class="section" id="sim-diasca-license">
<span id="lgpl"></span><h1><a class="toc-backref" href="#id266">Sim-Diasca License</a></h1>
<p>Sim-Diasca is free software; it has been developed by <a class="reference external" href="https://www.edf.fr/en/the-edf-group/inventing-the-future-of-energy/r-d-global-expertise">EDF R&amp;D</a> and is released under the <a class="reference external" href="http://www.gnu.org/licenses/lgpl.html">GNU LGPL licence</a> (GNU LESSER GENERAL PUBLIC LICENSE, Version 3).</p>
<p></p>
</div>
<div class="section" id="contributing-to-sim-diasca">
<h1><a class="toc-backref" href="#id267">Contributing To Sim-Diasca</a></h1>
<p>Of course contributions of all kinds (code, documentation, examples, etc.)  are welcome:</p>
<p><span class="raw-html"><center><img src="xkcd-study.png"></img></center></span>
</p>
<p>We cannot guarantee that all patches will be integrated, but we surely will review them and do our best to make use of them, provided the original author accepts they end up in the public release and under the same licensing terms as the rest of Sim-Diasca.</p>
<p></p>
</div>
<div class="section" id="what-to-do-next">
<h1><a class="toc-backref" href="#id268">What To Do Next?</a></h1>
<p>Congratulations, you reached the end of this technical guide!</p>
<p><span class="raw-html"><center><img src="xkcd-anti_mind_virus.png"></img></center></span>
</p>
<p>Recommended next actions would then be:</p>
<ol class="arabic simple">
<li>read the (much shorter) <em>Sim-Diasca Modeller Guide</em> and, possibly, the <em>Sim-Diasca Developer Guide</em> as well</li>
<li>write your own test models, getting inspiration from the <em>Sim-Diasca Mock Simulators</em> examples (see the top-level <tt class="docutils literal"><span class="pre">mock-simulators</span></tt> directory in the source archive; looking at the <tt class="docutils literal"><span class="pre">soda-test</span></tt> should clarify a lot the use of the engine)</li>
</ol>
<p>We hope that you will enjoy using Sim-Diasca. As always, any (constructive!) feedback is welcome (use <a class="reference external" href="mailto:olivier&#46;boudeville&#37;&#52;&#48;edf&#46;fr">this email address</a> for that). Thanks!</p>
<p><span class="raw-html"><center><img src="sim-diasca.png" id="responsive-image-small"></img></center></span>
</p>
<p><span class="raw-html"><a name="sim_diasca_bottom"></a></span></p>
</div>
</div>
</body>
</html>
